{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324812b5-edfc-4501-9ded-ecd559725cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:43:33.858298Z",
     "iopub.status.busy": "2024-04-02T19:43:33.857979Z",
     "iopub.status.idle": "2024-04-02T19:44:13.784505Z",
     "shell.execute_reply": "2024-04-02T19:44:13.783508Z",
     "shell.execute_reply.started": "2024-04-02T19:43:33.858275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF==1.23.26\n",
      "  Downloading PyMuPDF-1.23.26-cp39-none-manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.8.3\n",
      "  Downloading matplotlib-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.2.1\n",
      "  Downloading pandas-2.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Requests==2.31.0\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentence_transformers==2.5.1\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (3.4.1)\n",
      "Collecting tqdm==4.66.2\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.38.2\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (0.35.1)\n",
      "Collecting PyMuPDFb==1.23.22\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (5.10.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==2.2.1->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.12.1+cu116)\n",
      "Collecting huggingface-hub>=0.15.1\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.9.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (2022.10.31)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (3.9.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (66.1.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.4.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.8)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 10)) (5.9.4)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (8.0.2)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.5.2)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.16.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (7.2.9)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.8.3->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 7)) (6.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (25.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (6.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.5.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (7.3.4)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (0.1.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.6.6)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (8.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (3.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (5.1.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (3.0.36)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.11.1)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (5.7.3)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.4.8)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (21.3.0)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (3.1.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.5/38.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.18.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter->-r requirements.txt (line 12)) (2.6.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.23.5)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (4.17.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 12)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (18.2.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.57.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (2.21)\n",
      "Installing collected packages: tzdata, tqdm, safetensors, Requests, qtpy, PyMuPDFb, numpy, fsspec, scipy, PyMuPDF, pandas, huggingface-hub, bitsandbytes, tokenizers, matplotlib, accelerate, transformers, sentence_transformers, qtconsole, jupyter-console, jupyter\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: Requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.4\n",
      "    Uninstalling numpy-1.23.4:\n",
      "      Successfully uninstalled numpy-1.23.4\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.2\n",
      "    Uninstalling scipy-1.9.2:\n",
      "      Successfully uninstalled scipy-1.9.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.0\n",
      "    Uninstalling pandas-1.5.0:\n",
      "      Successfully uninstalled pandas-1.5.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.6.1\n",
      "    Uninstalling matplotlib-3.6.1:\n",
      "      Successfully uninstalled matplotlib-3.6.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: sentence_transformers\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "    Uninstalling sentence-transformers-2.2.2:\n",
      "      Successfully uninstalled sentence-transformers-2.2.2\n",
      "Successfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22 Requests-2.31.0 accelerate-0.28.0 bitsandbytes-0.43.0 fsspec-2024.3.1 huggingface-hub-0.22.2 jupyter-1.0.0 jupyter-console-6.6.3 matplotlib-3.8.3 numpy-1.26.4 pandas-2.2.1 qtconsole-5.5.1 qtpy-2.4.1 safetensors-0.4.2 scipy-1.12.0 sentence_transformers-2.5.1 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.38.2 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ca8e7f-485d-43bc-bb8a-b5332868591b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:44:52.589823Z",
     "iopub.status.busy": "2024-04-02T22:44:52.589003Z",
     "iopub.status.idle": "2024-04-02T22:44:52.763278Z",
     "shell.execute_reply": "2024-04-02T22:44:52.762517Z",
     "shell.execute_reply.started": "2024-04-02T22:44:52.589788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import fitz\n",
    "import os\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f05e79-77f3-4fde-b9bf-f6bda82205d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:44:54.042583Z",
     "iopub.status.busy": "2024-04-02T22:44:54.041608Z",
     "iopub.status.idle": "2024-04-02T22:44:54.047320Z",
     "shell.execute_reply": "2024-04-02T22:44:54.046535Z",
     "shell.execute_reply.started": "2024-04-02T22:44:54.042553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Standford NLP.pdf', 'Attn_paper.pdf', 'Faiss.pdf', 'Gemini_paper.pdf', 'BART.pdf']\n"
     ]
    }
   ],
   "source": [
    "pdf_path = './'\n",
    "pdf_files = [f for f in os.listdir(pdf_path) if f.endswith(\".pdf\")]\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553c8a31-8540-475a-a6d1-13624086aaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:44:54.423030Z",
     "iopub.status.busy": "2024-04-02T22:44:54.422207Z",
     "iopub.status.idle": "2024-04-02T22:44:54.426348Z",
     "shell.execute_reply": "2024-04-02T22:44:54.425564Z",
     "shell.execute_reply.started": "2024-04-02T22:44:54.422999Z"
    }
   },
   "outputs": [],
   "source": [
    "books_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f57935-34e4-40ae-bad8-5d1928230c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:44:55.084882Z",
     "iopub.status.busy": "2024-04-02T22:44:55.084532Z",
     "iopub.status.idle": "2024-04-02T22:44:55.091521Z",
     "shell.execute_reply": "2024-04-02T22:44:55.090940Z",
     "shell.execute_reply.started": "2024-04-02T22:44:55.084852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Text content of the pdf\n",
    "# For each pdf , get the pdf file contents \n",
    "# Store meta-data information about each pdf.\n",
    "\n",
    "def format_text(text):\n",
    "    text = text.strip(\"\\n\\n\")\n",
    "    text=text.replace(\"\\n\",'')\n",
    "    return text\n",
    "\n",
    "# # https://community.adobe.com/t5/acrobat-discussions/page-number-in-print-does-not-display-in-adobe-s-page-number-box/td-p/13781534\n",
    "# Doesn't use Logical Page numbers. Use the normal Page numbers\n",
    "# Logical causes issues during the rendering as you can't generalize to multiple pdfs\n",
    "\n",
    "def get_text_content(pdf_text_, pdf_):\n",
    "    doc = fitz.open(pdf_)\n",
    "    print(len(doc))\n",
    "    for page_num, page in enumerate(doc):\n",
    "        # Extract the text content of the page\n",
    "        text = page.get_text()\n",
    "        text = format_text(text)\n",
    "        name = pdf_.strip('.pdf')\n",
    "        pdf_text_.append((text, page_num+1, name))\n",
    "    return pdf_text_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240ec7a0-14df-4311-b574-22817bcda0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:44:56.152399Z",
     "iopub.status.busy": "2024-04-02T22:44:56.151496Z",
     "iopub.status.idle": "2024-04-02T22:44:59.157246Z",
     "shell.execute_reply": "2024-04-02T22:44:59.156456Z",
     "shell.execute_reply.started": "2024-04-02T22:44:56.152399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "15\n",
      "21\n",
      "62\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "books_ = []\n",
    "books_ = [get_text_content([], pdf_) for pdf_ in pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e7ba8b-f5f9-4a52-9168-67d7bf68b45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:00.030643Z",
     "iopub.status.busy": "2024-04-02T22:45:00.029953Z",
     "iopub.status.idle": "2024-04-02T22:45:00.038287Z",
     "shell.execute_reply": "2024-04-02T22:45:00.037293Z",
     "shell.execute_reply.started": "2024-04-02T22:45:00.030612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107,\n",
       " ('Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on theEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.ModelBLEUTraining Cost (FLOPs)EN-DEEN-FREN-DEEN-FRByteNet [18]23.75Deep-Att + PosUnk [39]39.21.0 · 1020GNMT + RL [38]24.639.922.3 · 10191.4 · 1020ConvS2S [9]25.1640.469.6 · 10181.5 · 1020MoE [32]26.0340.562.0 · 10191.2 · 1020Deep-Att + PosUnk Ensemble [39]40.48.0 · 1020GNMT + RL Ensemble [38]26.3041.161.8 · 10201.1 · 1021ConvS2S Ensemble [9]26.3641.297.7 · 10191.2 · 1021Transformer (base model)27.338.13.3 · 1018Transformer (big)28.441.82.3 · 1019Residual DropoutWe apply dropout [33] to the output of each sub-layer, before it is added to thesub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and thepositional encodings in both the encoder and decoder stacks. For the base model, we use a rate ofPdrop = 0.1.Label SmoothingDuring training, we employed label smoothing of value ϵls = 0.1 [36]. Thishurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.6Results6.1Machine TranslationOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model islisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base modelsurpasses all previously published models and ensembles, at a fraction of the training cost of any ofthe competitive models.On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,outperforming all of the previously published single models, at less than 1/4 the training cost of theprevious state-of-the-art model. The Transformer (big) model trained for English-to-French useddropout rate Pdrop = 0.1, instead of 0.3.For the base models, we used a single model obtained by averaging the last 5 checkpoints, whichwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. Weused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameterswere chosen after experimentation on the development set. We set the maximum output length duringinference to input length + 50, but terminate early when possible [38].Table 2 summarizes our results and compares our translation quality and training costs to other modelarchitectures from the literature. We estimate the number of floating point operations used to train amodel by multiplying the training time, the number of GPUs used, and an estimate of the sustainedsingle-precision floating-point capacity of each GPU 5.6.2Model VariationsTo evaluate the importance of different components of the Transformer, we varied our base modelin different ways, measuring the change in performance on English-to-German translation on the5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.8',\n",
       "  8,\n",
       "  'Attn_paper'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_[1][7][0]) , books_[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372100f9-c04e-4888-9d57-0e28f2d2a578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:02.176222Z",
     "iopub.status.busy": "2024-04-02T22:45:02.175255Z",
     "iopub.status.idle": "2024-04-02T22:45:02.248105Z",
     "shell.execute_reply": "2024-04-02T22:45:02.247168Z",
     "shell.execute_reply.started": "2024-04-02T22:45:02.176173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Books_  -> [List[List[(text_content, page_num)]]\n",
    "\n",
    "# Create a dictionary to store each pages documents into sentences\n",
    "\n",
    "# Estimating that each token is 4 characters\n",
    "# Page Info\n",
    "def page_formatter(page):\n",
    "    page_ = {}\n",
    "    for pg in page:\n",
    "        page_['doc_name'] = page[2]\n",
    "        page_['text'] = page[0]\n",
    "        page_['pg_num'] = page[1]\n",
    "        page_['pg_num_chars'] = len(page[0])\n",
    "        page_['pg_num_words'] = len(page[0].split(' '))\n",
    "        page_['pg_num_sentences'] = len(page[0].split('. ')) # Since sentences usually begin with '. '\n",
    "        page_['pg_num_tokens'] = page_['pg_num_chars'] / 4\n",
    "    return page_\n",
    "                                        \n",
    "# Testing with a single page\n",
    "# page_formatter(books_[1][6])\n",
    "\n",
    "all_content_ = [[page_formatter(page) for page in books] for books in books_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8f3a9c-4daf-448c-bde8-00c044a642e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:03.349382Z",
     "iopub.status.busy": "2024-04-02T22:45:03.348539Z",
     "iopub.status.idle": "2024-04-02T22:45:03.354933Z",
     "shell.execute_reply": "2024-04-02T22:45:03.353984Z",
     "shell.execute_reply.started": "2024-04-02T22:45:03.349352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_name': 'Gemini_paper',\n",
       " 'text': 'Gemini: A Family of Highly Capable Multimodal ModelsFigure 2 | Gemini supports interleaved sequences of text, image, audio, and video as inputs (illustratedby tokens of different colors in the input sequence). It can output responses with interleaved imageand text.tasks that require fine-grained understanding. In addition, Gemini can directly ingest audio signals at16kHz from Universal Speech Model (USM) (Zhang et al., 2023) features. This enables the model tocapture nuances that are typically lost when the audio is naively mapped to a text input (for example,see audio understanding demo on the website).Training the Gemini family of models required innovations in training algorithms, dataset, andinfrastructure. For the Pro model, the inherent scalability of our infrastructure and learning algorithmsenable us to complete pretraining in a matter of weeks, leveraging a fraction of the Ultra’s resources.The Nano series of models leverage additional advancements in distillation and training algorithmsto produce the best-in-class small language models for a wide variety of tasks, such as summarizationand reading comprehension, which power our next generation on-device experiences.3. Training InfrastructureWe trained Gemini models using TPUv5e and TPUv4 (Jouppi et al., 2023), depending on their sizesand configuration. Training Gemini Ultra used a large fleet of TPUv4 accelerators across multipledatacenters. This represents a significant increase in scale over our prior flagship model PaLM-2which presented new infrastructure challenges. Scaling up the number of accelerators results in aproportionate decrease in the mean time between failure of hardware in the overall system. Weminimized the rate of planned reschedules and preemptions, but genuine machine failures arecommonplace across all hardware accelerators at such large scales.TPUv4 accelerators are deployed in “SuperPods” of 4096 chips, each connected to a dedicatedoptical switch, which can dynamically reconfigure 4x4x4 chip cubes into arbitrary 3D torus topologiesin around 10 seconds (Jouppi et al., 2023). For Gemini Ultra, we decided to retain a small number ofcubes per superpod to allow for hot standbys and rolling maintenance.TPU accelerators primarily communicate over the high speed inter-chip-interconnect, but atGemini Ultra scale, we combine SuperPods in multiple datacenters using Google’s intra-cluster andinter-cluster network (Poutievski et al., 2022; Wetherall et al., 2023; yao Hong et al., 2018). Google’snetwork latencies and bandwidths are sufficient to support the commonly used synchronous training4',\n",
       " 'pg_num': 4,\n",
       " 'pg_num_chars': 2605,\n",
       " 'pg_num_words': 360,\n",
       " 'pg_num_sentences': 12,\n",
       " 'pg_num_tokens': 651.25}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[3][3] # List[List[dictionaries]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11cd74a8-2aa4-45cd-951e-c0849a2015a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:05.421254Z",
     "iopub.status.busy": "2024-04-02T22:45:05.420907Z",
     "iopub.status.idle": "2024-04-02T22:45:05.843094Z",
     "shell.execute_reply": "2024-04-02T22:45:05.841918Z",
     "shell.execute_reply.started": "2024-04-02T22:45:05.421228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
      "Token_mean , Sentences_mean (642.45, 17.0)\n",
      "Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
      "Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
      "Token_mean , Sentences_mean (1003.2, 18.7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df_p1_mean = pd.DataFrame(all_content_[0])['pg_num_tokens'].mean()\n",
    "# # df_p2 = pd.DataFrame(all_content_[1])\n",
    "# # df_p3 = pd.DataFrame(all_content_[2])\n",
    "# # df_p4 = pd.DataFrame(all_content_[3])\n",
    "# print(df_p1_mean)\n",
    "\n",
    "# Calculate the mean number of sentences in each document.Then use sentence_splitter \n",
    "# to split the long sentences\n",
    "def calc_mean(doc):\n",
    "    doc_df = pd.DataFrame(doc)\n",
    "    doc_mean = doc_df['pg_num_tokens'].mean()\n",
    "    doc_sentences_mean = doc_df['pg_num_sentences'].mean()\n",
    "    return doc_mean, doc_sentences_mean\n",
    "\n",
    "for doc in all_content_:\n",
    "    print(\"Token_mean , Sentences_mean\",calc_mean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490938ae-971f-4fc3-83d1-7a8a6271b570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:07.198014Z",
     "iopub.status.busy": "2024-04-02T22:45:07.196762Z",
     "iopub.status.idle": "2024-04-02T22:45:07.203206Z",
     "shell.execute_reply": "2024-04-02T22:45:07.202162Z",
     "shell.execute_reply.started": "2024-04-02T22:45:07.197974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each sentence is long , the mean token size are above and won't fit the embedding model for tokenization\n",
    "# Split sentences into smaller chunks\n",
    "\n",
    "# Method to put all sentences in an array called sentences for making the splitting easier\n",
    "def sentence_formatter_per_page(doc):\n",
    "    for page in doc:\n",
    "        page['sentences'] = [sentence for sentence in page['text'].split('. ')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c910ef41-1429-4e27-96c4-8e92fa6976fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:08.028589Z",
     "iopub.status.busy": "2024-04-02T22:45:08.027499Z",
     "iopub.status.idle": "2024-04-02T22:45:08.032745Z",
     "shell.execute_reply": "2024-04-02T22:45:08.031893Z",
     "shell.execute_reply.started": "2024-04-02T22:45:08.028549Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_formatter_all_books(books):\n",
    "    for item in books:\n",
    "        sentence_formatter_per_page(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53290f2f-9396-45b9-9a45-2f4302595bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:09.136286Z",
     "iopub.status.busy": "2024-04-02T22:45:09.135889Z",
     "iopub.status.idle": "2024-04-02T22:45:09.150749Z",
     "shell.execute_reply": "2024-04-02T22:45:09.149750Z",
     "shell.execute_reply.started": "2024-04-02T22:45:09.136243Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_formatter_all_books(all_content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0592b64-379c-485c-bb8e-e206894488f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:10.027129Z",
     "iopub.status.busy": "2024-04-02T22:45:10.026274Z",
     "iopub.status.idle": "2024-04-02T22:45:10.034940Z",
     "shell.execute_reply": "2024-04-02T22:45:10.033639Z",
     "shell.execute_reply.started": "2024-04-02T22:45:10.027129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_name': 'Standford NLP',\n",
       "  'text': '2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence. With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions. The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe. Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way. Consider the expression /[a-z]*/when matching against the text once upon a time. Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once. In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer. The operator *? is a Kleene star that matches as little text as*?possible. The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the. A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The). This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology). So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/. We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25). We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line. This is because the regular expression [ˆa-zA-Z], which',\n",
       "  'pg_num': 17,\n",
       "  'pg_num_chars': 2646,\n",
       "  'pg_num_words': 398,\n",
       "  'pg_num_sentences': 15,\n",
       "  'pg_num_tokens': 661.5,\n",
       "  'sentences': ['2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence',\n",
       "   'With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions',\n",
       "   'The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe',\n",
       "   'Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way',\n",
       "   'Consider the expression /[a-z]*/when matching against the text once upon a time',\n",
       "   'Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once',\n",
       "   'In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer',\n",
       "   'The operator *? is a Kleene star that matches as little text as*?possible',\n",
       "   'The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the',\n",
       "   'A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The)',\n",
       "   'This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology)',\n",
       "   'So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/',\n",
       "   'We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25)',\n",
       "   'We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line',\n",
       "   'This is because the regular expression [ˆa-zA-Z], which']},\n",
       " {'doc_name': 'Standford NLP',\n",
       "  'text': '10CHAPTER 2•REGULAR EXPRESSIONS, TEXT NORMALIZATION, EDIT DISTANCEwe used to avoid embedded instances of the, implies that there must be some single(although non-alphabetic) character before the the. We can avoid this by specify-ing that before the the we require either the beginning-of-line or a non-alphabeticcharacter, and the same at the end of the line:/(ˆ|[ˆa-zA-Z])[tT]he([ˆa-zA-Z]|$)/The process we just went through was based on ﬁxing two kinds of errors: falsepositives, strings that we incorrectly matched like other or there, and false nega-false positivestives, strings that we incorrectly missed, like The. Addressing these two kinds offalse negativeserrors comes up again and again in implementing speech and language processingsystems. Reducing the overall error rate for an application thus involves two antag-onistic efforts:• Increasing precision (minimizing false positives)• Increasing recall (minimizing false negatives)We’ll come back to precision and recall with more precise deﬁnitions in Chapter 4.2.1.4More OperatorsFigure 2.8 shows some aliases for common ranges, which can be used mainly tosave typing. Besides the Kleene * and Kleene + we can also use explicit numbers ascounters, by enclosing them in curly brackets. The regular expression /{3}/ means“exactly 3 occurrences of the previous character or expression”. So /a\\\\.{24}z/will match a followed by 24 dots followed by z (but not a followed by 23 or 25 dotsfollowed by a z).RegexExpansionMatchFirst Matches\\\\d[0-9]any digitParty␣of␣5\\\\D[ˆ0-9]any non-digitBlue␣moon\\\\w[a-zA-Z0-9_]any alphanumeric/underscoreDaiyu\\\\W[ˆ\\\\w]a non-alphanumeric!!!!\\\\s[␣\\\\r\\\\t\\\\n\\\\f]whitespace (space, tab)in Concord\\\\S[ˆ\\\\s]Non-whitespacein␣ConcordFigure 2.8Aliases for common sets of characters.A range of numbers can also be speciﬁed. So /{n,m}/ speciﬁes from n to moccurrences of the previous char or expression, and /{n,}/ means at least n occur-rences of the previous expression. REs for counting are summarized in Fig. 2.9.RegexMatch*zero or more occurrences of the previous char or expression+one or more occurrences of the previous char or expression?zero or one occurrence of the previous char or expression{n}exactly n occurrences of the previous char or expression{n,m}from n to m occurrences of the previous char or expression{n,}at least n occurrences of the previous char or expression{,m}up to m occurrences of the previous char or expressionFigure 2.9Regular expression operators for counting.Finally, certain special characters are referred to by special notation based on thebackslash (\\\\) (see Fig. 2.10). The most common of these are the newline characternewline',\n",
       "  'pg_num': 18,\n",
       "  'pg_num_chars': 2634,\n",
       "  'pg_num_words': 357,\n",
       "  'pg_num_sentences': 12,\n",
       "  'pg_num_tokens': 658.5,\n",
       "  'sentences': ['10CHAPTER 2•REGULAR EXPRESSIONS, TEXT NORMALIZATION, EDIT DISTANCEwe used to avoid embedded instances of the, implies that there must be some single(although non-alphabetic) character before the the',\n",
       "   'We can avoid this by specify-ing that before the the we require either the beginning-of-line or a non-alphabeticcharacter, and the same at the end of the line:/(ˆ|[ˆa-zA-Z])[tT]he([ˆa-zA-Z]|$)/The process we just went through was based on ﬁxing two kinds of errors: falsepositives, strings that we incorrectly matched like other or there, and false nega-false positivestives, strings that we incorrectly missed, like The',\n",
       "   'Addressing these two kinds offalse negativeserrors comes up again and again in implementing speech and language processingsystems',\n",
       "   'Reducing the overall error rate for an application thus involves two antag-onistic efforts:• Increasing precision (minimizing false positives)• Increasing recall (minimizing false negatives)We’ll come back to precision and recall with more precise deﬁnitions in Chapter 4.2.1.4More OperatorsFigure 2.8 shows some aliases for common ranges, which can be used mainly tosave typing',\n",
       "   'Besides the Kleene * and Kleene + we can also use explicit numbers ascounters, by enclosing them in curly brackets',\n",
       "   'The regular expression /{3}/ means“exactly 3 occurrences of the previous character or expression”',\n",
       "   'So /a\\\\.{24}z/will match a followed by 24 dots followed by z (but not a followed by 23 or 25 dotsfollowed by a z).RegexExpansionMatchFirst Matches\\\\d[0-9]any digitParty␣of␣5\\\\D[ˆ0-9]any non-digitBlue␣moon\\\\w[a-zA-Z0-9_]any alphanumeric/underscoreDaiyu\\\\W[ˆ\\\\w]a non-alphanumeric!!!!\\\\s[␣\\\\r\\\\t\\\\n\\\\f]whitespace (space, tab)in Concord\\\\S[ˆ\\\\s]Non-whitespacein␣ConcordFigure 2.8Aliases for common sets of characters.A range of numbers can also be speciﬁed',\n",
       "   'So /{n,m}/ speciﬁes from n to moccurrences of the previous char or expression, and /{n,}/ means at least n occur-rences of the previous expression',\n",
       "   'REs for counting are summarized in Fig',\n",
       "   '2.9.RegexMatch*zero or more occurrences of the previous char or expression+one or more occurrences of the previous char or expression?zero or one occurrence of the previous char or expression{n}exactly n occurrences of the previous char or expression{n,m}from n to m occurrences of the previous char or expression{n,}at least n occurrences of the previous char or expression{,m}up to m occurrences of the previous char or expressionFigure 2.9Regular expression operators for counting.Finally, certain special characters are referred to by special notation based on thebackslash (\\\\) (see Fig',\n",
       "   '2.10)',\n",
       "   'The most common of these are the newline characternewline']}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[0][16:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98814d44-297b-4e64-8629-b1428e7e4d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:14.055409Z",
     "iopub.status.busy": "2024-04-02T22:45:14.054327Z",
     "iopub.status.idle": "2024-04-02T22:45:14.062363Z",
     "shell.execute_reply": "2024-04-02T22:45:14.061321Z",
     "shell.execute_reply.started": "2024-04-02T22:45:14.055364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "def slice_sentences(page_sentences, overlap_size, slice_size):\n",
    "    return [page_sentences[i:i + slice_size] for i in range(0, len(page_sentences) - slice_size + 1, slice_size - overlap_size)]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "page_sentences = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "overlap_size = 2\n",
    "slice_size = 3\n",
    "result = slice_sentences(page_sentences, overlap_size, slice_size)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d78c1e6-fac7-4c67-8be1-4a3380158b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:15.548753Z",
     "iopub.status.busy": "2024-04-02T22:45:15.548102Z",
     "iopub.status.idle": "2024-04-02T22:45:15.553067Z",
     "shell.execute_reply": "2024-04-02T22:45:15.552217Z",
     "shell.execute_reply.started": "2024-04-02T22:45:15.548724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on this , splitting texts into size 8 since sizes are divisible by 6 (more or less)\n",
    "# Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
    "# Token_mean , Sentences_mean (642.45, 17.0)\n",
    "# Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
    "# Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
    "# Token_mean , Sentences_mean (1003.2, 18.7)\n",
    "\n",
    "# Keep overlap of 1 sentence default for every 6 sentences\n",
    "def slice_sentences(page_sentences, slice_size=5,overlap_size=1) :\n",
    "    return [page_sentences[i:i + slice_size] for i in range(0, len(page_sentences) - slice_size + 1, slice_size - overlap_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34cc056e-e4b2-41d5-bf11-3800a69177e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:16.814191Z",
     "iopub.status.busy": "2024-04-02T22:45:16.813543Z",
     "iopub.status.idle": "2024-04-02T22:45:16.818592Z",
     "shell.execute_reply": "2024-04-02T22:45:16.817907Z",
     "shell.execute_reply.started": "2024-04-02T22:45:16.814159Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def all_content_sentence_splitter(all_content):\n",
    "    for book in all_content:\n",
    "        for page in tqdm(book):\n",
    "            page[\"sentence_chunks\"] = slice_sentences(page[\"sentences\"],5,1)\n",
    "\n",
    "            page[\"num_chunks\"] = len(page[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d94c8fe-f37b-4b9b-9459-9f78b3b21c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:18.176594Z",
     "iopub.status.busy": "2024-04-02T22:45:18.175446Z",
     "iopub.status.idle": "2024-04-02T22:45:18.232298Z",
     "shell.execute_reply": "2024-04-02T22:45:18.231741Z",
     "shell.execute_reply.started": "2024-04-02T22:45:18.176560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c7ebd12c3b464982456b465c3de67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dad75a225a449fb13a1e44760642a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d594d8009064863b4f4639d3cf99712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3ef143e90344f4a29e706580e4c83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae4d87051e64facba7ebb8c9f059c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_content_sentence_splitter(all_content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05128216-2d66-435a-8080-bd35c3562472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:19.342058Z",
     "iopub.status.busy": "2024-04-02T22:45:19.341703Z",
     "iopub.status.idle": "2024-04-02T22:45:19.351702Z",
     "shell.execute_reply": "2024-04-02T22:45:19.350967Z",
     "shell.execute_reply.started": "2024-04-02T22:45:19.342025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_name': 'Faiss',\n",
       "  'text': 'nearest neighbor search.In NeurIPS 2021 Com-petitions and Demonstrations Track, pages 177–189.PMLR.[Simhadri et al., 2022b] Simhadri, H. V., Williams, G.,Aum¨uller, M., Douze, M., Babenko, A., Baranchuk,D., Chen, Q., Hosseini, L., Krishnaswamny, R.,Srinivasa, G., Subramanya, S. J., and Wang, J.(2022b).Results of the neurips’21 challenge onbillion-scale approximate nearest neighbor search.In Proceedings of the NeurIPS 2021 Competitions andDemonstrations Track, volume 176 of Proceedings ofMachine Learning Research, pages 177–189. PMLR.[Singh et al., 2021] Singh, A., Subramanya, S. J., Kr-ishnaswamy,R.,and Simhadri,H. V. (2021).Freshdiskann: A fast and accurate graph-based annindex for streaming similarity search.[Subramanya et al., 2019] Subramanya,S.J.,Kadekodi, R., Krishaswamy, R., and Simhadri,H. V. (2019). Diskann: Fast accurate billion-pointnearest neighbor search on a single node.InNeurips.[Sun et al., 2023a] Sun, P., Guo, R., and Kumar, S.(2023a). Automating nearest neighbor search con-figuration with constrained optimization.arXivpreprint arXiv:2301.01702.[Sun et al., 2023b] Sun, P., Simcha, D., Dopson, D.,Guo, R., and Kumar, S. (2023b). Soar: Improvedquantization for approximate nearest neighborsearch. In Thirty-seventh Conference on Neural Infor-mation Processing Systems.[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Ser-manet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A. (2015).Goingdeeper with convolutions. In Proceedings of the IEEEconference on computer vision and pattern recognition,pages 1–9.[Tavenard et al., 2011] Tavenard, R., J´egou, H., andAmsaleg, L. (2011). Balancing clusters to reduce re-sponse time variability in large scale image search.In 2011 9th International Workshop on Content-BasedMultimedia Indexing (CBMI), pages 19–24. IEEE.[Thakur et al., 2021] Thakur, N., Reimers, N., R¨uckl´e,A., Srivastava, A., and Gurevych, I. (2021). BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models. In Thirty-fifthConference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 2).[van Luijt and Verhagen, 2020] van Luijt, B. and Ver-hagen, M. (2020).Bringing semantic knowledgegraph technology to your data.IEEE Software,37(2):89–94.[Vardanian, 2022] Vardanian, A. (2022). USearch byUnum Cloud.[Wang et al., 2015] Wang, J., Liu, W., Kumar, S., andChang, S.-F. (2015). Learning to hash for indexingbig data - a survey. Proc. of the IEEE.[Wang et al., 2021] Wang, J., Yi, X., Guo, R., Jin, H.,Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., et al.(2021). Milvus: A purpose-built vector data man-agement system. In Proceedings of the 2021 Interna-tional Conference on Management of Data, pages 2614–2627.[Wang et al., 2017] Wang, J., Zhang, T., Sebe, N., Shen,H. T., et al. (2017). A survey on learning to hash.IEEE transactions on pattern analysis and machine in-telligence, 40(4):769–790.[Weber et al., 1998] Weber, R., Schek, H.-J., and Blott,S. (1998).A quantitative analysis and perfor-mance study for similarity-search methods in high-dimensional spaces.In VLDB, volume 98, pages194–205.21',\n",
       "  'pg_num': 21,\n",
       "  'pg_num_chars': 3133,\n",
       "  'pg_num_words': 408,\n",
       "  'pg_num_sentences': 36,\n",
       "  'pg_num_tokens': 783.25,\n",
       "  'sentences': ['nearest neighbor search.In NeurIPS 2021 Com-petitions and Demonstrations Track, pages 177–189.PMLR.[Simhadri et al., 2022b] Simhadri, H',\n",
       "   'V., Williams, G.,Aum¨uller, M., Douze, M., Babenko, A., Baranchuk,D., Chen, Q., Hosseini, L., Krishnaswamny, R.,Srinivasa, G., Subramanya, S',\n",
       "   'J., and Wang, J.(2022b).Results of the neurips’21 challenge onbillion-scale approximate nearest neighbor search.In Proceedings of the NeurIPS 2021 Competitions andDemonstrations Track, volume 176 of Proceedings ofMachine Learning Research, pages 177–189',\n",
       "   'PMLR.[Singh et al., 2021] Singh, A., Subramanya, S',\n",
       "   'J., Kr-ishnaswamy,R.,and Simhadri,H',\n",
       "   'V',\n",
       "   '(2021).Freshdiskann: A fast and accurate graph-based annindex for streaming similarity search.[Subramanya et al., 2019] Subramanya,S.J.,Kadekodi, R., Krishaswamy, R., and Simhadri,H',\n",
       "   'V',\n",
       "   '(2019)',\n",
       "   'Diskann: Fast accurate billion-pointnearest neighbor search on a single node.InNeurips.[Sun et al., 2023a] Sun, P., Guo, R., and Kumar, S.(2023a)',\n",
       "   'Automating nearest neighbor search con-figuration with constrained optimization.arXivpreprint arXiv:2301.01702.[Sun et al., 2023b] Sun, P., Simcha, D., Dopson, D.,Guo, R., and Kumar, S',\n",
       "   '(2023b)',\n",
       "   'Soar: Improvedquantization for approximate nearest neighborsearch',\n",
       "   'In Thirty-seventh Conference on Neural Infor-mation Processing Systems.[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Ser-manet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A',\n",
       "   '(2015).Goingdeeper with convolutions',\n",
       "   'In Proceedings of the IEEEconference on computer vision and pattern recognition,pages 1–9.[Tavenard et al., 2011] Tavenard, R., J´egou, H., andAmsaleg, L',\n",
       "   '(2011)',\n",
       "   'Balancing clusters to reduce re-sponse time variability in large scale image search.In 2011 9th International Workshop on Content-BasedMultimedia Indexing (CBMI), pages 19–24',\n",
       "   'IEEE.[Thakur et al., 2021] Thakur, N., Reimers, N., R¨uckl´e,A., Srivastava, A., and Gurevych, I',\n",
       "   '(2021)',\n",
       "   'BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models',\n",
       "   'In Thirty-fifthConference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 2).[van Luijt and Verhagen, 2020] van Luijt, B',\n",
       "   'and Ver-hagen, M',\n",
       "   '(2020).Bringing semantic knowledgegraph technology to your data.IEEE Software,37(2):89–94.[Vardanian, 2022] Vardanian, A',\n",
       "   '(2022)',\n",
       "   'USearch byUnum Cloud.[Wang et al., 2015] Wang, J., Liu, W., Kumar, S., andChang, S.-F',\n",
       "   '(2015)',\n",
       "   'Learning to hash for indexingbig data - a survey',\n",
       "   'Proc',\n",
       "   'of the IEEE.[Wang et al., 2021] Wang, J., Yi, X., Guo, R., Jin, H.,Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., et al.(2021)',\n",
       "   'Milvus: A purpose-built vector data man-agement system',\n",
       "   'In Proceedings of the 2021 Interna-tional Conference on Management of Data, pages 2614–2627.[Wang et al., 2017] Wang, J., Zhang, T., Sebe, N., Shen,H',\n",
       "   'T., et al',\n",
       "   '(2017)',\n",
       "   'A survey on learning to hash.IEEE transactions on pattern analysis and machine in-telligence, 40(4):769–790.[Weber et al., 1998] Weber, R., Schek, H.-J., and Blott,S',\n",
       "   '(1998).A quantitative analysis and perfor-mance study for similarity-search methods in high-dimensional spaces.In VLDB, volume 98, pages194–205.21'],\n",
       "  'sentence_chunks': [['nearest neighbor search.In NeurIPS 2021 Com-petitions and Demonstrations Track, pages 177–189.PMLR.[Simhadri et al., 2022b] Simhadri, H',\n",
       "    'V., Williams, G.,Aum¨uller, M., Douze, M., Babenko, A., Baranchuk,D., Chen, Q., Hosseini, L., Krishnaswamny, R.,Srinivasa, G., Subramanya, S',\n",
       "    'J., and Wang, J.(2022b).Results of the neurips’21 challenge onbillion-scale approximate nearest neighbor search.In Proceedings of the NeurIPS 2021 Competitions andDemonstrations Track, volume 176 of Proceedings ofMachine Learning Research, pages 177–189',\n",
       "    'PMLR.[Singh et al., 2021] Singh, A., Subramanya, S',\n",
       "    'J., Kr-ishnaswamy,R.,and Simhadri,H'],\n",
       "   ['J., Kr-ishnaswamy,R.,and Simhadri,H',\n",
       "    'V',\n",
       "    '(2021).Freshdiskann: A fast and accurate graph-based annindex for streaming similarity search.[Subramanya et al., 2019] Subramanya,S.J.,Kadekodi, R., Krishaswamy, R., and Simhadri,H',\n",
       "    'V',\n",
       "    '(2019)'],\n",
       "   ['(2019)',\n",
       "    'Diskann: Fast accurate billion-pointnearest neighbor search on a single node.InNeurips.[Sun et al., 2023a] Sun, P., Guo, R., and Kumar, S.(2023a)',\n",
       "    'Automating nearest neighbor search con-figuration with constrained optimization.arXivpreprint arXiv:2301.01702.[Sun et al., 2023b] Sun, P., Simcha, D., Dopson, D.,Guo, R., and Kumar, S',\n",
       "    '(2023b)',\n",
       "    'Soar: Improvedquantization for approximate nearest neighborsearch'],\n",
       "   ['Soar: Improvedquantization for approximate nearest neighborsearch',\n",
       "    'In Thirty-seventh Conference on Neural Infor-mation Processing Systems.[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Ser-manet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A',\n",
       "    '(2015).Goingdeeper with convolutions',\n",
       "    'In Proceedings of the IEEEconference on computer vision and pattern recognition,pages 1–9.[Tavenard et al., 2011] Tavenard, R., J´egou, H., andAmsaleg, L',\n",
       "    '(2011)'],\n",
       "   ['(2011)',\n",
       "    'Balancing clusters to reduce re-sponse time variability in large scale image search.In 2011 9th International Workshop on Content-BasedMultimedia Indexing (CBMI), pages 19–24',\n",
       "    'IEEE.[Thakur et al., 2021] Thakur, N., Reimers, N., R¨uckl´e,A., Srivastava, A., and Gurevych, I',\n",
       "    '(2021)',\n",
       "    'BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models'],\n",
       "   ['BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models',\n",
       "    'In Thirty-fifthConference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 2).[van Luijt and Verhagen, 2020] van Luijt, B',\n",
       "    'and Ver-hagen, M',\n",
       "    '(2020).Bringing semantic knowledgegraph technology to your data.IEEE Software,37(2):89–94.[Vardanian, 2022] Vardanian, A',\n",
       "    '(2022)'],\n",
       "   ['(2022)',\n",
       "    'USearch byUnum Cloud.[Wang et al., 2015] Wang, J., Liu, W., Kumar, S., andChang, S.-F',\n",
       "    '(2015)',\n",
       "    'Learning to hash for indexingbig data - a survey',\n",
       "    'Proc'],\n",
       "   ['Proc',\n",
       "    'of the IEEE.[Wang et al., 2021] Wang, J., Yi, X., Guo, R., Jin, H.,Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., et al.(2021)',\n",
       "    'Milvus: A purpose-built vector data man-agement system',\n",
       "    'In Proceedings of the 2021 Interna-tional Conference on Management of Data, pages 2614–2627.[Wang et al., 2017] Wang, J., Zhang, T., Sebe, N., Shen,H',\n",
       "    'T., et al']],\n",
       "  'num_chunks': 8},\n",
       " {'doc_name': 'Faiss',\n",
       "  'text': 'THE FAISS LIBRARYMatthijs DouzeFAIR, MetaAlexandr GuzhvaZillizChengqi DengZhejiang UniversityJeff JohnsonFAIR, MetaGergely SzilvasyFAIR, MetaPierre-Emmanuel Mazar´eFAIR, MetaMaria LomeliFAIR, MetaLucas HosseiniSkip LabsHerv´e J´egouKyutaiAbstractVector databases manage large collections of embed-ding vectors. As AI applications are growing rapidly,so are the number of embeddings that need to bestored and indexed. The Faiss library is dedicated tovector similarity search, a core functionality of vectordatabases. Faiss is a toolkit of indexing methods andrelated primitives used to search, cluster, compressand transform vectors. This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing. We benchmark key featuresof the library and discuss a few selected applicationsto highlight its broad applicability.1IntroductionThe emergence of deep learning has induced a shift inhow complex data is stored and searched, noticeablyby the development of embeddings. Embeddings arevector representations, typically produced by a neuralnetwork, whose main objective is to map (embed)the input media item into a vector space, where thelocality encodes the semantics of the input. Embed-dings are extracted from various forms of media:words [Mikolov et al., 2013, Bojanowski et al., 2017],text[Devlin et al., 2018,Izacard et al., 2021],im-ages[Caron et al., 2021,Pizzi et al., 2022],usersanditemsforrecommendation[Paterek, 2007].They can even encode object relations,for in-stance multi-modal text-image or text-audio rela-tions [Duquenne et al., 2023, Radford et al., 2021].Embeddings are employed as an intermediaterepresentationforfurtherprocessing,e.g.self-supervised image embeddings can input to shal-low supervised image classifiers [Caron et al., 2018,Caron et al., 2021].They are also leveraged asa pretext task for self-supervision,e.g. in Sim-CLR [Chen et al., 2020]. The purpose that we considerin this paper is when embeddings are used directlyto compare media items.The embedding extractoris designed such that the distance between embed-dings reflects the similarity between their correspond-ing media. As a result, neighborhood search in thisvector space offers a direct implementation of similar-ity search between media items.Embeddings are popular in industrial setting fortasks where end-to-end learning would not be cost-efficient.For example, a k nearest-neighbor classi-fier is more efficient to upgrade than a classificationdeep neural net. In that case, embeddings are par-ticularly useful as a compact intermediate representa-tion that can be re-used for several purposes. This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years. TheseDBMS are at the junction of traditional databases andApproximate Nearest Neighbor Search (ANNS) algo-rithms. Until recently, the latter were mostly consid-ered for specific use-cases or in research.From a practical point of view, there are multipleadvantages to maintain a clear separation of roles be-tween the embedding extraction and the vector searchalgorithm. Both are bound by an “embedding con-tract” on the embedding distance:• The embedding extractor, which is typically aneural network in modern systems, is trained sothat distances between embeddings are alignedwith the task to perform.• The vector index aims at performing neighborsearch among the embedding vectors as accu-rately as possible w.r.t. exact search results giventhe agreed distance metric.Faiss is an industrial-grade library for ANNS. It isdesigned to be used both from simple scripts and asa building block of a DBMS. In contrast with other li-braries that focus on a single indexing method, Faissis a toolbox that contains indexing methods that com-monly involve a chain of components (preprocessing,compression, non-exhaustive search, etc.). This is nec-essary: depending on the usage constraints, the mostefficient indexing methods are different.Let us also summarize what Faiss is not: Faiss doesnot extract features – it only indexes embeddings thathave been extracted by a different mechanism; Faissis not a service – it only provides functions that are1arXiv:2401.08281v1  [cs.LG]  16 Jan 2024',\n",
       "  'pg_num': 1,\n",
       "  'pg_num_chars': 4338,\n",
       "  'pg_num_words': 577,\n",
       "  'pg_num_sentences': 20,\n",
       "  'pg_num_tokens': 1084.5,\n",
       "  'sentences': ['THE FAISS LIBRARYMatthijs DouzeFAIR, MetaAlexandr GuzhvaZillizChengqi DengZhejiang UniversityJeff JohnsonFAIR, MetaGergely SzilvasyFAIR, MetaPierre-Emmanuel Mazar´eFAIR, MetaMaria LomeliFAIR, MetaLucas HosseiniSkip LabsHerv´e J´egouKyutaiAbstractVector databases manage large collections of embed-ding vectors',\n",
       "   'As AI applications are growing rapidly,so are the number of embeddings that need to bestored and indexed',\n",
       "   'The Faiss library is dedicated tovector similarity search, a core functionality of vectordatabases',\n",
       "   'Faiss is a toolkit of indexing methods andrelated primitives used to search, cluster, compressand transform vectors',\n",
       "   'This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing',\n",
       "   'We benchmark key featuresof the library and discuss a few selected applicationsto highlight its broad applicability.1IntroductionThe emergence of deep learning has induced a shift inhow complex data is stored and searched, noticeablyby the development of embeddings',\n",
       "   'Embeddings arevector representations, typically produced by a neuralnetwork, whose main objective is to map (embed)the input media item into a vector space, where thelocality encodes the semantics of the input',\n",
       "   'Embed-dings are extracted from various forms of media:words [Mikolov et al., 2013, Bojanowski et al., 2017],text[Devlin et al., 2018,Izacard et al., 2021],im-ages[Caron et al., 2021,Pizzi et al., 2022],usersanditemsforrecommendation[Paterek, 2007].They can even encode object relations,for in-stance multi-modal text-image or text-audio rela-tions [Duquenne et al., 2023, Radford et al., 2021].Embeddings are employed as an intermediaterepresentationforfurtherprocessing,e.g.self-supervised image embeddings can input to shal-low supervised image classifiers [Caron et al., 2018,Caron et al., 2021].They are also leveraged asa pretext task for self-supervision,e.g',\n",
       "   'in Sim-CLR [Chen et al., 2020]',\n",
       "   'The purpose that we considerin this paper is when embeddings are used directlyto compare media items.The embedding extractoris designed such that the distance between embed-dings reflects the similarity between their correspond-ing media',\n",
       "   'As a result, neighborhood search in thisvector space offers a direct implementation of similar-ity search between media items.Embeddings are popular in industrial setting fortasks where end-to-end learning would not be cost-efficient.For example, a k nearest-neighbor classi-fier is more efficient to upgrade than a classificationdeep neural net',\n",
       "   'In that case, embeddings are par-ticularly useful as a compact intermediate representa-tion that can be re-used for several purposes',\n",
       "   'This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years',\n",
       "   'TheseDBMS are at the junction of traditional databases andApproximate Nearest Neighbor Search (ANNS) algo-rithms',\n",
       "   'Until recently, the latter were mostly consid-ered for specific use-cases or in research.From a practical point of view, there are multipleadvantages to maintain a clear separation of roles be-tween the embedding extraction and the vector searchalgorithm',\n",
       "   'Both are bound by an “embedding con-tract” on the embedding distance:• The embedding extractor, which is typically aneural network in modern systems, is trained sothat distances between embeddings are alignedwith the task to perform.• The vector index aims at performing neighborsearch among the embedding vectors as accu-rately as possible w.r.t',\n",
       "   'exact search results giventhe agreed distance metric.Faiss is an industrial-grade library for ANNS',\n",
       "   'It isdesigned to be used both from simple scripts and asa building block of a DBMS',\n",
       "   'In contrast with other li-braries that focus on a single indexing method, Faissis a toolbox that contains indexing methods that com-monly involve a chain of components (preprocessing,compression, non-exhaustive search, etc.)',\n",
       "   'This is nec-essary: depending on the usage constraints, the mostefficient indexing methods are different.Let us also summarize what Faiss is not: Faiss doesnot extract features – it only indexes embeddings thathave been extracted by a different mechanism; Faissis not a service – it only provides functions that are1arXiv:2401.08281v1  [cs.LG]  16 Jan 2024'],\n",
       "  'sentence_chunks': [['THE FAISS LIBRARYMatthijs DouzeFAIR, MetaAlexandr GuzhvaZillizChengqi DengZhejiang UniversityJeff JohnsonFAIR, MetaGergely SzilvasyFAIR, MetaPierre-Emmanuel Mazar´eFAIR, MetaMaria LomeliFAIR, MetaLucas HosseiniSkip LabsHerv´e J´egouKyutaiAbstractVector databases manage large collections of embed-ding vectors',\n",
       "    'As AI applications are growing rapidly,so are the number of embeddings that need to bestored and indexed',\n",
       "    'The Faiss library is dedicated tovector similarity search, a core functionality of vectordatabases',\n",
       "    'Faiss is a toolkit of indexing methods andrelated primitives used to search, cluster, compressand transform vectors',\n",
       "    'This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing'],\n",
       "   ['This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing',\n",
       "    'We benchmark key featuresof the library and discuss a few selected applicationsto highlight its broad applicability.1IntroductionThe emergence of deep learning has induced a shift inhow complex data is stored and searched, noticeablyby the development of embeddings',\n",
       "    'Embeddings arevector representations, typically produced by a neuralnetwork, whose main objective is to map (embed)the input media item into a vector space, where thelocality encodes the semantics of the input',\n",
       "    'Embed-dings are extracted from various forms of media:words [Mikolov et al., 2013, Bojanowski et al., 2017],text[Devlin et al., 2018,Izacard et al., 2021],im-ages[Caron et al., 2021,Pizzi et al., 2022],usersanditemsforrecommendation[Paterek, 2007].They can even encode object relations,for in-stance multi-modal text-image or text-audio rela-tions [Duquenne et al., 2023, Radford et al., 2021].Embeddings are employed as an intermediaterepresentationforfurtherprocessing,e.g.self-supervised image embeddings can input to shal-low supervised image classifiers [Caron et al., 2018,Caron et al., 2021].They are also leveraged asa pretext task for self-supervision,e.g',\n",
       "    'in Sim-CLR [Chen et al., 2020]'],\n",
       "   ['in Sim-CLR [Chen et al., 2020]',\n",
       "    'The purpose that we considerin this paper is when embeddings are used directlyto compare media items.The embedding extractoris designed such that the distance between embed-dings reflects the similarity between their correspond-ing media',\n",
       "    'As a result, neighborhood search in thisvector space offers a direct implementation of similar-ity search between media items.Embeddings are popular in industrial setting fortasks where end-to-end learning would not be cost-efficient.For example, a k nearest-neighbor classi-fier is more efficient to upgrade than a classificationdeep neural net',\n",
       "    'In that case, embeddings are par-ticularly useful as a compact intermediate representa-tion that can be re-used for several purposes',\n",
       "    'This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years'],\n",
       "   ['This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years',\n",
       "    'TheseDBMS are at the junction of traditional databases andApproximate Nearest Neighbor Search (ANNS) algo-rithms',\n",
       "    'Until recently, the latter were mostly consid-ered for specific use-cases or in research.From a practical point of view, there are multipleadvantages to maintain a clear separation of roles be-tween the embedding extraction and the vector searchalgorithm',\n",
       "    'Both are bound by an “embedding con-tract” on the embedding distance:• The embedding extractor, which is typically aneural network in modern systems, is trained sothat distances between embeddings are alignedwith the task to perform.• The vector index aims at performing neighborsearch among the embedding vectors as accu-rately as possible w.r.t',\n",
       "    'exact search results giventhe agreed distance metric.Faiss is an industrial-grade library for ANNS']],\n",
       "  'num_chunks': 4},\n",
       " {'doc_name': 'Faiss',\n",
       "  'text': 'lied on Faiss. The engine has since been rewritten.Weaviate [van Luijt and Verhagen, 2020] is a compos-ite retrieval engine that includes vector search.Benchmarksandcompetitions.Theleadingbenchmarkformillion-scaledatasetsisANN-benchmarks[Aum¨uller et al., 2020]thatnowcomparesabout50implementationsofANNS.Thisbenchmarkwasupgradedwiththebig-ANN [Simhadri et al., 2022a] challenge, that includes6 datasets with 1 billion vectors each.Faiss wasused as a baseline for the challenge and multiplesubmissions derived from Faiss. The 2023’s edition ofthe challenge is at a more modest scale (10M vectors)but the tasks are more elaborate. For instance there isa filtered track for which Faiss was a baseline method.DatasetsThe datasets used to evaluate vector searchare typical for the tasks that vector search per-forms.Early datasets are based on keypoint fea-tures like SIFT [Lowe, 2004] used in image match-ing.WeuseBIGANN[J´egou et al., 2011b],adataset of 128-dimensional SIFT features.Later,when global image descriptors produced by neu-ral nets became popular, the Deep1B dataset wasreleased[Babenko and Lempitsky, 2016],with96-dimensional image features extracted with GoogleLeNet [Szegedy et al., 2015]. For this paper we intro-duce a dataset of 768-dimensional Contriever text em-beddings [Izacard et al., 2021] that are compared withinner product similarity. The embeddings are com-puted on English Wikipedia passages. The higher di-mension of these embeddings is typical for contempo-rary applications.Each dataset has 10k query vectors, 20M to 350Mtraining vectors. We indicate the size of the databaseexplicitly, for example “Deep1M” means the databasecontains the 1M first vectors of deep1B. The training,database and query vectors are sampled randomlyfrom the same distribution, we don’t address out-of-distribution data in this paper [Jaiswal et al., 2022,Baranchuk et al., 2023].3Performance axes of a vectorsearch libraryVector search is a well-defined, unambiguous oper-ation.In its simplest formulation, given a set ofdatabase vectors {xi, i = 1..N} ⊂ Rd and a query vec-tor q ∈ Rd, it computesn = argminn=1..N∥q − xn∥(1)This can be computed with a direct algorithm by iter-ating over all database vectors: this is brute force search.A slightly more general and complex operation is tocompute the k nearest neighbors of q:(n1, ..., nk) = k − argminn=1..N∥q − xn∥(2)This is what the search method of a Faiss index re-turns. A related operation is to find all the elementsthat are within some distance ε to the query:R = {n = 1..N s.t. ∥q − xn∥ ≤ ε},(3)which is computed with the range search method.Distance measures.In the equations above, weleave the definition of the distance undefined. Themost commonly used distances in Faiss are the L2 dis-tance, the cosine similarity and the inner product simi-larity (for the latter two the argmin should be replacedwith an argmax). These simple measures have usefulanalytical properties: for example, they are invariantunder d-dimensional rotations.There are many relationships between the mea-sures. They can be made equivalent by preprocess-ing transformations on the query and/or the databasevectors. Table 1 summarizes the preprocessing trans-formations that are applicable for various bridges.Some were already identified [Bachrach et al., 2014,Hong et al., 2019], others are new.Notethatvectorstransformedinthiswayhaveaveryanisotropicdistribu-tion[Morozov and Babenko, 2018]andcanbe“harder” to index. In particular, for product or scalarquantization, the additional dimension incurred formany transformations is not homogeneous with otherdimensions. See Section 4.2 for mitigations.3.1Brute force searchImplementing brute force search efficiently is not triv-ial [Chern et al., 2022, Johnson et al., 2019]. It requires(1) an efficient way of computing the distances and(2) for k-nearest neighbor search, an efficient way ofkeeping track of the k smallest distances.Computing distances in Faiss is performed either bydirect distances computations, or, when query vectorsare provided in large enough batches, using a matrixmultiplicationdecomposition[Johnson et al., 2019,equation 2]. The Faiss functions are exposed in knnand knn gpu for CPU and GPU respectively.Collectingthetop-ksmallestdistancesisusuallydoneviaabinaryheaponCPU[Douze and J´egou, 2014,section2.1]orasortingnetworkonGPU[Johnson et al., 2019,Ootomo et al., 2023]. For larger values of k, it is moreefficient to use a reservoir: an unordered result bufferof size k′ > k that is resized to k when it overflows.Brute-force search gives accurate results. However,for large, high-dimensional datasets this approach be-comes slow. In low dimensions, there are branch-and-bound methods that yield exact search results. How-ever, in large dimensions they provide no speedupover brute force search [Weber et al., 1998].In these cases, we have to resort to approximatenearest neighbor search (ANNS).3',\n",
       "  'pg_num': 3,\n",
       "  'pg_num_chars': 4917,\n",
       "  'pg_num_words': 651,\n",
       "  'pg_num_sentences': 23,\n",
       "  'pg_num_tokens': 1229.25,\n",
       "  'sentences': ['lied on Faiss',\n",
       "   'The engine has since been rewritten.Weaviate [van Luijt and Verhagen, 2020] is a compos-ite retrieval engine that includes vector search.Benchmarksandcompetitions.Theleadingbenchmarkformillion-scaledatasetsisANN-benchmarks[Aum¨uller et al., 2020]thatnowcomparesabout50implementationsofANNS.Thisbenchmarkwasupgradedwiththebig-ANN [Simhadri et al., 2022a] challenge, that includes6 datasets with 1 billion vectors each.Faiss wasused as a baseline for the challenge and multiplesubmissions derived from Faiss',\n",
       "   'The 2023’s edition ofthe challenge is at a more modest scale (10M vectors)but the tasks are more elaborate',\n",
       "   'For instance there isa filtered track for which Faiss was a baseline method.DatasetsThe datasets used to evaluate vector searchare typical for the tasks that vector search per-forms.Early datasets are based on keypoint fea-tures like SIFT [Lowe, 2004] used in image match-ing.WeuseBIGANN[J´egou et al., 2011b],adataset of 128-dimensional SIFT features.Later,when global image descriptors produced by neu-ral nets became popular, the Deep1B dataset wasreleased[Babenko and Lempitsky, 2016],with96-dimensional image features extracted with GoogleLeNet [Szegedy et al., 2015]',\n",
       "   'For this paper we intro-duce a dataset of 768-dimensional Contriever text em-beddings [Izacard et al., 2021] that are compared withinner product similarity',\n",
       "   'The embeddings are com-puted on English Wikipedia passages',\n",
       "   'The higher di-mension of these embeddings is typical for contempo-rary applications.Each dataset has 10k query vectors, 20M to 350Mtraining vectors',\n",
       "   'We indicate the size of the databaseexplicitly, for example “Deep1M” means the databasecontains the 1M first vectors of deep1B',\n",
       "   'The training,database and query vectors are sampled randomlyfrom the same distribution, we don’t address out-of-distribution data in this paper [Jaiswal et al., 2022,Baranchuk et al., 2023].3Performance axes of a vectorsearch libraryVector search is a well-defined, unambiguous oper-ation.In its simplest formulation, given a set ofdatabase vectors {xi, i = 1..N} ⊂ Rd and a query vec-tor q ∈ Rd, it computesn = argminn=1..N∥q − xn∥(1)This can be computed with a direct algorithm by iter-ating over all database vectors: this is brute force search.A slightly more general and complex operation is tocompute the k nearest neighbors of q:(n1, ..., nk) = k − argminn=1..N∥q − xn∥(2)This is what the search method of a Faiss index re-turns',\n",
       "   'A related operation is to find all the elementsthat are within some distance ε to the query:R = {n = 1..N s.t',\n",
       "   '∥q − xn∥ ≤ ε},(3)which is computed with the range search method.Distance measures.In the equations above, weleave the definition of the distance undefined',\n",
       "   'Themost commonly used distances in Faiss are the L2 dis-tance, the cosine similarity and the inner product simi-larity (for the latter two the argmin should be replacedwith an argmax)',\n",
       "   'These simple measures have usefulanalytical properties: for example, they are invariantunder d-dimensional rotations.There are many relationships between the mea-sures',\n",
       "   'They can be made equivalent by preprocess-ing transformations on the query and/or the databasevectors',\n",
       "   'Table 1 summarizes the preprocessing trans-formations that are applicable for various bridges.Some were already identified [Bachrach et al., 2014,Hong et al., 2019], others are new.Notethatvectorstransformedinthiswayhaveaveryanisotropicdistribu-tion[Morozov and Babenko, 2018]andcanbe“harder” to index',\n",
       "   'In particular, for product or scalarquantization, the additional dimension incurred formany transformations is not homogeneous with otherdimensions',\n",
       "   'See Section 4.2 for mitigations.3.1Brute force searchImplementing brute force search efficiently is not triv-ial [Chern et al., 2022, Johnson et al., 2019]',\n",
       "   'It requires(1) an efficient way of computing the distances and(2) for k-nearest neighbor search, an efficient way ofkeeping track of the k smallest distances.Computing distances in Faiss is performed either bydirect distances computations, or, when query vectorsare provided in large enough batches, using a matrixmultiplicationdecomposition[Johnson et al., 2019,equation 2]',\n",
       "   'The Faiss functions are exposed in knnand knn gpu for CPU and GPU respectively.Collectingthetop-ksmallestdistancesisusuallydoneviaabinaryheaponCPU[Douze and J´egou, 2014,section2.1]orasortingnetworkonGPU[Johnson et al., 2019,Ootomo et al., 2023]',\n",
       "   'For larger values of k, it is moreefficient to use a reservoir: an unordered result bufferof size k′ > k that is resized to k when it overflows.Brute-force search gives accurate results',\n",
       "   'However,for large, high-dimensional datasets this approach be-comes slow',\n",
       "   'In low dimensions, there are branch-and-bound methods that yield exact search results',\n",
       "   'How-ever, in large dimensions they provide no speedupover brute force search [Weber et al., 1998].In these cases, we have to resort to approximatenearest neighbor search (ANNS).3'],\n",
       "  'sentence_chunks': [['lied on Faiss',\n",
       "    'The engine has since been rewritten.Weaviate [van Luijt and Verhagen, 2020] is a compos-ite retrieval engine that includes vector search.Benchmarksandcompetitions.Theleadingbenchmarkformillion-scaledatasetsisANN-benchmarks[Aum¨uller et al., 2020]thatnowcomparesabout50implementationsofANNS.Thisbenchmarkwasupgradedwiththebig-ANN [Simhadri et al., 2022a] challenge, that includes6 datasets with 1 billion vectors each.Faiss wasused as a baseline for the challenge and multiplesubmissions derived from Faiss',\n",
       "    'The 2023’s edition ofthe challenge is at a more modest scale (10M vectors)but the tasks are more elaborate',\n",
       "    'For instance there isa filtered track for which Faiss was a baseline method.DatasetsThe datasets used to evaluate vector searchare typical for the tasks that vector search per-forms.Early datasets are based on keypoint fea-tures like SIFT [Lowe, 2004] used in image match-ing.WeuseBIGANN[J´egou et al., 2011b],adataset of 128-dimensional SIFT features.Later,when global image descriptors produced by neu-ral nets became popular, the Deep1B dataset wasreleased[Babenko and Lempitsky, 2016],with96-dimensional image features extracted with GoogleLeNet [Szegedy et al., 2015]',\n",
       "    'For this paper we intro-duce a dataset of 768-dimensional Contriever text em-beddings [Izacard et al., 2021] that are compared withinner product similarity'],\n",
       "   ['For this paper we intro-duce a dataset of 768-dimensional Contriever text em-beddings [Izacard et al., 2021] that are compared withinner product similarity',\n",
       "    'The embeddings are com-puted on English Wikipedia passages',\n",
       "    'The higher di-mension of these embeddings is typical for contempo-rary applications.Each dataset has 10k query vectors, 20M to 350Mtraining vectors',\n",
       "    'We indicate the size of the databaseexplicitly, for example “Deep1M” means the databasecontains the 1M first vectors of deep1B',\n",
       "    'The training,database and query vectors are sampled randomlyfrom the same distribution, we don’t address out-of-distribution data in this paper [Jaiswal et al., 2022,Baranchuk et al., 2023].3Performance axes of a vectorsearch libraryVector search is a well-defined, unambiguous oper-ation.In its simplest formulation, given a set ofdatabase vectors {xi, i = 1..N} ⊂ Rd and a query vec-tor q ∈ Rd, it computesn = argminn=1..N∥q − xn∥(1)This can be computed with a direct algorithm by iter-ating over all database vectors: this is brute force search.A slightly more general and complex operation is tocompute the k nearest neighbors of q:(n1, ..., nk) = k − argminn=1..N∥q − xn∥(2)This is what the search method of a Faiss index re-turns'],\n",
       "   ['The training,database and query vectors are sampled randomlyfrom the same distribution, we don’t address out-of-distribution data in this paper [Jaiswal et al., 2022,Baranchuk et al., 2023].3Performance axes of a vectorsearch libraryVector search is a well-defined, unambiguous oper-ation.In its simplest formulation, given a set ofdatabase vectors {xi, i = 1..N} ⊂ Rd and a query vec-tor q ∈ Rd, it computesn = argminn=1..N∥q − xn∥(1)This can be computed with a direct algorithm by iter-ating over all database vectors: this is brute force search.A slightly more general and complex operation is tocompute the k nearest neighbors of q:(n1, ..., nk) = k − argminn=1..N∥q − xn∥(2)This is what the search method of a Faiss index re-turns',\n",
       "    'A related operation is to find all the elementsthat are within some distance ε to the query:R = {n = 1..N s.t',\n",
       "    '∥q − xn∥ ≤ ε},(3)which is computed with the range search method.Distance measures.In the equations above, weleave the definition of the distance undefined',\n",
       "    'Themost commonly used distances in Faiss are the L2 dis-tance, the cosine similarity and the inner product simi-larity (for the latter two the argmin should be replacedwith an argmax)',\n",
       "    'These simple measures have usefulanalytical properties: for example, they are invariantunder d-dimensional rotations.There are many relationships between the mea-sures'],\n",
       "   ['These simple measures have usefulanalytical properties: for example, they are invariantunder d-dimensional rotations.There are many relationships between the mea-sures',\n",
       "    'They can be made equivalent by preprocess-ing transformations on the query and/or the databasevectors',\n",
       "    'Table 1 summarizes the preprocessing trans-formations that are applicable for various bridges.Some were already identified [Bachrach et al., 2014,Hong et al., 2019], others are new.Notethatvectorstransformedinthiswayhaveaveryanisotropicdistribu-tion[Morozov and Babenko, 2018]andcanbe“harder” to index',\n",
       "    'In particular, for product or scalarquantization, the additional dimension incurred formany transformations is not homogeneous with otherdimensions',\n",
       "    'See Section 4.2 for mitigations.3.1Brute force searchImplementing brute force search efficiently is not triv-ial [Chern et al., 2022, Johnson et al., 2019]'],\n",
       "   ['See Section 4.2 for mitigations.3.1Brute force searchImplementing brute force search efficiently is not triv-ial [Chern et al., 2022, Johnson et al., 2019]',\n",
       "    'It requires(1) an efficient way of computing the distances and(2) for k-nearest neighbor search, an efficient way ofkeeping track of the k smallest distances.Computing distances in Faiss is performed either bydirect distances computations, or, when query vectorsare provided in large enough batches, using a matrixmultiplicationdecomposition[Johnson et al., 2019,equation 2]',\n",
       "    'The Faiss functions are exposed in knnand knn gpu for CPU and GPU respectively.Collectingthetop-ksmallestdistancesisusuallydoneviaabinaryheaponCPU[Douze and J´egou, 2014,section2.1]orasortingnetworkonGPU[Johnson et al., 2019,Ootomo et al., 2023]',\n",
       "    'For larger values of k, it is moreefficient to use a reservoir: an unordered result bufferof size k′ > k that is resized to k when it overflows.Brute-force search gives accurate results',\n",
       "    'However,for large, high-dimensional datasets this approach be-comes slow']],\n",
       "  'num_chunks': 5}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.sample(all_content_[2],k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea2631b-bc9d-4ad5-b32f-b6eb07ec631f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:20.867963Z",
     "iopub.status.busy": "2024-04-02T22:45:20.867532Z",
     "iopub.status.idle": "2024-04-02T22:45:20.893417Z",
     "shell.execute_reply": "2024-04-02T22:45:20.892323Z",
     "shell.execute_reply.started": "2024-04-02T22:45:20.867935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2900.025997</td>\n",
       "      <td>418.400347</td>\n",
       "      <td>32.854419</td>\n",
       "      <td>725.006499</td>\n",
       "      <td>7.608319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>166.709828</td>\n",
       "      <td>1175.894326</td>\n",
       "      <td>155.640269</td>\n",
       "      <td>98.641975</td>\n",
       "      <td>293.973582</td>\n",
       "      <td>24.652779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>2349.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>587.250000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2773.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>693.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>433.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>11555.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>2888.750000</td>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pg_num  pg_num_chars  pg_num_words  pg_num_sentences  \\\n",
       "count  577.000000    577.000000    577.000000        577.000000   \n",
       "mean   289.000000   2900.025997    418.400347         32.854419   \n",
       "std    166.709828   1175.894326    155.640269         98.641975   \n",
       "min      1.000000      0.000000      1.000000          1.000000   \n",
       "25%    145.000000   2349.000000    340.000000         10.000000   \n",
       "50%    289.000000   2773.000000    412.000000         13.000000   \n",
       "75%    433.000000   3232.000000    476.000000         17.000000   \n",
       "max    577.000000  11555.000000   1474.000000        994.000000   \n",
       "\n",
       "       pg_num_tokens  num_chunks  \n",
       "count     577.000000  577.000000  \n",
       "mean      725.006499    7.608319  \n",
       "std       293.973582   24.652779  \n",
       "min         0.000000    0.000000  \n",
       "25%       587.250000    2.000000  \n",
       "50%       693.250000    3.000000  \n",
       "75%       808.000000    4.000000  \n",
       "max      2888.750000  248.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "501fbfcd-2c8e-44bb-90f4-2d0fc3b146fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:22.453217Z",
     "iopub.status.busy": "2024-04-02T22:45:22.452847Z",
     "iopub.status.idle": "2024-04-02T22:45:22.474977Z",
     "shell.execute_reply": "2024-04-02T22:45:22.474069Z",
     "shell.execute_reply.started": "2024-04-02T22:45:22.453186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2569.800000</td>\n",
       "      <td>338.40000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>642.450000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.472136</td>\n",
       "      <td>1084.092853</td>\n",
       "      <td>166.50474</td>\n",
       "      <td>11.814035</td>\n",
       "      <td>271.023213</td>\n",
       "      <td>2.947154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2132.500000</td>\n",
       "      <td>304.50000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>533.125000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3036.000000</td>\n",
       "      <td>383.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>3170.000000</td>\n",
       "      <td>459.00000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>792.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>4203.000000</td>\n",
       "      <td>570.00000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1050.750000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  15.000000     15.000000      15.00000         15.000000      15.000000   \n",
       "mean    8.000000   2569.800000     338.40000         17.000000     642.450000   \n",
       "std     4.472136   1084.092853     166.50474         11.814035     271.023213   \n",
       "min     1.000000    702.000000      45.00000          3.000000     175.500000   \n",
       "25%     4.500000   2132.500000     304.50000         12.000000     533.125000   \n",
       "50%     8.000000   3036.000000     383.00000         15.000000     759.000000   \n",
       "75%    11.500000   3170.000000     459.00000         18.500000     792.500000   \n",
       "max    15.000000   4203.000000     570.00000         43.000000    1050.750000   \n",
       "\n",
       "       num_chunks  \n",
       "count   15.000000  \n",
       "mean     3.600000  \n",
       "std      2.947154  \n",
       "min      0.000000  \n",
       "25%      2.500000  \n",
       "50%      3.000000  \n",
       "75%      4.000000  \n",
       "max     10.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[1]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79a8345-70f0-427a-a1cb-22b30d1dcfdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:23.760265Z",
     "iopub.status.busy": "2024-04-02T22:45:23.758542Z",
     "iopub.status.idle": "2024-04-02T22:45:23.779973Z",
     "shell.execute_reply": "2024-04-02T22:45:23.779282Z",
     "shell.execute_reply.started": "2024-04-02T22:45:23.760224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4713.047619</td>\n",
       "      <td>651.142857</td>\n",
       "      <td>26.857143</td>\n",
       "      <td>1178.261905</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.204837</td>\n",
       "      <td>600.454701</td>\n",
       "      <td>98.317997</td>\n",
       "      <td>14.118377</td>\n",
       "      <td>150.113675</td>\n",
       "      <td>3.507136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3133.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>783.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1105.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4792.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>5049.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1262.250000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>5733.000000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1433.250000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  21.000000     21.000000     21.000000         21.000000      21.000000   \n",
       "mean   11.000000   4713.047619    651.142857         26.857143    1178.261905   \n",
       "std     6.204837    600.454701     98.317997         14.118377     150.113675   \n",
       "min     1.000000   3133.000000    408.000000         13.000000     783.250000   \n",
       "25%     6.000000   4422.000000    592.000000         19.000000    1105.500000   \n",
       "50%    11.000000   4792.000000    651.000000         23.000000    1198.000000   \n",
       "75%    16.000000   5049.000000    716.000000         24.000000    1262.250000   \n",
       "max    21.000000   5733.000000    806.000000         63.000000    1433.250000   \n",
       "\n",
       "       num_chunks  \n",
       "count   21.000000  \n",
       "mean     6.000000  \n",
       "std      3.507136  \n",
       "min      3.000000  \n",
       "25%      4.000000  \n",
       "50%      5.000000  \n",
       "75%      5.000000  \n",
       "max     15.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[2]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5e3a14d-6873-420f-a0cd-46e5472cd92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:25.038920Z",
     "iopub.status.busy": "2024-04-02T22:45:25.038209Z",
     "iopub.status.idle": "2024-04-02T22:45:25.059740Z",
     "shell.execute_reply": "2024-04-02T22:45:25.058793Z",
     "shell.execute_reply.started": "2024-04-02T22:45:25.038889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>2324.854839</td>\n",
       "      <td>294.064516</td>\n",
       "      <td>11.983871</td>\n",
       "      <td>581.213710</td>\n",
       "      <td>2.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.041619</td>\n",
       "      <td>1125.285987</td>\n",
       "      <td>150.230192</td>\n",
       "      <td>8.864170</td>\n",
       "      <td>281.321497</td>\n",
       "      <td>2.236423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.250000</td>\n",
       "      <td>1292.250000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>323.062500</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>2419.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>604.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.750000</td>\n",
       "      <td>3361.000000</td>\n",
       "      <td>413.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>840.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>4105.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1026.250000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  62.000000     62.000000     62.000000         62.000000      62.000000   \n",
       "mean   31.500000   2324.854839    294.064516         11.983871     581.213710   \n",
       "std    18.041619   1125.285987    150.230192          8.864170     281.321497   \n",
       "min     1.000000    587.000000     87.000000          1.000000     146.750000   \n",
       "25%    16.250000   1292.250000    125.500000          4.250000     323.062500   \n",
       "50%    31.500000   2419.000000    329.000000         11.000000     604.750000   \n",
       "75%    46.750000   3361.000000    413.750000         17.000000     840.250000   \n",
       "max    62.000000   4105.000000    559.000000         36.000000    1026.250000   \n",
       "\n",
       "       num_chunks  \n",
       "count   62.000000  \n",
       "mean     2.419355  \n",
       "std      2.236423  \n",
       "min      0.000000  \n",
       "25%      0.250000  \n",
       "50%      2.000000  \n",
       "75%      4.000000  \n",
       "max      8.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[3]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307ae1cd-6aa0-4cc8-9efd-fb3f1db3811e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:29.898042Z",
     "iopub.status.busy": "2024-04-02T22:45:29.897663Z",
     "iopub.status.idle": "2024-04-02T22:45:29.905237Z",
     "shell.execute_reply": "2024-04-02T22:45:29.904262Z",
     "shell.execute_reply.started": "2024-04-02T22:45:29.898010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the sentence_chunks into it's own individual chunks to reduce size further.\n",
    "import re\n",
    "all_pdf_formatted = []\n",
    "def final_chunk_dict(all_content, all_pdf_formatted):\n",
    "    for doc in tqdm(all_content):\n",
    "        for page in doc:\n",
    "            for sentence_chunk in page[\"sentence_chunks\"]:\n",
    "                chunk_ = {}\n",
    "                chunk_[\"pg_num\"] = page[\"pg_num\"]\n",
    "                # Join sentences like a paragraph structure\n",
    "                joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "                joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # spacing issue after join.\n",
    "                chunk_[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "                #write metadata\n",
    "                chunk_[\"chunk_num_chars\"] = len(joined_sentence_chunk)\n",
    "                chunk_[\"chunk_num_tokens\"] = len(joined_sentence_chunk) / 4\n",
    "                chunk_[\"chunk_num_words\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "                chunk_[\"doc_name\"] = page[\"doc_name\"]\n",
    "                all_pdf_formatted.append(chunk_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ddfa4b0-a5c3-48c7-aede-27464f121c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:31.373737Z",
     "iopub.status.busy": "2024-04-02T22:45:31.373043Z",
     "iopub.status.idle": "2024-04-02T22:45:31.450427Z",
     "shell.execute_reply": "2024-04-02T22:45:31.449674Z",
     "shell.execute_reply.started": "2024-04-02T22:45:31.373707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6d0f6308124046be8271615391b2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_chunk_dict(all_content_, all_pdf_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cfa6892-493c-4473-bd53-9d1ad33c9ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:53.807859Z",
     "iopub.status.busy": "2024-04-02T22:45:53.807482Z",
     "iopub.status.idle": "2024-04-02T22:45:53.813986Z",
     "shell.execute_reply": "2024-04-02T22:45:53.813093Z",
     "shell.execute_reply.started": "2024-04-02T22:45:53.807828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pg_num': 2,\n",
       "  'sentence_chunk': 'We refer thereader the early survey by [Wang et al., 2015] for re-search on binary codes. Since the work by [J´egou et al., 2010], ANN basedon quantization has emerged as a powerful alter-native to binary codes [Wang et al., 2017]. We re-fer the reader to the survey by [Matsui et al., 2018]that discusses numerous research works related toquantization-based compact codes.1https://github.com/facebookresearch/faiss2https://faiss.ai/LSH is also often referring to indexing with mul-tiple partitions, such as E2LSH [Datar et al., 2004]. We do no consider them because they are notperforming as well as learned partitions on realdata [Paulev´e et al., 2010]. Early data-aware meth-ods that proved successful on large datasets includemultiple partitions based on kd-tree or hierarchical k-means in [Muja and Lowe, 2014]They are often com-bined with compressed-domain representation andare especially appropriate for very large-scale set-tings [Jegou et al., 2008, J´egou et al., 2010]. After the introduction of the NN-descent algo-rithm [Dong et al., 2011], ANN algorithms based ongraphs have emerged as a viable alternative to meth-ods based on space partitioning. In particularHNSW, which is the most popular current indexingmethod [Malkov and Yashunin, 2018] for medium-sized dataset is implemented in HNSWlib. Software packages. Most of the research works onvector search were open-sourced, and some of theseevolved in relatively comprehensive software pack-ages for vector searchFLANN includes several in-dex types and a distributed implementation describedextensively in the paper [Muja and Lowe, 2014]Thefirst implementation of product quantization reliedon the Yael library [Douze and J´egou, 2014], that al-ready had a few of the Faiss principles:opti-mized primitives for clustering methods (GMM andk-means), scripting language interface (Matlab andPython) and benchmarking operators. The NM-Slib package, intended for text retrieval was thefirst package to include HNSW [Boytsov et al., 2016]and also offers several index types. The HNSWliblibrary later became the reference implementationof HNSW [Malkov and Yashunin, 2018]. Google’sSCANN library is mainly a thoroughly optimized im-plementation of IVFPQ [J´egou et al., 2010] on SIMDand includes several index variants for variousdatabase scalesSCANN was open-sourced togetherwith the paper [Guo et al., 2020], which does not de-scribe what makes the library so fast: its engineer-ing optimization',\n",
       "  'chunk_num_chars': 2458,\n",
       "  'chunk_num_tokens': 614.5,\n",
       "  'chunk_num_words': 339,\n",
       "  'doc_name': 'Faiss'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_pdf_formatted,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c23de83b-4b7b-4101-b314-77b702494f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:58.898463Z",
     "iopub.status.busy": "2024-04-02T22:45:58.898119Z",
     "iopub.status.idle": "2024-04-02T22:45:58.909823Z",
     "shell.execute_reply": "2024-04-02T22:45:58.909044Z",
     "shell.execute_reply.started": "2024-04-02T22:45:58.898436Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = pd.DataFrame(all_pdf_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8c02a5a-9cec-4932-bedb-880c7d12f996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:45:59.893102Z",
     "iopub.status.busy": "2024-04-02T22:45:59.892353Z",
     "iopub.status.idle": "2024-04-02T22:45:59.911876Z",
     "shell.execute_reply": "2024-04-02T22:45:59.910877Z",
     "shell.execute_reply.started": "2024-04-02T22:45:59.893091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>273.468599</td>\n",
       "      <td>417.125814</td>\n",
       "      <td>104.281453</td>\n",
       "      <td>58.060912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>245.631995</td>\n",
       "      <td>545.919045</td>\n",
       "      <td>136.479761</td>\n",
       "      <td>76.180003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>257.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>189.500000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  4761.000000      4761.000000       4761.000000      4761.000000\n",
       "mean    273.468599       417.125814        104.281453        58.060912\n",
       "std     245.631995       545.919045        136.479761        76.180003\n",
       "min       1.000000         0.000000          0.000000         1.000000\n",
       "25%       7.000000        27.000000          6.750000         3.000000\n",
       "50%     257.000000       134.000000         33.500000        15.000000\n",
       "75%     548.000000       758.000000        189.500000       109.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ccb5bd-4d6a-4a8d-9498-dd215852e5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:03.529960Z",
     "iopub.status.busy": "2024-04-02T22:46:03.529106Z",
     "iopub.status.idle": "2024-04-02T22:46:03.535641Z",
     "shell.execute_reply": "2024-04-02T22:46:03.534778Z",
     "shell.execute_reply.started": "2024-04-02T22:46:03.529925Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = all_pdf_formatted_df[all_pdf_formatted_df['chunk_num_tokens'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c257ff8-57f3-4d3f-b73b-3ba09ac70d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:05.636256Z",
     "iopub.status.busy": "2024-04-02T22:46:05.635272Z",
     "iopub.status.idle": "2024-04-02T22:46:05.651043Z",
     "shell.execute_reply": "2024-04-02T22:46:05.650170Z",
     "shell.execute_reply.started": "2024-04-02T22:46:05.636223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "      <th>doc_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>51</td>\n",
       "      <td>It was my first time in the Big Apple, and I h...</td>\n",
       "      <td>351</td>\n",
       "      <td>87.75</td>\n",
       "      <td>70</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>51</td>\n",
       "      <td>Iloved running around and playing fetchWe also...</td>\n",
       "      <td>321</td>\n",
       "      <td>80.25</td>\n",
       "      <td>55</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>52</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>704</td>\n",
       "      <td>176.00</td>\n",
       "      <td>107</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>53</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>347</td>\n",
       "      <td>86.75</td>\n",
       "      <td>61</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>53</td>\n",
       "      <td>The roots of this equation are 𝑥1 = 5 and𝑥2 = ...</td>\n",
       "      <td>353</td>\n",
       "      <td>88.25</td>\n",
       "      <td>59</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>53</td>\n",
       "      <td>The model shows good understanding of the task...</td>\n",
       "      <td>472</td>\n",
       "      <td>118.00</td>\n",
       "      <td>69</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>54</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>687</td>\n",
       "      <td>171.75</td>\n",
       "      <td>109</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>57</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>398</td>\n",
       "      <td>99.50</td>\n",
       "      <td>62</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>60</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>2132</td>\n",
       "      <td>533.00</td>\n",
       "      <td>345</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>62</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>627</td>\n",
       "      <td>156.75</td>\n",
       "      <td>94</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>1</td>\n",
       "      <td>BART: Denoising Sequence-to-Sequence Pre-train...</td>\n",
       "      <td>2061</td>\n",
       "      <td>515.25</td>\n",
       "      <td>268</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>1</td>\n",
       "      <td>Wealso report ablation experiments that replic...</td>\n",
       "      <td>1360</td>\n",
       "      <td>340.00</td>\n",
       "      <td>186</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>1</td>\n",
       "      <td>BART is a denoising autoencoder builtwith a se...</td>\n",
       "      <td>1733</td>\n",
       "      <td>433.25</td>\n",
       "      <td>244</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>2</td>\n",
       "      <td>Bidirectional EncoderA _ C _ E B    D  (a) BER...</td>\n",
       "      <td>1504</td>\n",
       "      <td>376.00</td>\n",
       "      <td>229</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>2</td>\n",
       "      <td>The corrupted document (left) is encoded witha...</td>\n",
       "      <td>2180</td>\n",
       "      <td>545.00</td>\n",
       "      <td>306</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>2</td>\n",
       "      <td>The architecture is closely related to that us...</td>\n",
       "      <td>1362</td>\n",
       "      <td>340.50</td>\n",
       "      <td>184</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>3</td>\n",
       "      <td>D _ E . A _C _ E . C D E A BDocument RotationT...</td>\n",
       "      <td>188</td>\n",
       "      <td>47.00</td>\n",
       "      <td>35</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>3</td>\n",
       "      <td>A B C . Sentence PermutationFigure 2: Transfor...</td>\n",
       "      <td>904</td>\n",
       "      <td>226.00</td>\n",
       "      <td>134</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>3</td>\n",
       "      <td>Text inﬁll-ing teaches the model to predict ho...</td>\n",
       "      <td>1756</td>\n",
       "      <td>439.00</td>\n",
       "      <td>245</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>3</td>\n",
       "      <td>Here, the encoder in-put is the input sequence...</td>\n",
       "      <td>1059</td>\n",
       "      <td>264.75</td>\n",
       "      <td>154</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>3</td>\n",
       "      <td>The new encoder can use aseparate vocabulary f...</td>\n",
       "      <td>1127</td>\n",
       "      <td>281.75</td>\n",
       "      <td>157</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>4</td>\n",
       "      <td>Pre-trained DecoderPre-trained EncoderlabelA B...</td>\n",
       "      <td>1186</td>\n",
       "      <td>296.50</td>\n",
       "      <td>175</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>4</td>\n",
       "      <td>For refer-ence, we compare our implementations...</td>\n",
       "      <td>2187</td>\n",
       "      <td>546.75</td>\n",
       "      <td>317</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>4</td>\n",
       "      <td>We ﬁnd the former works better for BARTmodels,...</td>\n",
       "      <td>1398</td>\n",
       "      <td>349.50</td>\n",
       "      <td>198</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>5</td>\n",
       "      <td>ModelSQuAD 1.1MNLIELI5XSumConvAI2CNN/DMF1AccPP...</td>\n",
       "      <td>1343</td>\n",
       "      <td>335.75</td>\n",
       "      <td>129</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>5</td>\n",
       "      <td>Performance varies considerably across tasks, ...</td>\n",
       "      <td>1689</td>\n",
       "      <td>422.25</td>\n",
       "      <td>209</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>5</td>\n",
       "      <td>Some of this dif-ference is likely due to not ...</td>\n",
       "      <td>1291</td>\n",
       "      <td>322.75</td>\n",
       "      <td>187</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>6</td>\n",
       "      <td>SQuAD 1.1SQuAD 2.0MNLISSTQQPQNLISTS-BRTEMRPCCo...</td>\n",
       "      <td>1860</td>\n",
       "      <td>465.00</td>\n",
       "      <td>186</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>6</td>\n",
       "      <td>We use the same pre-training data as Liu et al...</td>\n",
       "      <td>1684</td>\n",
       "      <td>421.00</td>\n",
       "      <td>223</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>6</td>\n",
       "      <td>During generation, we set beam size as 5,remov...</td>\n",
       "      <td>1315</td>\n",
       "      <td>328.75</td>\n",
       "      <td>162</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>7</td>\n",
       "      <td>ELI5R1R2RLBest Extractive23.53.117.5Language M...</td>\n",
       "      <td>925</td>\n",
       "      <td>231.25</td>\n",
       "      <td>98</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>7</td>\n",
       "      <td>We ﬁnd BART outperforms the best pre-vious wor...</td>\n",
       "      <td>1841</td>\n",
       "      <td>460.25</td>\n",
       "      <td>246</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>7</td>\n",
       "      <td>However, model output is also highly ab-stract...</td>\n",
       "      <td>974</td>\n",
       "      <td>243.50</td>\n",
       "      <td>129</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>7</td>\n",
       "      <td>GPT (Radford et al., 2018) only models left-wa...</td>\n",
       "      <td>919</td>\n",
       "      <td>229.75</td>\n",
       "      <td>128</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>7</td>\n",
       "      <td>Predictions are not made auto-regressively, re...</td>\n",
       "      <td>712</td>\n",
       "      <td>178.00</td>\n",
       "      <td>101</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>8</td>\n",
       "      <td>Source Document (abbreviated)BART SummaryThe r...</td>\n",
       "      <td>1245</td>\n",
       "      <td>311.25</td>\n",
       "      <td>188</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>8</td>\n",
       "      <td>He said, “I hope that Anne Sacoolas will come ...</td>\n",
       "      <td>979</td>\n",
       "      <td>244.75</td>\n",
       "      <td>146</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>8</td>\n",
       "      <td>On Wednesday, Turkey began a militaryoffensive...</td>\n",
       "      <td>808</td>\n",
       "      <td>202.00</td>\n",
       "      <td>121</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>8</td>\n",
       "      <td>It was an event speciﬁcally designed tohelp Ki...</td>\n",
       "      <td>789</td>\n",
       "      <td>197.25</td>\n",
       "      <td>117</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>8</td>\n",
       "      <td>Summaries combine information from across the ...</td>\n",
       "      <td>1079</td>\n",
       "      <td>269.75</td>\n",
       "      <td>139</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>9</td>\n",
       "      <td>ReferencesEneko Agirre, Llu’is M‘arquez, and R...</td>\n",
       "      <td>643</td>\n",
       "      <td>160.75</td>\n",
       "      <td>69</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>9</td>\n",
       "      <td>Springer, 2006. Jacob Devlin, Ming-Wei Chang, ...</td>\n",
       "      <td>788</td>\n",
       "      <td>197.00</td>\n",
       "      <td>85</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>9</td>\n",
       "      <td>doi: 10.18653/v1/N19-1423. URL https://www.acl...</td>\n",
       "      <td>833</td>\n",
       "      <td>208.25</td>\n",
       "      <td>92</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>9</td>\n",
       "      <td>arXiv preprint arXiv:1905.03197, 2019. Sergey ...</td>\n",
       "      <td>693</td>\n",
       "      <td>173.25</td>\n",
       "      <td>82</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>9</td>\n",
       "      <td>Gaussian error lin-ear units (gelus)arXiv prep...</td>\n",
       "      <td>385</td>\n",
       "      <td>96.25</td>\n",
       "      <td>45</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>9</td>\n",
       "      <td>1693–1701, 2015. Mandar Joshi, Danqi Chen, Yin...</td>\n",
       "      <td>617</td>\n",
       "      <td>154.25</td>\n",
       "      <td>70</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>9</td>\n",
       "      <td>The Winograd schema challengeIn AAAISpring Sym...</td>\n",
       "      <td>895</td>\n",
       "      <td>223.75</td>\n",
       "      <td>103</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>9</td>\n",
       "      <td>Efﬁcient estimation of word representationsin ...</td>\n",
       "      <td>917</td>\n",
       "      <td>229.25</td>\n",
       "      <td>86</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>10</td>\n",
       "      <td>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyr...</td>\n",
       "      <td>1131</td>\n",
       "      <td>282.75</td>\n",
       "      <td>134</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4760</th>\n",
       "      <td>10</td>\n",
       "      <td>In Advances in neural information processingsy...</td>\n",
       "      <td>703</td>\n",
       "      <td>175.75</td>\n",
       "      <td>79</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pg_num                                     sentence_chunk  \\\n",
       "4710      51  It was my first time in the Big Apple, and I h...   \n",
       "4711      51  Iloved running around and playing fetchWe also...   \n",
       "4712      52  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4713      53  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4714      53  The roots of this equation are 𝑥1 = 5 and𝑥2 = ...   \n",
       "4715      53  The model shows good understanding of the task...   \n",
       "4716      54  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4717      57  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4718      60  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4719      62  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4720       1  BART: Denoising Sequence-to-Sequence Pre-train...   \n",
       "4721       1  Wealso report ablation experiments that replic...   \n",
       "4722       1  BART is a denoising autoencoder builtwith a se...   \n",
       "4723       2  Bidirectional EncoderA _ C _ E B    D  (a) BER...   \n",
       "4724       2  The corrupted document (left) is encoded witha...   \n",
       "4725       2  The architecture is closely related to that us...   \n",
       "4727       3  D _ E . A _C _ E . C D E A BDocument RotationT...   \n",
       "4728       3  A B C . Sentence PermutationFigure 2: Transfor...   \n",
       "4729       3  Text inﬁll-ing teaches the model to predict ho...   \n",
       "4730       3  Here, the encoder in-put is the input sequence...   \n",
       "4731       3  The new encoder can use aseparate vocabulary f...   \n",
       "4732       4  Pre-trained DecoderPre-trained EncoderlabelA B...   \n",
       "4733       4  For refer-ence, we compare our implementations...   \n",
       "4734       4  We ﬁnd the former works better for BARTmodels,...   \n",
       "4735       5  ModelSQuAD 1.1MNLIELI5XSumConvAI2CNN/DMF1AccPP...   \n",
       "4736       5  Performance varies considerably across tasks, ...   \n",
       "4737       5  Some of this dif-ference is likely due to not ...   \n",
       "4738       6  SQuAD 1.1SQuAD 2.0MNLISSTQQPQNLISTS-BRTEMRPCCo...   \n",
       "4739       6  We use the same pre-training data as Liu et al...   \n",
       "4740       6  During generation, we set beam size as 5,remov...   \n",
       "4741       7  ELI5R1R2RLBest Extractive23.53.117.5Language M...   \n",
       "4742       7  We ﬁnd BART outperforms the best pre-vious wor...   \n",
       "4743       7  However, model output is also highly ab-stract...   \n",
       "4744       7  GPT (Radford et al., 2018) only models left-wa...   \n",
       "4745       7  Predictions are not made auto-regressively, re...   \n",
       "4746       8  Source Document (abbreviated)BART SummaryThe r...   \n",
       "4747       8  He said, “I hope that Anne Sacoolas will come ...   \n",
       "4748       8  On Wednesday, Turkey began a militaryoffensive...   \n",
       "4749       8  It was an event speciﬁcally designed tohelp Ki...   \n",
       "4750       8  Summaries combine information from across the ...   \n",
       "4751       9  ReferencesEneko Agirre, Llu’is M‘arquez, and R...   \n",
       "4752       9  Springer, 2006. Jacob Devlin, Ming-Wei Chang, ...   \n",
       "4753       9  doi: 10.18653/v1/N19-1423. URL https://www.acl...   \n",
       "4754       9  arXiv preprint arXiv:1905.03197, 2019. Sergey ...   \n",
       "4755       9  Gaussian error lin-ear units (gelus)arXiv prep...   \n",
       "4756       9  1693–1701, 2015. Mandar Joshi, Danqi Chen, Yin...   \n",
       "4757       9  The Winograd schema challengeIn AAAISpring Sym...   \n",
       "4758       9  Efﬁcient estimation of word representationsin ...   \n",
       "4759      10  Pranav Rajpurkar, Jian Zhang, Konstantin Lopyr...   \n",
       "4760      10  In Advances in neural information processingsy...   \n",
       "\n",
       "      chunk_num_chars  chunk_num_tokens  chunk_num_words      doc_name  \n",
       "4710              351             87.75               70  Gemini_paper  \n",
       "4711              321             80.25               55  Gemini_paper  \n",
       "4712              704            176.00              107  Gemini_paper  \n",
       "4713              347             86.75               61  Gemini_paper  \n",
       "4714              353             88.25               59  Gemini_paper  \n",
       "4715              472            118.00               69  Gemini_paper  \n",
       "4716              687            171.75              109  Gemini_paper  \n",
       "4717              398             99.50               62  Gemini_paper  \n",
       "4718             2132            533.00              345  Gemini_paper  \n",
       "4719              627            156.75               94  Gemini_paper  \n",
       "4720             2061            515.25              268          BART  \n",
       "4721             1360            340.00              186          BART  \n",
       "4722             1733            433.25              244          BART  \n",
       "4723             1504            376.00              229          BART  \n",
       "4724             2180            545.00              306          BART  \n",
       "4725             1362            340.50              184          BART  \n",
       "4727              188             47.00               35          BART  \n",
       "4728              904            226.00              134          BART  \n",
       "4729             1756            439.00              245          BART  \n",
       "4730             1059            264.75              154          BART  \n",
       "4731             1127            281.75              157          BART  \n",
       "4732             1186            296.50              175          BART  \n",
       "4733             2187            546.75              317          BART  \n",
       "4734             1398            349.50              198          BART  \n",
       "4735             1343            335.75              129          BART  \n",
       "4736             1689            422.25              209          BART  \n",
       "4737             1291            322.75              187          BART  \n",
       "4738             1860            465.00              186          BART  \n",
       "4739             1684            421.00              223          BART  \n",
       "4740             1315            328.75              162          BART  \n",
       "4741              925            231.25               98          BART  \n",
       "4742             1841            460.25              246          BART  \n",
       "4743              974            243.50              129          BART  \n",
       "4744              919            229.75              128          BART  \n",
       "4745              712            178.00              101          BART  \n",
       "4746             1245            311.25              188          BART  \n",
       "4747              979            244.75              146          BART  \n",
       "4748              808            202.00              121          BART  \n",
       "4749              789            197.25              117          BART  \n",
       "4750             1079            269.75              139          BART  \n",
       "4751              643            160.75               69          BART  \n",
       "4752              788            197.00               85          BART  \n",
       "4753              833            208.25               92          BART  \n",
       "4754              693            173.25               82          BART  \n",
       "4755              385             96.25               45          BART  \n",
       "4756              617            154.25               70          BART  \n",
       "4757              895            223.75              103          BART  \n",
       "4758              917            229.25               86          BART  \n",
       "4759             1131            282.75              134          BART  \n",
       "4760              703            175.75               79          BART  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e89eddc-7e15-42e2-84e3-bede788e2097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:11.232841Z",
     "iopub.status.busy": "2024-04-02T22:46:11.231999Z",
     "iopub.status.idle": "2024-04-02T22:46:11.249960Z",
     "shell.execute_reply": "2024-04-02T22:46:11.249108Z",
     "shell.execute_reply.started": "2024-04-02T22:46:11.232808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dece0490-ecdd-4d8a-bfc8-061c0e893619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:15.758822Z",
     "iopub.status.busy": "2024-04-02T22:46:15.758420Z",
     "iopub.status.idle": "2024-04-02T22:46:15.767408Z",
     "shell.execute_reply": "2024-04-02T22:46:15.766201Z",
     "shell.execute_reply.started": "2024-04-02T22:46:15.758740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n",
      "979\n",
      "398CHAPTER 18•DEPENDENCY PARSINGleading to a parse for the following example. Book me the morningﬂightiobjobjdetcompoundroot(18.7)Let’s consider the state of the conﬁguration at Step 2, after the word me has beenpushed onto the stack. StackWord ListRelations[root, book, me] [the, morning, ﬂight]The correct operator to apply here is RIGHTARC which assigns book as the head ofme and pops me from the stack resulting in the following conﬁguration. StackWord ListRelations[root, book] [the, morning, ﬂight] (book → me)After several subsequent applications of the SHIFT and LEFTARC operators, the con-ﬁguration in Step 6 looks like the following:StackWord ListRelations[root, book, the, morning, ﬂight][](book → me)Here, all the remaining words have been passed onto the stack and all that is leftto do is to apply the appropriate reduce operatorsIn the current conﬁguration, weemploy the LEFTARC operator resulting in the following state. StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.\n",
      "234.0\n",
      "\n",
      "StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.\n"
     ]
    }
   ],
   "source": [
    "# Using only 1 step for reducing max_tokens\n",
    "# Optimize later using recursion , if max_tokens_length still greater than 384\n",
    "# Testing:\n",
    "\n",
    "sample = {'pg_num': 406,\n",
    "  'sentence_chunk': '398CHAPTER 18•DEPENDENCY PARSINGleading to a parse for the following example. Book me the morningﬂightiobjobjdetcompoundroot(18.7)Let’s consider the state of the conﬁguration at Step 2, after the word me has beenpushed onto the stack. StackWord ListRelations[root, book, me] [the, morning, ﬂight]The correct operator to apply here is RIGHTARC which assigns book as the head ofme and pops me from the stack resulting in the following conﬁguration. StackWord ListRelations[root, book] [the, morning, ﬂight] (book → me)After several subsequent applications of the SHIFT and LEFTARC operators, the con-ﬁguration in Step 6 looks like the following:StackWord ListRelations[root, book, the, morning, ﬂight][](book → me)Here, all the remaining words have been passed onto the stack and all that is leftto do is to apply the appropriate reduce operatorsIn the current conﬁguration, weemploy the LEFTARC operator resulting in the following state. StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.',\n",
    "  'chunk_num_chars': 1959,\n",
    "  'chunk_num_tokens': 489.75,\n",
    "  'chunk_num_words': 286,\n",
    "  'doc_name': 'Standford NLP'}\n",
    "\n",
    "\n",
    "\n",
    "length_chunk = len(sample['sentence_chunk'])\n",
    "print(length_chunk//2)\n",
    "# Split it into two\n",
    "\n",
    "midpoint = length_chunk // 2\n",
    "print(midpoint)\n",
    "# Find the last period before the midpoint\n",
    "split_point = sample['sentence_chunk'].rfind('. ', 0, midpoint)\n",
    "\n",
    "# Split the text into two parts\n",
    "first_half = sample['sentence_chunk'][:split_point+1]  # +1 to include the period\n",
    "second_half = sample['sentence_chunk'][split_point+2:]  # +2 to skip the period and space\n",
    "\n",
    "print(sample['sentence_chunk'])\n",
    "print(len(first_half)/4)\n",
    "print()\n",
    "print(second_half)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9534e519-4357-4938-9f88-f0235e1eb5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:17.458711Z",
     "iopub.status.busy": "2024-04-02T22:46:17.457899Z",
     "iopub.status.idle": "2024-04-02T22:46:17.466391Z",
     "shell.execute_reply": "2024-04-02T22:46:17.465676Z",
     "shell.execute_reply.started": "2024-04-02T22:46:17.458681Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Optimize later using recursion , if max_tokens_length still greater than 384.\n",
    "# For now just using 1/2 the length\n",
    "# Rectifying the max_length tokens\n",
    "def check_and_rectify_token_length(docs_df):\n",
    "    # 384 is the max_token_length for some smaller models\n",
    "    df_exceeding_length = docs_df[docs_df['chunk_num_tokens'] > 384]\n",
    "    # Split further\n",
    "    # Remove the df\n",
    "    docs_df = docs_df[docs_df['chunk_num_tokens'] <= 384]\n",
    "    # Convert them to dict\n",
    "    doc_token_length_exceeded = df_exceeding_length.to_dict(\"records\")\n",
    "    # Run the splitter further. Split the chunks into two\n",
    "    for doc in doc_token_length_exceeded:\n",
    "        # Get sentencfe length\n",
    "        doc_new_1 = {}\n",
    "        doc_new_2 = {}\n",
    "        length_chunk = len(doc['sentence_chunk'])\n",
    "        # Split it into two\n",
    "        # Assume `text` is your long text\n",
    "        # Find the midpoint\n",
    "        midpoint = length_chunk // 2\n",
    "\n",
    "        # Find the last period before the midpoint\n",
    "        split_point = doc['sentence_chunk'].rfind('. ', 0, midpoint)\n",
    "\n",
    "        # Split the text into two parts\n",
    "        first_half = doc['sentence_chunk'][:split_point+1]  # +1 to include the period\n",
    "        second_half = doc['sentence_chunk'][split_point+2:]  # +2 to skip the period and space\n",
    "\n",
    "        # Reclaculate all metadata except pg_num and doc_name            \n",
    "        doc_new_1['pg_num'] = doc['pg_num']\n",
    "        doc_new_2['pg_num'] = doc['pg_num']\n",
    "\n",
    "        doc_new_1['doc_name'] = doc['doc_name']\n",
    "        doc_new_2['doc_name'] = doc['doc_name']\n",
    "\n",
    "\n",
    "        #write metadata\n",
    "        doc_new_1['sentence_chunk'] = first_half\n",
    "        doc_new_1[\"chunk_num_chars\"] = len(first_half)\n",
    "        doc_new_1[\"chunk_num_tokens\"] = len(first_half) / 4\n",
    "        doc_new_1[\"chunk_num_words\"] = len([word for word in first_half.split(\" \")])\n",
    "\n",
    "        #write metadata\n",
    "        doc_new_2['sentence_chunk'] = second_half\n",
    "        doc_new_2[\"chunk_num_chars\"] = len(first_half)\n",
    "        doc_new_2[\"chunk_num_tokens\"] = len(first_half) / 4\n",
    "        doc_new_2[\"chunk_num_words\"] = len([word for word in first_half.split(\" \")])\n",
    "        \n",
    "\n",
    "        # Add it to the original dataframe\n",
    "\n",
    "        docs_df = pd.concat([docs_df, pd.DataFrame([doc_new_1]), pd.DataFrame([doc_new_2])], ignore_index=True) \n",
    "    return docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b861a578-c8e8-4513-864f-b187f295e7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:19.742858Z",
     "iopub.status.busy": "2024-04-02T22:46:19.742503Z",
     "iopub.status.idle": "2024-04-02T22:46:19.757729Z",
     "shell.execute_reply": "2024-04-02T22:46:19.756705Z",
     "shell.execute_reply.started": "2024-04-02T22:46:19.742831Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_backup = all_pdf_formatted_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fce5eea-49da-43b8-a1c4-eb045d3cca5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:47:00.758134Z",
     "iopub.status.busy": "2024-04-02T22:47:00.756940Z",
     "iopub.status.idle": "2024-04-02T22:47:00.787117Z",
     "shell.execute_reply": "2024-04-02T22:47:00.786027Z",
     "shell.execute_reply.started": "2024-04-02T22:47:00.758100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_pdf_formatted_backup).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f723275-1048-4dfe-917b-848f14e07f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:46:22.996881Z",
     "iopub.status.busy": "2024-04-02T22:46:22.996202Z",
     "iopub.status.idle": "2024-04-02T22:46:23.300029Z",
     "shell.execute_reply": "2024-04-02T22:46:23.299061Z",
     "shell.execute_reply.started": "2024-04-02T22:46:22.996852Z"
    }
   },
   "outputs": [],
   "source": [
    "#Running rectified\n",
    "\n",
    "all_pdf_formatted_df = check_and_rectify_token_length(all_pdf_formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21288ebb-439e-4fe0-96e6-8b7a6d9038c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:49:40.391958Z",
     "iopub.status.busy": "2024-04-02T22:49:40.391151Z",
     "iopub.status.idle": "2024-04-02T22:49:40.408073Z",
     "shell.execute_reply": "2024-04-02T22:49:40.407470Z",
     "shell.execute_reply.started": "2024-04-02T22:49:40.391928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>355.840078</td>\n",
       "      <td>503.923807</td>\n",
       "      <td>125.980952</td>\n",
       "      <td>70.375384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.237183</td>\n",
       "      <td>431.908522</td>\n",
       "      <td>107.977130</td>\n",
       "      <td>64.635809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>456.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>552.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>212.500000</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>1534.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3583.000000      3583.000000       3583.000000      3583.000000\n",
       "mean    355.840078       503.923807        125.980952        70.375384\n",
       "std     217.237183       431.908522        107.977130        64.635809\n",
       "min       1.000000         0.000000          0.000000         1.000000\n",
       "25%     136.000000       117.000000         29.250000        13.000000\n",
       "50%     456.000000       355.000000         88.750000        46.000000\n",
       "75%     552.000000       850.000000        212.500000       123.000000\n",
       "max     570.000000      1534.000000        383.500000       287.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the increase in chunk_num_tokens count \n",
    "# max_ is less than 384\n",
    "# min token 0\n",
    "# \n",
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "649284c6-537d-4dd9-a0d1-4b4b22edeac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:44:01.583990Z",
     "iopub.status.busy": "2024-04-02T22:44:01.583022Z",
     "iopub.status.idle": "2024-04-02T22:44:01.606139Z",
     "shell.execute_reply": "2024-04-02T22:44:01.605420Z",
     "shell.execute_reply.started": "2024-04-02T22:44:01.583949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_pdf_formatted_backup).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f509e93b-3a25-407c-a4aa-b07dbe3b3886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:50:24.191179Z",
     "iopub.status.busy": "2024-04-02T22:50:24.190526Z",
     "iopub.status.idle": "2024-04-02T22:50:24.205446Z",
     "shell.execute_reply": "2024-04-02T22:50:24.204252Z",
     "shell.execute_reply.started": "2024-04-02T22:50:24.191151Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = all_pdf_formatted_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1be24a2d-85a0-4caf-aa90-397e6fe19d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:51:53.763308Z",
     "iopub.status.busy": "2024-04-02T22:51:53.762286Z",
     "iopub.status.idle": "2024-04-02T22:51:53.767981Z",
     "shell.execute_reply": "2024-04-02T22:51:53.767418Z",
     "shell.execute_reply.started": "2024-04-02T22:51:53.763291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pg_num': 541,\n",
       "  'sentence_chunk': 'Neural machine transla-tion by jointly learning to align andtranslateICLR 2015. Bahdanau,D.,J. Chorowski,DSerdyuk, PBrakel, and YBen-gio',\n",
       "  'chunk_num_chars': 136,\n",
       "  'chunk_num_tokens': 34.0,\n",
       "  'chunk_num_words': 15,\n",
       "  'doc_name': 'Standford NLP'},\n",
       " {'pg_num': 7,\n",
       "  'sentence_chunk': 'We ﬁnd BART outperforms the best pre-vious work by 1.2 ROUGE-L, but the dataset remainsa challenging, because answers are only weakly speci-ﬁed by the question.5.4TranslationWe also evaluated performance on WMT16 Romanian-English,augmentedwithback-translationdatafrom Sennrich et al(2016). We use a 6-layertransformer source encoder to map Romanian intoa representation that BART is able to de-noise intoEnglish, following the approach introduced in §3.4. Experiment results are presented in Table 6. Wecompare our results against a baseline Transformerarchitecture (Vaswani et al., 2017) with Transformer-large settings (the baseline row). We show theperformance of both steps of our model in the ﬁxedBART and tuned BART rows. For each row weexperiment on the original WMT16 Romanian-Englishaugmented with back-translation data. We use abeam width of 5 and a length penalty of α = 1.',\n",
       "  'chunk_num_chars': 884,\n",
       "  'chunk_num_tokens': 221.0,\n",
       "  'chunk_num_words': 124,\n",
       "  'doc_name': 'BART'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_pdf_formatted_df,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be59c9-3de0-428b-af6c-f9a77338f2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50a8ab-4945-4ef9-990b-535bb4db0c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500db2bb-2086-4799-9560-3649f664ecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38c5ee-fbce-4d32-b10f-8036fa200150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5ab39-6232-4ed8-b431-c6cc4138bb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbf3a7-e8b9-491a-8c26-5496c197047d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d82036-9f62-493d-9b6c-4adcdc947d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
