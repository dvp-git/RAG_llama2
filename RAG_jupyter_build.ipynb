{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324812b5-edfc-4501-9ded-ecd559725cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T12:39:22.859093Z",
     "iopub.status.busy": "2024-04-03T12:39:22.858614Z",
     "iopub.status.idle": "2024-04-03T12:40:08.315815Z",
     "shell.execute_reply": "2024-04-03T12:40:08.315111Z",
     "shell.execute_reply.started": "2024-04-03T12:39:22.859058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF==1.23.26\n",
      "  Downloading PyMuPDF-1.23.26-cp39-none-manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.8.3\n",
      "  Downloading matplotlib-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.2.1\n",
      "  Downloading pandas-2.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Requests==2.31.0\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentence_transformers==2.5.1\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (3.4.1)\n",
      "Collecting tqdm==4.66.2\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.38.2\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (0.35.1)\n",
      "Collecting PyMuPDFb==1.23.22\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (4.38.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (5.10.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.4.4)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==2.2.1->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.9.2)\n",
      "Collecting huggingface-hub>=0.15.1\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.12.1+cu116)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (3.9.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (66.1.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.4.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 10)) (5.9.4)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (7.2.9)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.5.2)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.16.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (8.0.2)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (4.4.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.8.3->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 7)) (6.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (8.5.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.6.6)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (5.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (6.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (7.3.4)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (25.0.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (3.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (4.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (5.1.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (3.0.36)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.11.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (5.7.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.2)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.4.8)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (21.3.0)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (3.1.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.18.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.6.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter->-r requirements.txt (line 12)) (2.6.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.23.5)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 12)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (18.2.0)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.57.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (3.6.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (2.21)\n",
      "Installing collected packages: tzdata, tqdm, safetensors, Requests, qtpy, PyMuPDFb, numpy, fsspec, scipy, PyMuPDF, pandas, huggingface-hub, bitsandbytes, tokenizers, matplotlib, accelerate, transformers, sentence_transformers, qtconsole, jupyter-console, jupyter\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: Requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.4\n",
      "    Uninstalling numpy-1.23.4:\n",
      "      Successfully uninstalled numpy-1.23.4\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.2\n",
      "    Uninstalling scipy-1.9.2:\n",
      "      Successfully uninstalled scipy-1.9.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.0\n",
      "    Uninstalling pandas-1.5.0:\n",
      "      Successfully uninstalled pandas-1.5.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.6.1\n",
      "    Uninstalling matplotlib-3.6.1:\n",
      "      Successfully uninstalled matplotlib-3.6.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: sentence_transformers\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "    Uninstalling sentence-transformers-2.2.2:\n",
      "      Successfully uninstalled sentence-transformers-2.2.2\n",
      "Successfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22 Requests-2.31.0 accelerate-0.28.0 bitsandbytes-0.43.0 fsspec-2024.3.1 huggingface-hub-0.22.2 jupyter-1.0.0 jupyter-console-6.6.3 matplotlib-3.8.3 numpy-1.26.4 pandas-2.2.1 qtconsole-5.5.1 qtpy-2.4.1 safetensors-0.4.2 scipy-1.13.0 sentence_transformers-2.5.1 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.38.2 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ca8e7f-485d-43bc-bb8a-b5332868591b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:00.074221Z",
     "iopub.status.busy": "2024-04-03T14:51:00.073459Z",
     "iopub.status.idle": "2024-04-03T14:51:00.246844Z",
     "shell.execute_reply": "2024-04-03T14:51:00.245574Z",
     "shell.execute_reply.started": "2024-04-03T14:51:00.074181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import fitz\n",
    "import os\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f05e79-77f3-4fde-b9bf-f6bda82205d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:01.287280Z",
     "iopub.status.busy": "2024-04-03T14:51:01.286452Z",
     "iopub.status.idle": "2024-04-03T14:51:01.292434Z",
     "shell.execute_reply": "2024-04-03T14:51:01.291584Z",
     "shell.execute_reply.started": "2024-04-03T14:51:01.287249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Standford NLP.pdf', 'Attn_paper.pdf', 'Faiss.pdf', 'Gemini_paper.pdf', 'BART.pdf']\n"
     ]
    }
   ],
   "source": [
    "pdf_path = './'\n",
    "pdf_files = [f for f in os.listdir(pdf_path) if f.endswith(\".pdf\")]\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553c8a31-8540-475a-a6d1-13624086aaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:02.121129Z",
     "iopub.status.busy": "2024-04-03T14:51:02.120298Z",
     "iopub.status.idle": "2024-04-03T14:51:02.124967Z",
     "shell.execute_reply": "2024-04-03T14:51:02.124027Z",
     "shell.execute_reply.started": "2024-04-03T14:51:02.121096Z"
    }
   },
   "outputs": [],
   "source": [
    "books_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f57935-34e4-40ae-bad8-5d1928230c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:03.064537Z",
     "iopub.status.busy": "2024-04-03T14:51:03.063429Z",
     "iopub.status.idle": "2024-04-03T14:51:03.071684Z",
     "shell.execute_reply": "2024-04-03T14:51:03.070810Z",
     "shell.execute_reply.started": "2024-04-03T14:51:03.064491Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Text content of the pdf\n",
    "# For each pdf , get the pdf file contents \n",
    "# Store meta-data information about each pdf.\n",
    "\n",
    "def format_text(text):\n",
    "    text = text.strip(\"\\n\\n\")\n",
    "    text=text.replace(\"\\n\",'')\n",
    "    return text\n",
    "\n",
    "# # https://community.adobe.com/t5/acrobat-discussions/page-number-in-print-does-not-display-in-adobe-s-page-number-box/td-p/13781534\n",
    "# Doesn't use Logical Page numbers. Use the normal Page numbers\n",
    "# Logical causes issues during the rendering as you can't generalize to multiple pdfs\n",
    "\n",
    "def get_text_content(pdf_text_, pdf_):\n",
    "    doc = fitz.open(pdf_)\n",
    "    print(len(doc))\n",
    "    for page_num, page in enumerate(doc):\n",
    "        # Extract the text content of the page\n",
    "        text = page.get_text()\n",
    "        text = format_text(text)\n",
    "        name = pdf_.strip('.pdf')\n",
    "        pdf_text_.append((text, page_num+1, name))\n",
    "    return pdf_text_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240ec7a0-14df-4311-b574-22817bcda0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:04.121932Z",
     "iopub.status.busy": "2024-04-03T14:51:04.121489Z",
     "iopub.status.idle": "2024-04-03T14:51:07.407373Z",
     "shell.execute_reply": "2024-04-03T14:51:07.406427Z",
     "shell.execute_reply.started": "2024-04-03T14:51:04.121894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "15\n",
      "21\n",
      "62\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "books_ = []\n",
    "books_ = [get_text_content([], pdf_) for pdf_ in pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e7ba8b-f5f9-4a52-9168-67d7bf68b45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:07.410327Z",
     "iopub.status.busy": "2024-04-03T14:51:07.409334Z",
     "iopub.status.idle": "2024-04-03T14:51:07.418053Z",
     "shell.execute_reply": "2024-04-03T14:51:07.417130Z",
     "shell.execute_reply.started": "2024-04-03T14:51:07.410309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107,\n",
       " ('Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on theEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.ModelBLEUTraining Cost (FLOPs)EN-DEEN-FREN-DEEN-FRByteNet [18]23.75Deep-Att + PosUnk [39]39.21.0 · 1020GNMT + RL [38]24.639.922.3 · 10191.4 · 1020ConvS2S [9]25.1640.469.6 · 10181.5 · 1020MoE [32]26.0340.562.0 · 10191.2 · 1020Deep-Att + PosUnk Ensemble [39]40.48.0 · 1020GNMT + RL Ensemble [38]26.3041.161.8 · 10201.1 · 1021ConvS2S Ensemble [9]26.3641.297.7 · 10191.2 · 1021Transformer (base model)27.338.13.3 · 1018Transformer (big)28.441.82.3 · 1019Residual DropoutWe apply dropout [33] to the output of each sub-layer, before it is added to thesub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and thepositional encodings in both the encoder and decoder stacks. For the base model, we use a rate ofPdrop = 0.1.Label SmoothingDuring training, we employed label smoothing of value ϵls = 0.1 [36]. Thishurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.6Results6.1Machine TranslationOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model islisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base modelsurpasses all previously published models and ensembles, at a fraction of the training cost of any ofthe competitive models.On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,outperforming all of the previously published single models, at less than 1/4 the training cost of theprevious state-of-the-art model. The Transformer (big) model trained for English-to-French useddropout rate Pdrop = 0.1, instead of 0.3.For the base models, we used a single model obtained by averaging the last 5 checkpoints, whichwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. Weused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameterswere chosen after experimentation on the development set. We set the maximum output length duringinference to input length + 50, but terminate early when possible [38].Table 2 summarizes our results and compares our translation quality and training costs to other modelarchitectures from the literature. We estimate the number of floating point operations used to train amodel by multiplying the training time, the number of GPUs used, and an estimate of the sustainedsingle-precision floating-point capacity of each GPU 5.6.2Model VariationsTo evaluate the importance of different components of the Transformer, we varied our base modelin different ways, measuring the change in performance on English-to-German translation on the5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.8',\n",
       "  8,\n",
       "  'Attn_paper'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_[1][7][0]) , books_[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372100f9-c04e-4888-9d57-0e28f2d2a578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:08.623147Z",
     "iopub.status.busy": "2024-04-03T14:51:08.622364Z",
     "iopub.status.idle": "2024-04-03T14:51:08.693960Z",
     "shell.execute_reply": "2024-04-03T14:51:08.693042Z",
     "shell.execute_reply.started": "2024-04-03T14:51:08.623115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Books_  -> [List[List[(text_content, page_num)]]\n",
    "\n",
    "# Create a dictionary to store each pages documents into sentences\n",
    "\n",
    "# Estimating that each token is 4 characters\n",
    "# Page Info\n",
    "def page_formatter(page):\n",
    "    page_ = {}\n",
    "    for pg in page:\n",
    "        page_['doc_name'] = page[2]\n",
    "        page_['text'] = page[0]\n",
    "        page_['pg_num'] = page[1]\n",
    "        page_['pg_num_chars'] = len(page[0])\n",
    "        page_['pg_num_words'] = len(page[0].split(' '))\n",
    "        page_['pg_num_sentences'] = len(page[0].split('. ')) # Since sentences usually begin with '. '\n",
    "        page_['pg_num_tokens'] = page_['pg_num_chars'] / 4\n",
    "    return page_\n",
    "                                        \n",
    "# Testing with a single page\n",
    "# page_formatter(books_[1][6])\n",
    "\n",
    "all_content_ = [[page_formatter(page) for page in books] for books in books_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8f3a9c-4daf-448c-bde8-00c044a642e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:10.106225Z",
     "iopub.status.busy": "2024-04-03T14:51:10.105387Z",
     "iopub.status.idle": "2024-04-03T14:51:10.111202Z",
     "shell.execute_reply": "2024-04-03T14:51:10.110360Z",
     "shell.execute_reply.started": "2024-04-03T14:51:10.106192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_name': 'Gemini_paper',\n",
       " 'text': 'Gemini: A Family of Highly Capable Multimodal ModelsFigure 2 | Gemini supports interleaved sequences of text, image, audio, and video as inputs (illustratedby tokens of different colors in the input sequence). It can output responses with interleaved imageand text.tasks that require fine-grained understanding. In addition, Gemini can directly ingest audio signals at16kHz from Universal Speech Model (USM) (Zhang et al., 2023) features. This enables the model tocapture nuances that are typically lost when the audio is naively mapped to a text input (for example,see audio understanding demo on the website).Training the Gemini family of models required innovations in training algorithms, dataset, andinfrastructure. For the Pro model, the inherent scalability of our infrastructure and learning algorithmsenable us to complete pretraining in a matter of weeks, leveraging a fraction of the Ultra’s resources.The Nano series of models leverage additional advancements in distillation and training algorithmsto produce the best-in-class small language models for a wide variety of tasks, such as summarizationand reading comprehension, which power our next generation on-device experiences.3. Training InfrastructureWe trained Gemini models using TPUv5e and TPUv4 (Jouppi et al., 2023), depending on their sizesand configuration. Training Gemini Ultra used a large fleet of TPUv4 accelerators across multipledatacenters. This represents a significant increase in scale over our prior flagship model PaLM-2which presented new infrastructure challenges. Scaling up the number of accelerators results in aproportionate decrease in the mean time between failure of hardware in the overall system. Weminimized the rate of planned reschedules and preemptions, but genuine machine failures arecommonplace across all hardware accelerators at such large scales.TPUv4 accelerators are deployed in “SuperPods” of 4096 chips, each connected to a dedicatedoptical switch, which can dynamically reconfigure 4x4x4 chip cubes into arbitrary 3D torus topologiesin around 10 seconds (Jouppi et al., 2023). For Gemini Ultra, we decided to retain a small number ofcubes per superpod to allow for hot standbys and rolling maintenance.TPU accelerators primarily communicate over the high speed inter-chip-interconnect, but atGemini Ultra scale, we combine SuperPods in multiple datacenters using Google’s intra-cluster andinter-cluster network (Poutievski et al., 2022; Wetherall et al., 2023; yao Hong et al., 2018). Google’snetwork latencies and bandwidths are sufficient to support the commonly used synchronous training4',\n",
       " 'pg_num': 4,\n",
       " 'pg_num_chars': 2605,\n",
       " 'pg_num_words': 360,\n",
       " 'pg_num_sentences': 12,\n",
       " 'pg_num_tokens': 651.25}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[3][3] # List[List[dictionaries]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11cd74a8-2aa4-45cd-951e-c0849a2015a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:11.472642Z",
     "iopub.status.busy": "2024-04-03T14:51:11.471900Z",
     "iopub.status.idle": "2024-04-03T14:51:11.849753Z",
     "shell.execute_reply": "2024-04-03T14:51:11.849095Z",
     "shell.execute_reply.started": "2024-04-03T14:51:11.472611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
      "Token_mean , Sentences_mean (642.45, 17.0)\n",
      "Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
      "Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
      "Token_mean , Sentences_mean (1003.2, 18.7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df_p1_mean = pd.DataFrame(all_content_[0])['pg_num_tokens'].mean()\n",
    "# # df_p2 = pd.DataFrame(all_content_[1])\n",
    "# # df_p3 = pd.DataFrame(all_content_[2])\n",
    "# # df_p4 = pd.DataFrame(all_content_[3])\n",
    "# print(df_p1_mean)\n",
    "\n",
    "# Calculate the mean number of sentences in each document.Then use sentence_splitter \n",
    "# to split the long sentences\n",
    "def calc_mean(doc):\n",
    "    doc_df = pd.DataFrame(doc)\n",
    "    doc_mean = doc_df['pg_num_tokens'].mean()\n",
    "    doc_sentences_mean = doc_df['pg_num_sentences'].mean()\n",
    "    return doc_mean, doc_sentences_mean\n",
    "\n",
    "for doc in all_content_:\n",
    "    print(\"Token_mean , Sentences_mean\",calc_mean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490938ae-971f-4fc3-83d1-7a8a6271b570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:12.974077Z",
     "iopub.status.busy": "2024-04-03T14:51:12.973203Z",
     "iopub.status.idle": "2024-04-03T14:51:12.978991Z",
     "shell.execute_reply": "2024-04-03T14:51:12.977864Z",
     "shell.execute_reply.started": "2024-04-03T14:51:12.974046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each sentence is long , the mean token size are above and won't fit the embedding model for tokenization\n",
    "# Split sentences into smaller chunks\n",
    "\n",
    "# Method to put all sentences in an array called sentences for making the splitting easier\n",
    "def sentence_formatter_per_page(doc):\n",
    "    for page in doc:\n",
    "        page['sentences'] = [sentence for sentence in page['text'].split('. ')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c910ef41-1429-4e27-96c4-8e92fa6976fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:13.809962Z",
     "iopub.status.busy": "2024-04-03T14:51:13.809047Z",
     "iopub.status.idle": "2024-04-03T14:51:13.815057Z",
     "shell.execute_reply": "2024-04-03T14:51:13.813907Z",
     "shell.execute_reply.started": "2024-04-03T14:51:13.809915Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_formatter_all_books(books):\n",
    "    for item in books:\n",
    "        sentence_formatter_per_page(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53290f2f-9396-45b9-9a45-2f4302595bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:14.914540Z",
     "iopub.status.busy": "2024-04-03T14:51:14.913787Z",
     "iopub.status.idle": "2024-04-03T14:51:14.927319Z",
     "shell.execute_reply": "2024-04-03T14:51:14.926499Z",
     "shell.execute_reply.started": "2024-04-03T14:51:14.914496Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_formatter_all_books(all_content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0592b64-379c-485c-bb8e-e206894488f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:15.835264Z",
     "iopub.status.busy": "2024-04-03T14:51:15.834437Z",
     "iopub.status.idle": "2024-04-03T14:51:15.841831Z",
     "shell.execute_reply": "2024-04-03T14:51:15.841005Z",
     "shell.execute_reply.started": "2024-04-03T14:51:15.835230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_name': 'Standford NLP',\n",
       "  'text': '2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence. With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions. The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe. Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way. Consider the expression /[a-z]*/when matching against the text once upon a time. Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once. In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer. The operator *? is a Kleene star that matches as little text as*?possible. The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the. A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The). This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology). So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/. We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25). We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line. This is because the regular expression [ˆa-zA-Z], which',\n",
       "  'pg_num': 17,\n",
       "  'pg_num_chars': 2646,\n",
       "  'pg_num_words': 398,\n",
       "  'pg_num_sentences': 15,\n",
       "  'pg_num_tokens': 661.5,\n",
       "  'sentences': ['2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence',\n",
       "   'With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions',\n",
       "   'The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe',\n",
       "   'Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way',\n",
       "   'Consider the expression /[a-z]*/when matching against the text once upon a time',\n",
       "   'Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once',\n",
       "   'In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer',\n",
       "   'The operator *? is a Kleene star that matches as little text as*?possible',\n",
       "   'The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the',\n",
       "   'A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The)',\n",
       "   'This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology)',\n",
       "   'So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/',\n",
       "   'We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25)',\n",
       "   'We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line',\n",
       "   'This is because the regular expression [ˆa-zA-Z], which']},\n",
       " {'doc_name': 'Standford NLP',\n",
       "  'text': '10CHAPTER 2•REGULAR EXPRESSIONS, TEXT NORMALIZATION, EDIT DISTANCEwe used to avoid embedded instances of the, implies that there must be some single(although non-alphabetic) character before the the. We can avoid this by specify-ing that before the the we require either the beginning-of-line or a non-alphabeticcharacter, and the same at the end of the line:/(ˆ|[ˆa-zA-Z])[tT]he([ˆa-zA-Z]|$)/The process we just went through was based on ﬁxing two kinds of errors: falsepositives, strings that we incorrectly matched like other or there, and false nega-false positivestives, strings that we incorrectly missed, like The. Addressing these two kinds offalse negativeserrors comes up again and again in implementing speech and language processingsystems. Reducing the overall error rate for an application thus involves two antag-onistic efforts:• Increasing precision (minimizing false positives)• Increasing recall (minimizing false negatives)We’ll come back to precision and recall with more precise deﬁnitions in Chapter 4.2.1.4More OperatorsFigure 2.8 shows some aliases for common ranges, which can be used mainly tosave typing. Besides the Kleene * and Kleene + we can also use explicit numbers ascounters, by enclosing them in curly brackets. The regular expression /{3}/ means“exactly 3 occurrences of the previous character or expression”. So /a\\\\.{24}z/will match a followed by 24 dots followed by z (but not a followed by 23 or 25 dotsfollowed by a z).RegexExpansionMatchFirst Matches\\\\d[0-9]any digitParty␣of␣5\\\\D[ˆ0-9]any non-digitBlue␣moon\\\\w[a-zA-Z0-9_]any alphanumeric/underscoreDaiyu\\\\W[ˆ\\\\w]a non-alphanumeric!!!!\\\\s[␣\\\\r\\\\t\\\\n\\\\f]whitespace (space, tab)in Concord\\\\S[ˆ\\\\s]Non-whitespacein␣ConcordFigure 2.8Aliases for common sets of characters.A range of numbers can also be speciﬁed. So /{n,m}/ speciﬁes from n to moccurrences of the previous char or expression, and /{n,}/ means at least n occur-rences of the previous expression. REs for counting are summarized in Fig. 2.9.RegexMatch*zero or more occurrences of the previous char or expression+one or more occurrences of the previous char or expression?zero or one occurrence of the previous char or expression{n}exactly n occurrences of the previous char or expression{n,m}from n to m occurrences of the previous char or expression{n,}at least n occurrences of the previous char or expression{,m}up to m occurrences of the previous char or expressionFigure 2.9Regular expression operators for counting.Finally, certain special characters are referred to by special notation based on thebackslash (\\\\) (see Fig. 2.10). The most common of these are the newline characternewline',\n",
       "  'pg_num': 18,\n",
       "  'pg_num_chars': 2634,\n",
       "  'pg_num_words': 357,\n",
       "  'pg_num_sentences': 12,\n",
       "  'pg_num_tokens': 658.5,\n",
       "  'sentences': ['10CHAPTER 2•REGULAR EXPRESSIONS, TEXT NORMALIZATION, EDIT DISTANCEwe used to avoid embedded instances of the, implies that there must be some single(although non-alphabetic) character before the the',\n",
       "   'We can avoid this by specify-ing that before the the we require either the beginning-of-line or a non-alphabeticcharacter, and the same at the end of the line:/(ˆ|[ˆa-zA-Z])[tT]he([ˆa-zA-Z]|$)/The process we just went through was based on ﬁxing two kinds of errors: falsepositives, strings that we incorrectly matched like other or there, and false nega-false positivestives, strings that we incorrectly missed, like The',\n",
       "   'Addressing these two kinds offalse negativeserrors comes up again and again in implementing speech and language processingsystems',\n",
       "   'Reducing the overall error rate for an application thus involves two antag-onistic efforts:• Increasing precision (minimizing false positives)• Increasing recall (minimizing false negatives)We’ll come back to precision and recall with more precise deﬁnitions in Chapter 4.2.1.4More OperatorsFigure 2.8 shows some aliases for common ranges, which can be used mainly tosave typing',\n",
       "   'Besides the Kleene * and Kleene + we can also use explicit numbers ascounters, by enclosing them in curly brackets',\n",
       "   'The regular expression /{3}/ means“exactly 3 occurrences of the previous character or expression”',\n",
       "   'So /a\\\\.{24}z/will match a followed by 24 dots followed by z (but not a followed by 23 or 25 dotsfollowed by a z).RegexExpansionMatchFirst Matches\\\\d[0-9]any digitParty␣of␣5\\\\D[ˆ0-9]any non-digitBlue␣moon\\\\w[a-zA-Z0-9_]any alphanumeric/underscoreDaiyu\\\\W[ˆ\\\\w]a non-alphanumeric!!!!\\\\s[␣\\\\r\\\\t\\\\n\\\\f]whitespace (space, tab)in Concord\\\\S[ˆ\\\\s]Non-whitespacein␣ConcordFigure 2.8Aliases for common sets of characters.A range of numbers can also be speciﬁed',\n",
       "   'So /{n,m}/ speciﬁes from n to moccurrences of the previous char or expression, and /{n,}/ means at least n occur-rences of the previous expression',\n",
       "   'REs for counting are summarized in Fig',\n",
       "   '2.9.RegexMatch*zero or more occurrences of the previous char or expression+one or more occurrences of the previous char or expression?zero or one occurrence of the previous char or expression{n}exactly n occurrences of the previous char or expression{n,m}from n to m occurrences of the previous char or expression{n,}at least n occurrences of the previous char or expression{,m}up to m occurrences of the previous char or expressionFigure 2.9Regular expression operators for counting.Finally, certain special characters are referred to by special notation based on thebackslash (\\\\) (see Fig',\n",
       "   '2.10)',\n",
       "   'The most common of these are the newline characternewline']}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[0][16:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98814d44-297b-4e64-8629-b1428e7e4d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:18.920744Z",
     "iopub.status.busy": "2024-04-03T14:51:18.919660Z",
     "iopub.status.idle": "2024-04-03T14:51:18.927701Z",
     "shell.execute_reply": "2024-04-03T14:51:18.926467Z",
     "shell.execute_reply.started": "2024-04-03T14:51:18.920714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "def slice_sentences(page_sentences, overlap_size, slice_size):\n",
    "    return [page_sentences[i:i + slice_size] for i in range(0, len(page_sentences) - slice_size + 1, slice_size - overlap_size)]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "page_sentences = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "overlap_size = 2\n",
    "slice_size = 3\n",
    "result = slice_sentences(page_sentences, overlap_size, slice_size)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d78c1e6-fac7-4c67-8be1-4a3380158b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:20.012253Z",
     "iopub.status.busy": "2024-04-03T14:51:20.011218Z",
     "iopub.status.idle": "2024-04-03T14:51:20.016469Z",
     "shell.execute_reply": "2024-04-03T14:51:20.015713Z",
     "shell.execute_reply.started": "2024-04-03T14:51:20.012189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on this , splitting texts into size 8 since sizes are divisible by 6 (more or less)\n",
    "# Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
    "# Token_mean , Sentences_mean (642.45, 17.0)\n",
    "# Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
    "# Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
    "# Token_mean , Sentences_mean (1003.2, 18.7)\n",
    "\n",
    "# Keep overlap of 1 sentence default for every 6 sentences\n",
    "def slice_sentences(page_sentences, slice_size=5,overlap_size=1) :\n",
    "    return [page_sentences[i:i + slice_size] for i in range(0, len(page_sentences) - slice_size + 1, slice_size - overlap_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34cc056e-e4b2-41d5-bf11-3800a69177e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:21.248423Z",
     "iopub.status.busy": "2024-04-03T14:51:21.247349Z",
     "iopub.status.idle": "2024-04-03T14:51:21.253967Z",
     "shell.execute_reply": "2024-04-03T14:51:21.252984Z",
     "shell.execute_reply.started": "2024-04-03T14:51:21.248378Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def all_content_sentence_splitter(all_content):\n",
    "    for book in all_content:\n",
    "        for page in tqdm(book):\n",
    "            page[\"sentence_chunks\"] = slice_sentences(page[\"sentences\"],5,1)\n",
    "\n",
    "            page[\"num_chunks\"] = len(page[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d94c8fe-f37b-4b9b-9459-9f78b3b21c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:22.923218Z",
     "iopub.status.busy": "2024-04-03T14:51:22.922572Z",
     "iopub.status.idle": "2024-04-03T14:51:22.984833Z",
     "shell.execute_reply": "2024-04-03T14:51:22.983989Z",
     "shell.execute_reply.started": "2024-04-03T14:51:22.923190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e993793cce1643edba36a200f0afbd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febd4b60e99f470a93a40520bf423024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b280af8ebe644a9ebe99bccf0cfef383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eff948f35743b99b0120db78cdf0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709dffe86793430ea9f65a6f31ac9be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_content_sentence_splitter(all_content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05128216-2d66-435a-8080-bd35c3562472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:25.344258Z",
     "iopub.status.busy": "2024-04-03T14:51:25.343904Z",
     "iopub.status.idle": "2024-04-03T14:51:25.354209Z",
     "shell.execute_reply": "2024-04-03T14:51:25.353445Z",
     "shell.execute_reply.started": "2024-04-03T14:51:25.344210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_name': 'Faiss',\n",
       "  'text': 'nearest neighbor search.In NeurIPS 2021 Com-petitions and Demonstrations Track, pages 177–189.PMLR.[Simhadri et al., 2022b] Simhadri, H. V., Williams, G.,Aum¨uller, M., Douze, M., Babenko, A., Baranchuk,D., Chen, Q., Hosseini, L., Krishnaswamny, R.,Srinivasa, G., Subramanya, S. J., and Wang, J.(2022b).Results of the neurips’21 challenge onbillion-scale approximate nearest neighbor search.In Proceedings of the NeurIPS 2021 Competitions andDemonstrations Track, volume 176 of Proceedings ofMachine Learning Research, pages 177–189. PMLR.[Singh et al., 2021] Singh, A., Subramanya, S. J., Kr-ishnaswamy,R.,and Simhadri,H. V. (2021).Freshdiskann: A fast and accurate graph-based annindex for streaming similarity search.[Subramanya et al., 2019] Subramanya,S.J.,Kadekodi, R., Krishaswamy, R., and Simhadri,H. V. (2019). Diskann: Fast accurate billion-pointnearest neighbor search on a single node.InNeurips.[Sun et al., 2023a] Sun, P., Guo, R., and Kumar, S.(2023a). Automating nearest neighbor search con-figuration with constrained optimization.arXivpreprint arXiv:2301.01702.[Sun et al., 2023b] Sun, P., Simcha, D., Dopson, D.,Guo, R., and Kumar, S. (2023b). Soar: Improvedquantization for approximate nearest neighborsearch. In Thirty-seventh Conference on Neural Infor-mation Processing Systems.[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Ser-manet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A. (2015).Goingdeeper with convolutions. In Proceedings of the IEEEconference on computer vision and pattern recognition,pages 1–9.[Tavenard et al., 2011] Tavenard, R., J´egou, H., andAmsaleg, L. (2011). Balancing clusters to reduce re-sponse time variability in large scale image search.In 2011 9th International Workshop on Content-BasedMultimedia Indexing (CBMI), pages 19–24. IEEE.[Thakur et al., 2021] Thakur, N., Reimers, N., R¨uckl´e,A., Srivastava, A., and Gurevych, I. (2021). BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models. In Thirty-fifthConference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 2).[van Luijt and Verhagen, 2020] van Luijt, B. and Ver-hagen, M. (2020).Bringing semantic knowledgegraph technology to your data.IEEE Software,37(2):89–94.[Vardanian, 2022] Vardanian, A. (2022). USearch byUnum Cloud.[Wang et al., 2015] Wang, J., Liu, W., Kumar, S., andChang, S.-F. (2015). Learning to hash for indexingbig data - a survey. Proc. of the IEEE.[Wang et al., 2021] Wang, J., Yi, X., Guo, R., Jin, H.,Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., et al.(2021). Milvus: A purpose-built vector data man-agement system. In Proceedings of the 2021 Interna-tional Conference on Management of Data, pages 2614–2627.[Wang et al., 2017] Wang, J., Zhang, T., Sebe, N., Shen,H. T., et al. (2017). A survey on learning to hash.IEEE transactions on pattern analysis and machine in-telligence, 40(4):769–790.[Weber et al., 1998] Weber, R., Schek, H.-J., and Blott,S. (1998).A quantitative analysis and perfor-mance study for similarity-search methods in high-dimensional spaces.In VLDB, volume 98, pages194–205.21',\n",
       "  'pg_num': 21,\n",
       "  'pg_num_chars': 3133,\n",
       "  'pg_num_words': 408,\n",
       "  'pg_num_sentences': 36,\n",
       "  'pg_num_tokens': 783.25,\n",
       "  'sentences': ['nearest neighbor search.In NeurIPS 2021 Com-petitions and Demonstrations Track, pages 177–189.PMLR.[Simhadri et al., 2022b] Simhadri, H',\n",
       "   'V., Williams, G.,Aum¨uller, M., Douze, M., Babenko, A., Baranchuk,D., Chen, Q., Hosseini, L., Krishnaswamny, R.,Srinivasa, G., Subramanya, S',\n",
       "   'J., and Wang, J.(2022b).Results of the neurips’21 challenge onbillion-scale approximate nearest neighbor search.In Proceedings of the NeurIPS 2021 Competitions andDemonstrations Track, volume 176 of Proceedings ofMachine Learning Research, pages 177–189',\n",
       "   'PMLR.[Singh et al., 2021] Singh, A., Subramanya, S',\n",
       "   'J., Kr-ishnaswamy,R.,and Simhadri,H',\n",
       "   'V',\n",
       "   '(2021).Freshdiskann: A fast and accurate graph-based annindex for streaming similarity search.[Subramanya et al., 2019] Subramanya,S.J.,Kadekodi, R., Krishaswamy, R., and Simhadri,H',\n",
       "   'V',\n",
       "   '(2019)',\n",
       "   'Diskann: Fast accurate billion-pointnearest neighbor search on a single node.InNeurips.[Sun et al., 2023a] Sun, P., Guo, R., and Kumar, S.(2023a)',\n",
       "   'Automating nearest neighbor search con-figuration with constrained optimization.arXivpreprint arXiv:2301.01702.[Sun et al., 2023b] Sun, P., Simcha, D., Dopson, D.,Guo, R., and Kumar, S',\n",
       "   '(2023b)',\n",
       "   'Soar: Improvedquantization for approximate nearest neighborsearch',\n",
       "   'In Thirty-seventh Conference on Neural Infor-mation Processing Systems.[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Ser-manet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A',\n",
       "   '(2015).Goingdeeper with convolutions',\n",
       "   'In Proceedings of the IEEEconference on computer vision and pattern recognition,pages 1–9.[Tavenard et al., 2011] Tavenard, R., J´egou, H., andAmsaleg, L',\n",
       "   '(2011)',\n",
       "   'Balancing clusters to reduce re-sponse time variability in large scale image search.In 2011 9th International Workshop on Content-BasedMultimedia Indexing (CBMI), pages 19–24',\n",
       "   'IEEE.[Thakur et al., 2021] Thakur, N., Reimers, N., R¨uckl´e,A., Srivastava, A., and Gurevych, I',\n",
       "   '(2021)',\n",
       "   'BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models',\n",
       "   'In Thirty-fifthConference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 2).[van Luijt and Verhagen, 2020] van Luijt, B',\n",
       "   'and Ver-hagen, M',\n",
       "   '(2020).Bringing semantic knowledgegraph technology to your data.IEEE Software,37(2):89–94.[Vardanian, 2022] Vardanian, A',\n",
       "   '(2022)',\n",
       "   'USearch byUnum Cloud.[Wang et al., 2015] Wang, J., Liu, W., Kumar, S., andChang, S.-F',\n",
       "   '(2015)',\n",
       "   'Learning to hash for indexingbig data - a survey',\n",
       "   'Proc',\n",
       "   'of the IEEE.[Wang et al., 2021] Wang, J., Yi, X., Guo, R., Jin, H.,Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., et al.(2021)',\n",
       "   'Milvus: A purpose-built vector data man-agement system',\n",
       "   'In Proceedings of the 2021 Interna-tional Conference on Management of Data, pages 2614–2627.[Wang et al., 2017] Wang, J., Zhang, T., Sebe, N., Shen,H',\n",
       "   'T., et al',\n",
       "   '(2017)',\n",
       "   'A survey on learning to hash.IEEE transactions on pattern analysis and machine in-telligence, 40(4):769–790.[Weber et al., 1998] Weber, R., Schek, H.-J., and Blott,S',\n",
       "   '(1998).A quantitative analysis and perfor-mance study for similarity-search methods in high-dimensional spaces.In VLDB, volume 98, pages194–205.21'],\n",
       "  'sentence_chunks': [['nearest neighbor search.In NeurIPS 2021 Com-petitions and Demonstrations Track, pages 177–189.PMLR.[Simhadri et al., 2022b] Simhadri, H',\n",
       "    'V., Williams, G.,Aum¨uller, M., Douze, M., Babenko, A., Baranchuk,D., Chen, Q., Hosseini, L., Krishnaswamny, R.,Srinivasa, G., Subramanya, S',\n",
       "    'J., and Wang, J.(2022b).Results of the neurips’21 challenge onbillion-scale approximate nearest neighbor search.In Proceedings of the NeurIPS 2021 Competitions andDemonstrations Track, volume 176 of Proceedings ofMachine Learning Research, pages 177–189',\n",
       "    'PMLR.[Singh et al., 2021] Singh, A., Subramanya, S',\n",
       "    'J., Kr-ishnaswamy,R.,and Simhadri,H'],\n",
       "   ['J., Kr-ishnaswamy,R.,and Simhadri,H',\n",
       "    'V',\n",
       "    '(2021).Freshdiskann: A fast and accurate graph-based annindex for streaming similarity search.[Subramanya et al., 2019] Subramanya,S.J.,Kadekodi, R., Krishaswamy, R., and Simhadri,H',\n",
       "    'V',\n",
       "    '(2019)'],\n",
       "   ['(2019)',\n",
       "    'Diskann: Fast accurate billion-pointnearest neighbor search on a single node.InNeurips.[Sun et al., 2023a] Sun, P., Guo, R., and Kumar, S.(2023a)',\n",
       "    'Automating nearest neighbor search con-figuration with constrained optimization.arXivpreprint arXiv:2301.01702.[Sun et al., 2023b] Sun, P., Simcha, D., Dopson, D.,Guo, R., and Kumar, S',\n",
       "    '(2023b)',\n",
       "    'Soar: Improvedquantization for approximate nearest neighborsearch'],\n",
       "   ['Soar: Improvedquantization for approximate nearest neighborsearch',\n",
       "    'In Thirty-seventh Conference on Neural Infor-mation Processing Systems.[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Ser-manet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A',\n",
       "    '(2015).Goingdeeper with convolutions',\n",
       "    'In Proceedings of the IEEEconference on computer vision and pattern recognition,pages 1–9.[Tavenard et al., 2011] Tavenard, R., J´egou, H., andAmsaleg, L',\n",
       "    '(2011)'],\n",
       "   ['(2011)',\n",
       "    'Balancing clusters to reduce re-sponse time variability in large scale image search.In 2011 9th International Workshop on Content-BasedMultimedia Indexing (CBMI), pages 19–24',\n",
       "    'IEEE.[Thakur et al., 2021] Thakur, N., Reimers, N., R¨uckl´e,A., Srivastava, A., and Gurevych, I',\n",
       "    '(2021)',\n",
       "    'BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models'],\n",
       "   ['BEIR:A heterogeneous benchmark for zero-shot evalua-tion of information retrieval models',\n",
       "    'In Thirty-fifthConference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 2).[van Luijt and Verhagen, 2020] van Luijt, B',\n",
       "    'and Ver-hagen, M',\n",
       "    '(2020).Bringing semantic knowledgegraph technology to your data.IEEE Software,37(2):89–94.[Vardanian, 2022] Vardanian, A',\n",
       "    '(2022)'],\n",
       "   ['(2022)',\n",
       "    'USearch byUnum Cloud.[Wang et al., 2015] Wang, J., Liu, W., Kumar, S., andChang, S.-F',\n",
       "    '(2015)',\n",
       "    'Learning to hash for indexingbig data - a survey',\n",
       "    'Proc'],\n",
       "   ['Proc',\n",
       "    'of the IEEE.[Wang et al., 2021] Wang, J., Yi, X., Guo, R., Jin, H.,Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., et al.(2021)',\n",
       "    'Milvus: A purpose-built vector data man-agement system',\n",
       "    'In Proceedings of the 2021 Interna-tional Conference on Management of Data, pages 2614–2627.[Wang et al., 2017] Wang, J., Zhang, T., Sebe, N., Shen,H',\n",
       "    'T., et al']],\n",
       "  'num_chunks': 8},\n",
       " {'doc_name': 'Faiss',\n",
       "  'text': 'No encodingPQ encodingscalar quantizerFlatIndexFlatIndexPQIndexScalarQuantizerIVFIndexIVFFlatIndexIVFPQIndexIVFScalarQuantizerHNSWIndexHSNWFlatIndexHNSWPQIndexHNSWScalarQuantizerTable 2: A few combinations of pruning approaches and compression methods. In the cells: the corresponding index implementations.Decoupling encoding and non-exhaustive search op-tions.Beyond a certain scale, search time is deter-mined by the number of distance computations be-tween the query vector and database vectors.Thenon-exhaustive search methods in Faiss are eitherbased on a clustering, or on a graph exploration, seeSection 5. Another limiting factor of vector search isthe memory usage per vector (RAM or disk). In or-der to fit more vectors, they need to be compressed.Faiss implements a range of compression options, seeSection 4.Therefore, Faiss indexes are built as a combinationof pruning method and a compression method, see Ta-ble 2. In the following sections, we explore the optionsin these two directions.To evaluate a large number of index configurationsefficiently, the benchmarking framework takes advan-tage of this compositional nature of Faiss indices dur-ing the index training and search. The training of vec-tor transformations and k-means clustering for IVFcoarse quantizers are factored out and reused duringthe training of compatible indices. Coarse quantizersand IVF indices are first trained and evaluated sep-arately, the parameter space is pruned as describedin the previous section, and only the combinationsof Pareto-optimal components are benchmarked to-gether. It is implemented in bench fw.3.6Refining (IndexRefine)It is possible to combine a fast and inaccurate in-dexing method with a slower and more accuratesearch[J´egou et al., 2011b,Subramanya et al., 2019,Guo et al., 2020].This is done by querying the fastindex to retrieve a shortlist of results. The more ac-curate search then computes more accurate search re-sults only for the shortlist. This requires the accurateindex to store the vectors in a way that allows efficientrandom access to possibly-compressed database vec-tors. Some implementations use a slower storage (e.g.flash) for the second index [Subramanya et al., 2019,Sun et al., 2023b].For the first-level index, the relevant accuracy met-ric is the recall at the rank that will be used for re-ranking. The recall @ rank 1000 can thus sometimesbe a relevant metric, even if the end application doesnot use the 1000th neighbor at all.Several methods are also based on this refin-ing principle but do not use two separate in-dexes.Instead, they use two ways of interpret-ing the same compressed vectors:a fast and in-accurate decoding and a slower but more accu-rate decoding [Douze et al., 2016, Douze et al., 2018,Morozov and Babenko, 2019, Amara et al., 2022] arebased on this principle.The polysemous codesmethod [Douze et al., 2016] is implemented in Faiss’sIndexIVFPQ.4Compression levelsFaiss supports various vector codecs: these are meth-ods to compress vectors so that they take up less mem-ory. A compression method C : Rd → {1, ..., K}, a.k.a.a quantizer, converts a continuous multi-dimensionalvector to an integer or equivalently a fixed size bitstring. The length of the corresponding bit string iscalled the code size. The decoder D : {1, ..., K} → Rdreconstructs an approximation of the vector from theinteger. Since the number of distinct integers of a cer-tain size is finite, the decoder can only reconstruct afinite number K of distinct vectors.The search of Equation (1) becomes approximate:n = argminn=1..N∥q − D(C(xn))∥ = argminn=1..N∥q − D(Cn)∥(10)Where the codes Cn = C(xn) are precomputed andstored in the index. This is the asymmetric distancecomputation (ADC) [J´egou et al., 2010]. The symmet-ric distance computation (SDC) corresponds to thecase when the query vector is also compressed:n = argminn=1..N∥D(C(q)) − D(Cn)∥(11)Most Faiss indexes perform ADC as it is more ac-curate: there is no accuracy loss on the query vectors.SDC is useful when there is also a storage constrainton the queries or for indexing methods for which SDCis faster to compute than ADC.4.1The vector codecsThe k-means vector quantizer (Kmeans)The idealvector quantizer minimizes the MSE between the orig-inal and the decompressed vectors. This is formalizedin the Lloyd necessary conditions for the optimality ofa quantizer [Lloyd, 1982].The k-means clustering algorithm can be seen asa quantizer that directly applies the Lloyd optimal-ity conditions [Amara et al., 2022]. The K centroidsof k-means are an explicit enumeration of all possi-ble vectors that can be reconstructed. Thus the size ofthe bit strings that the k-means quantizer produces is⌈log2 K⌉ bits.The k-means vector quantizer is very accurate butthe memory usage and encoding complexity grow6',\n",
       "  'pg_num': 6,\n",
       "  'pg_num_chars': 4804,\n",
       "  'pg_num_words': 681,\n",
       "  'pg_num_sentences': 21,\n",
       "  'pg_num_tokens': 1201.0,\n",
       "  'sentences': ['No encodingPQ encodingscalar quantizerFlatIndexFlatIndexPQIndexScalarQuantizerIVFIndexIVFFlatIndexIVFPQIndexIVFScalarQuantizerHNSWIndexHSNWFlatIndexHNSWPQIndexHNSWScalarQuantizerTable 2: A few combinations of pruning approaches and compression methods',\n",
       "   'In the cells: the corresponding index implementations.Decoupling encoding and non-exhaustive search op-tions.Beyond a certain scale, search time is deter-mined by the number of distance computations be-tween the query vector and database vectors.Thenon-exhaustive search methods in Faiss are eitherbased on a clustering, or on a graph exploration, seeSection 5',\n",
       "   'Another limiting factor of vector search isthe memory usage per vector (RAM or disk)',\n",
       "   'In or-der to fit more vectors, they need to be compressed.Faiss implements a range of compression options, seeSection 4.Therefore, Faiss indexes are built as a combinationof pruning method and a compression method, see Ta-ble 2',\n",
       "   'In the following sections, we explore the optionsin these two directions.To evaluate a large number of index configurationsefficiently, the benchmarking framework takes advan-tage of this compositional nature of Faiss indices dur-ing the index training and search',\n",
       "   'The training of vec-tor transformations and k-means clustering for IVFcoarse quantizers are factored out and reused duringthe training of compatible indices',\n",
       "   'Coarse quantizersand IVF indices are first trained and evaluated sep-arately, the parameter space is pruned as describedin the previous section, and only the combinationsof Pareto-optimal components are benchmarked to-gether',\n",
       "   'It is implemented in bench fw.3.6Refining (IndexRefine)It is possible to combine a fast and inaccurate in-dexing method with a slower and more accuratesearch[J´egou et al., 2011b,Subramanya et al., 2019,Guo et al., 2020].This is done by querying the fastindex to retrieve a shortlist of results',\n",
       "   'The more ac-curate search then computes more accurate search re-sults only for the shortlist',\n",
       "   'This requires the accurateindex to store the vectors in a way that allows efficientrandom access to possibly-compressed database vec-tors',\n",
       "   'Some implementations use a slower storage (e.g.flash) for the second index [Subramanya et al., 2019,Sun et al., 2023b].For the first-level index, the relevant accuracy met-ric is the recall at the rank that will be used for re-ranking',\n",
       "   'The recall @ rank 1000 can thus sometimesbe a relevant metric, even if the end application doesnot use the 1000th neighbor at all.Several methods are also based on this refin-ing principle but do not use two separate in-dexes.Instead, they use two ways of interpret-ing the same compressed vectors:a fast and in-accurate decoding and a slower but more accu-rate decoding [Douze et al., 2016, Douze et al., 2018,Morozov and Babenko, 2019, Amara et al., 2022] arebased on this principle.The polysemous codesmethod [Douze et al., 2016] is implemented in Faiss’sIndexIVFPQ.4Compression levelsFaiss supports various vector codecs: these are meth-ods to compress vectors so that they take up less mem-ory',\n",
       "   'A compression method C : Rd → {1, ..., K}, a.k.a.a quantizer, converts a continuous multi-dimensionalvector to an integer or equivalently a fixed size bitstring',\n",
       "   'The length of the corresponding bit string iscalled the code size',\n",
       "   'The decoder D : {1, ..., K} → Rdreconstructs an approximation of the vector from theinteger',\n",
       "   'Since the number of distinct integers of a cer-tain size is finite, the decoder can only reconstruct afinite number K of distinct vectors.The search of Equation (1) becomes approximate:n = argminn=1..N∥q − D(C(xn))∥ = argminn=1..N∥q − D(Cn)∥(10)Where the codes Cn = C(xn) are precomputed andstored in the index',\n",
       "   'This is the asymmetric distancecomputation (ADC) [J´egou et al., 2010]',\n",
       "   'The symmet-ric distance computation (SDC) corresponds to thecase when the query vector is also compressed:n = argminn=1..N∥D(C(q)) − D(Cn)∥(11)Most Faiss indexes perform ADC as it is more ac-curate: there is no accuracy loss on the query vectors.SDC is useful when there is also a storage constrainton the queries or for indexing methods for which SDCis faster to compute than ADC.4.1The vector codecsThe k-means vector quantizer (Kmeans)The idealvector quantizer minimizes the MSE between the orig-inal and the decompressed vectors',\n",
       "   'This is formalizedin the Lloyd necessary conditions for the optimality ofa quantizer [Lloyd, 1982].The k-means clustering algorithm can be seen asa quantizer that directly applies the Lloyd optimal-ity conditions [Amara et al., 2022]',\n",
       "   'The K centroidsof k-means are an explicit enumeration of all possi-ble vectors that can be reconstructed',\n",
       "   'Thus the size ofthe bit strings that the k-means quantizer produces is⌈log2 K⌉ bits.The k-means vector quantizer is very accurate butthe memory usage and encoding complexity grow6'],\n",
       "  'sentence_chunks': [['No encodingPQ encodingscalar quantizerFlatIndexFlatIndexPQIndexScalarQuantizerIVFIndexIVFFlatIndexIVFPQIndexIVFScalarQuantizerHNSWIndexHSNWFlatIndexHNSWPQIndexHNSWScalarQuantizerTable 2: A few combinations of pruning approaches and compression methods',\n",
       "    'In the cells: the corresponding index implementations.Decoupling encoding and non-exhaustive search op-tions.Beyond a certain scale, search time is deter-mined by the number of distance computations be-tween the query vector and database vectors.Thenon-exhaustive search methods in Faiss are eitherbased on a clustering, or on a graph exploration, seeSection 5',\n",
       "    'Another limiting factor of vector search isthe memory usage per vector (RAM or disk)',\n",
       "    'In or-der to fit more vectors, they need to be compressed.Faiss implements a range of compression options, seeSection 4.Therefore, Faiss indexes are built as a combinationof pruning method and a compression method, see Ta-ble 2',\n",
       "    'In the following sections, we explore the optionsin these two directions.To evaluate a large number of index configurationsefficiently, the benchmarking framework takes advan-tage of this compositional nature of Faiss indices dur-ing the index training and search'],\n",
       "   ['In the following sections, we explore the optionsin these two directions.To evaluate a large number of index configurationsefficiently, the benchmarking framework takes advan-tage of this compositional nature of Faiss indices dur-ing the index training and search',\n",
       "    'The training of vec-tor transformations and k-means clustering for IVFcoarse quantizers are factored out and reused duringthe training of compatible indices',\n",
       "    'Coarse quantizersand IVF indices are first trained and evaluated sep-arately, the parameter space is pruned as describedin the previous section, and only the combinationsof Pareto-optimal components are benchmarked to-gether',\n",
       "    'It is implemented in bench fw.3.6Refining (IndexRefine)It is possible to combine a fast and inaccurate in-dexing method with a slower and more accuratesearch[J´egou et al., 2011b,Subramanya et al., 2019,Guo et al., 2020].This is done by querying the fastindex to retrieve a shortlist of results',\n",
       "    'The more ac-curate search then computes more accurate search re-sults only for the shortlist'],\n",
       "   ['The more ac-curate search then computes more accurate search re-sults only for the shortlist',\n",
       "    'This requires the accurateindex to store the vectors in a way that allows efficientrandom access to possibly-compressed database vec-tors',\n",
       "    'Some implementations use a slower storage (e.g.flash) for the second index [Subramanya et al., 2019,Sun et al., 2023b].For the first-level index, the relevant accuracy met-ric is the recall at the rank that will be used for re-ranking',\n",
       "    'The recall @ rank 1000 can thus sometimesbe a relevant metric, even if the end application doesnot use the 1000th neighbor at all.Several methods are also based on this refin-ing principle but do not use two separate in-dexes.Instead, they use two ways of interpret-ing the same compressed vectors:a fast and in-accurate decoding and a slower but more accu-rate decoding [Douze et al., 2016, Douze et al., 2018,Morozov and Babenko, 2019, Amara et al., 2022] arebased on this principle.The polysemous codesmethod [Douze et al., 2016] is implemented in Faiss’sIndexIVFPQ.4Compression levelsFaiss supports various vector codecs: these are meth-ods to compress vectors so that they take up less mem-ory',\n",
       "    'A compression method C : Rd → {1, ..., K}, a.k.a.a quantizer, converts a continuous multi-dimensionalvector to an integer or equivalently a fixed size bitstring'],\n",
       "   ['A compression method C : Rd → {1, ..., K}, a.k.a.a quantizer, converts a continuous multi-dimensionalvector to an integer or equivalently a fixed size bitstring',\n",
       "    'The length of the corresponding bit string iscalled the code size',\n",
       "    'The decoder D : {1, ..., K} → Rdreconstructs an approximation of the vector from theinteger',\n",
       "    'Since the number of distinct integers of a cer-tain size is finite, the decoder can only reconstruct afinite number K of distinct vectors.The search of Equation (1) becomes approximate:n = argminn=1..N∥q − D(C(xn))∥ = argminn=1..N∥q − D(Cn)∥(10)Where the codes Cn = C(xn) are precomputed andstored in the index',\n",
       "    'This is the asymmetric distancecomputation (ADC) [J´egou et al., 2010]'],\n",
       "   ['This is the asymmetric distancecomputation (ADC) [J´egou et al., 2010]',\n",
       "    'The symmet-ric distance computation (SDC) corresponds to thecase when the query vector is also compressed:n = argminn=1..N∥D(C(q)) − D(Cn)∥(11)Most Faiss indexes perform ADC as it is more ac-curate: there is no accuracy loss on the query vectors.SDC is useful when there is also a storage constrainton the queries or for indexing methods for which SDCis faster to compute than ADC.4.1The vector codecsThe k-means vector quantizer (Kmeans)The idealvector quantizer minimizes the MSE between the orig-inal and the decompressed vectors',\n",
       "    'This is formalizedin the Lloyd necessary conditions for the optimality ofa quantizer [Lloyd, 1982].The k-means clustering algorithm can be seen asa quantizer that directly applies the Lloyd optimal-ity conditions [Amara et al., 2022]',\n",
       "    'The K centroidsof k-means are an explicit enumeration of all possi-ble vectors that can be reconstructed',\n",
       "    'Thus the size ofthe bit strings that the k-means quantizer produces is⌈log2 K⌉ bits.The k-means vector quantizer is very accurate butthe memory usage and encoding complexity grow6']],\n",
       "  'num_chunks': 5},\n",
       " {'doc_name': 'Faiss',\n",
       "  'text': 'exponentially with the code size. Therefore, k-meansis impractical to use beyond 3-byte codes, correspond-ing to 16M centroids.Scalar quantizersScalar quantizers encode each di-mension of a vector independently.A very classical and simple scalar quantizer is LSH(IndexLSH), where each vector component is encodedin a single bit by comparing it to a threshold. Thethreshold can be set to 0 or trained.Faiss furthersupports efficient search of binary vectors via theIndexBinary objects, see Section 4.5.The Faiss ScalarQuantizer also supports uniformquantizers that encode a vector component into 8,6 or 4 bits – referred to as SQ8, SQ6, SQ4.A per-component scale and offset determine which valuesare reconstructed. They can be set separately for eachdimension or uniformly on the whole vector.TheIndexRowwiseMinMax stores vectors with per-vectornormalizing coefficients. The ranges are trained be-forehand on a set of representative vectors. The lower-precision float16 representation is also considered as ascalar quantizer, SQfp16.Multi-codebook quantizers.Faiss contains severalmulti-codebook quantization options. They are builtfrom M vector quantizers that can reconstruct K dis-tinct values each. The codes produced by these meth-ods are of the form (c1, ..., cM) ∈ {1, ..., K}M, i.e. eachcode indexes one of the quantizers. The number of re-constructed vectors is KM and the code size is thusM⌈log2(K)⌉.The product quantizer (ProductQuantizer, alsonoted PQ) is a simple multi-codebook quantizer thatsplits the input vector into M sub-vectors and quan-tizes them separately [J´egou et al., 2010] with a k-means quantizer. At reconstruction time, the individ-ual reconstructions are concatenated to produce the fi-nal code. In the following, we will use the notationPQ6x10 for a product quantizer with 6 sub-vectorseach encoded in 10 bits (M = 6, K = 210).Additive quantizers are a family of multi-codebookquantizerswherethereconstructionsfromsub-quantizers are summed up together. Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers. Each quantizer can representthe set of reproduction values of the enclosed quantizers.Faiss also supports a combination of PQ andresidual quantizer, ProductResidualQuantizer.Inthat case, the vector is split in sub-vectors thatare encoded independently with additive quantiz-ers [Babenko and Lempitsky, 2015]. The codes fromthe sub-quantizers are concatenated. We use the no-tation PRQ2x6x10 to indicate that vectors are split in2 and encoded independently with RQ6x10, yieldinga total of 12 codebooks of size 210.Hierarchy of quantizersAlthough this is not by de-sign, it turns out that there is a strict ordering be-tween the quantizers described before. This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive. The hierarchy of quantizers is shownin Figure 2:1. the binary representation with bits +1 and -1 canbe represented as a scalar quantizer with 1 bit percomponent;2. the scalar quantizer can be represented as a prod-uct quantizer with 1 dimension per sub-vectorand uniform per-dimension quantizer;3. the product quantizer can be represented as aproduct-additive quantizer where the additivequantizer has a single level;4. the product additive quantizer is an addi-tive quantizer where within each codebook allcomponents outside one sub-vector are set to0 [Babenko and Lempitsky, 2014];5. the additive quantizer (and any other quantizer)can be represented as a vector quantizer wherethe codebook entries are the explicit enumerationof all possible reconstructions.The implications of this hierarchy are (1) the de-grees of freedom for the reproduction values of quan-tizer i + 1 are larger than for i, so it is more accurate(2) quantizer i+1 has a higher capacity so it consumesmore resources in terms of training time and storageoverhead than i. In practice, the product quantizer of-ten offers a good tradeoff, which explains its adoption.7',\n",
       "  'pg_num': 7,\n",
       "  'pg_num_chars': 4774,\n",
       "  'pg_num_words': 649,\n",
       "  'pg_num_sentences': 24,\n",
       "  'pg_num_tokens': 1193.5,\n",
       "  'sentences': ['exponentially with the code size',\n",
       "   'Therefore, k-meansis impractical to use beyond 3-byte codes, correspond-ing to 16M centroids.Scalar quantizersScalar quantizers encode each di-mension of a vector independently.A very classical and simple scalar quantizer is LSH(IndexLSH), where each vector component is encodedin a single bit by comparing it to a threshold',\n",
       "   'Thethreshold can be set to 0 or trained.Faiss furthersupports efficient search of binary vectors via theIndexBinary objects, see Section 4.5.The Faiss ScalarQuantizer also supports uniformquantizers that encode a vector component into 8,6 or 4 bits – referred to as SQ8, SQ6, SQ4.A per-component scale and offset determine which valuesare reconstructed',\n",
       "   'They can be set separately for eachdimension or uniformly on the whole vector.TheIndexRowwiseMinMax stores vectors with per-vectornormalizing coefficients',\n",
       "   'The ranges are trained be-forehand on a set of representative vectors',\n",
       "   'The lower-precision float16 representation is also considered as ascalar quantizer, SQfp16.Multi-codebook quantizers.Faiss contains severalmulti-codebook quantization options',\n",
       "   'They are builtfrom M vector quantizers that can reconstruct K dis-tinct values each',\n",
       "   'The codes produced by these meth-ods are of the form (c1, ..., cM) ∈ {1, ..., K}M, i.e',\n",
       "   'eachcode indexes one of the quantizers',\n",
       "   'The number of re-constructed vectors is KM and the code size is thusM⌈log2(K)⌉.The product quantizer (ProductQuantizer, alsonoted PQ) is a simple multi-codebook quantizer thatsplits the input vector into M sub-vectors and quan-tizes them separately [J´egou et al., 2010] with a k-means quantizer',\n",
       "   'At reconstruction time, the individ-ual reconstructions are concatenated to produce the fi-nal code',\n",
       "   'In the following, we will use the notationPQ6x10 for a product quantizer with 6 sub-vectorseach encoded in 10 bits (M = 6, K = 210).Additive quantizers are a family of multi-codebookquantizerswherethereconstructionsfromsub-quantizers are summed up together',\n",
       "   'Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers',\n",
       "   'Each quantizer can representthe set of reproduction values of the enclosed quantizers.Faiss also supports a combination of PQ andresidual quantizer, ProductResidualQuantizer.Inthat case, the vector is split in sub-vectors thatare encoded independently with additive quantiz-ers [Babenko and Lempitsky, 2015]',\n",
       "   'The codes fromthe sub-quantizers are concatenated',\n",
       "   'We use the no-tation PRQ2x6x10 to indicate that vectors are split in2 and encoded independently with RQ6x10, yieldinga total of 12 codebooks of size 210.Hierarchy of quantizersAlthough this is not by de-sign, it turns out that there is a strict ordering be-tween the quantizers described before',\n",
       "   'This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive',\n",
       "   'The hierarchy of quantizers is shownin Figure 2:1',\n",
       "   'the binary representation with bits +1 and -1 canbe represented as a scalar quantizer with 1 bit percomponent;2',\n",
       "   'the scalar quantizer can be represented as a prod-uct quantizer with 1 dimension per sub-vectorand uniform per-dimension quantizer;3',\n",
       "   'the product quantizer can be represented as aproduct-additive quantizer where the additivequantizer has a single level;4',\n",
       "   'the product additive quantizer is an addi-tive quantizer where within each codebook allcomponents outside one sub-vector are set to0 [Babenko and Lempitsky, 2014];5',\n",
       "   'the additive quantizer (and any other quantizer)can be represented as a vector quantizer wherethe codebook entries are the explicit enumerationof all possible reconstructions.The implications of this hierarchy are (1) the de-grees of freedom for the reproduction values of quan-tizer i + 1 are larger than for i, so it is more accurate(2) quantizer i+1 has a higher capacity so it consumesmore resources in terms of training time and storageoverhead than i',\n",
       "   'In practice, the product quantizer of-ten offers a good tradeoff, which explains its adoption.7'],\n",
       "  'sentence_chunks': [['exponentially with the code size',\n",
       "    'Therefore, k-meansis impractical to use beyond 3-byte codes, correspond-ing to 16M centroids.Scalar quantizersScalar quantizers encode each di-mension of a vector independently.A very classical and simple scalar quantizer is LSH(IndexLSH), where each vector component is encodedin a single bit by comparing it to a threshold',\n",
       "    'Thethreshold can be set to 0 or trained.Faiss furthersupports efficient search of binary vectors via theIndexBinary objects, see Section 4.5.The Faiss ScalarQuantizer also supports uniformquantizers that encode a vector component into 8,6 or 4 bits – referred to as SQ8, SQ6, SQ4.A per-component scale and offset determine which valuesare reconstructed',\n",
       "    'They can be set separately for eachdimension or uniformly on the whole vector.TheIndexRowwiseMinMax stores vectors with per-vectornormalizing coefficients',\n",
       "    'The ranges are trained be-forehand on a set of representative vectors'],\n",
       "   ['The ranges are trained be-forehand on a set of representative vectors',\n",
       "    'The lower-precision float16 representation is also considered as ascalar quantizer, SQfp16.Multi-codebook quantizers.Faiss contains severalmulti-codebook quantization options',\n",
       "    'They are builtfrom M vector quantizers that can reconstruct K dis-tinct values each',\n",
       "    'The codes produced by these meth-ods are of the form (c1, ..., cM) ∈ {1, ..., K}M, i.e',\n",
       "    'eachcode indexes one of the quantizers'],\n",
       "   ['eachcode indexes one of the quantizers',\n",
       "    'The number of re-constructed vectors is KM and the code size is thusM⌈log2(K)⌉.The product quantizer (ProductQuantizer, alsonoted PQ) is a simple multi-codebook quantizer thatsplits the input vector into M sub-vectors and quan-tizes them separately [J´egou et al., 2010] with a k-means quantizer',\n",
       "    'At reconstruction time, the individ-ual reconstructions are concatenated to produce the fi-nal code',\n",
       "    'In the following, we will use the notationPQ6x10 for a product quantizer with 6 sub-vectorseach encoded in 10 bits (M = 6, K = 210).Additive quantizers are a family of multi-codebookquantizerswherethereconstructionsfromsub-quantizers are summed up together',\n",
       "    'Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers'],\n",
       "   ['Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers',\n",
       "    'Each quantizer can representthe set of reproduction values of the enclosed quantizers.Faiss also supports a combination of PQ andresidual quantizer, ProductResidualQuantizer.Inthat case, the vector is split in sub-vectors thatare encoded independently with additive quantiz-ers [Babenko and Lempitsky, 2015]',\n",
       "    'The codes fromthe sub-quantizers are concatenated',\n",
       "    'We use the no-tation PRQ2x6x10 to indicate that vectors are split in2 and encoded independently with RQ6x10, yieldinga total of 12 codebooks of size 210.Hierarchy of quantizersAlthough this is not by de-sign, it turns out that there is a strict ordering be-tween the quantizers described before',\n",
       "    'This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive'],\n",
       "   ['This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive',\n",
       "    'The hierarchy of quantizers is shownin Figure 2:1',\n",
       "    'the binary representation with bits +1 and -1 canbe represented as a scalar quantizer with 1 bit percomponent;2',\n",
       "    'the scalar quantizer can be represented as a prod-uct quantizer with 1 dimension per sub-vectorand uniform per-dimension quantizer;3',\n",
       "    'the product quantizer can be represented as aproduct-additive quantizer where the additivequantizer has a single level;4']],\n",
       "  'num_chunks': 5}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.sample(all_content_[2],k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea2631b-bc9d-4ad5-b32f-b6eb07ec631f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:27.819920Z",
     "iopub.status.busy": "2024-04-03T14:51:27.819041Z",
     "iopub.status.idle": "2024-04-03T14:51:27.845344Z",
     "shell.execute_reply": "2024-04-03T14:51:27.844513Z",
     "shell.execute_reply.started": "2024-04-03T14:51:27.819889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2900.025997</td>\n",
       "      <td>418.400347</td>\n",
       "      <td>32.854419</td>\n",
       "      <td>725.006499</td>\n",
       "      <td>7.608319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>166.709828</td>\n",
       "      <td>1175.894326</td>\n",
       "      <td>155.640269</td>\n",
       "      <td>98.641975</td>\n",
       "      <td>293.973582</td>\n",
       "      <td>24.652779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>2349.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>587.250000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2773.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>693.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>433.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>11555.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>2888.750000</td>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pg_num  pg_num_chars  pg_num_words  pg_num_sentences  \\\n",
       "count  577.000000    577.000000    577.000000        577.000000   \n",
       "mean   289.000000   2900.025997    418.400347         32.854419   \n",
       "std    166.709828   1175.894326    155.640269         98.641975   \n",
       "min      1.000000      0.000000      1.000000          1.000000   \n",
       "25%    145.000000   2349.000000    340.000000         10.000000   \n",
       "50%    289.000000   2773.000000    412.000000         13.000000   \n",
       "75%    433.000000   3232.000000    476.000000         17.000000   \n",
       "max    577.000000  11555.000000   1474.000000        994.000000   \n",
       "\n",
       "       pg_num_tokens  num_chunks  \n",
       "count     577.000000  577.000000  \n",
       "mean      725.006499    7.608319  \n",
       "std       293.973582   24.652779  \n",
       "min         0.000000    0.000000  \n",
       "25%       587.250000    2.000000  \n",
       "50%       693.250000    3.000000  \n",
       "75%       808.000000    4.000000  \n",
       "max      2888.750000  248.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "501fbfcd-2c8e-44bb-90f4-2d0fc3b146fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:29.446669Z",
     "iopub.status.busy": "2024-04-03T14:51:29.445750Z",
     "iopub.status.idle": "2024-04-03T14:51:29.467335Z",
     "shell.execute_reply": "2024-04-03T14:51:29.466747Z",
     "shell.execute_reply.started": "2024-04-03T14:51:29.446634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2569.800000</td>\n",
       "      <td>338.40000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>642.450000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.472136</td>\n",
       "      <td>1084.092853</td>\n",
       "      <td>166.50474</td>\n",
       "      <td>11.814035</td>\n",
       "      <td>271.023213</td>\n",
       "      <td>2.947154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2132.500000</td>\n",
       "      <td>304.50000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>533.125000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3036.000000</td>\n",
       "      <td>383.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>3170.000000</td>\n",
       "      <td>459.00000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>792.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>4203.000000</td>\n",
       "      <td>570.00000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1050.750000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  15.000000     15.000000      15.00000         15.000000      15.000000   \n",
       "mean    8.000000   2569.800000     338.40000         17.000000     642.450000   \n",
       "std     4.472136   1084.092853     166.50474         11.814035     271.023213   \n",
       "min     1.000000    702.000000      45.00000          3.000000     175.500000   \n",
       "25%     4.500000   2132.500000     304.50000         12.000000     533.125000   \n",
       "50%     8.000000   3036.000000     383.00000         15.000000     759.000000   \n",
       "75%    11.500000   3170.000000     459.00000         18.500000     792.500000   \n",
       "max    15.000000   4203.000000     570.00000         43.000000    1050.750000   \n",
       "\n",
       "       num_chunks  \n",
       "count   15.000000  \n",
       "mean     3.600000  \n",
       "std      2.947154  \n",
       "min      0.000000  \n",
       "25%      2.500000  \n",
       "50%      3.000000  \n",
       "75%      4.000000  \n",
       "max     10.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[1]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79a8345-70f0-427a-a1cb-22b30d1dcfdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:30.384452Z",
     "iopub.status.busy": "2024-04-03T14:51:30.383730Z",
     "iopub.status.idle": "2024-04-03T14:51:30.406662Z",
     "shell.execute_reply": "2024-04-03T14:51:30.406087Z",
     "shell.execute_reply.started": "2024-04-03T14:51:30.384415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4713.047619</td>\n",
       "      <td>651.142857</td>\n",
       "      <td>26.857143</td>\n",
       "      <td>1178.261905</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.204837</td>\n",
       "      <td>600.454701</td>\n",
       "      <td>98.317997</td>\n",
       "      <td>14.118377</td>\n",
       "      <td>150.113675</td>\n",
       "      <td>3.507136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3133.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>783.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1105.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4792.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>5049.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1262.250000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>5733.000000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1433.250000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  21.000000     21.000000     21.000000         21.000000      21.000000   \n",
       "mean   11.000000   4713.047619    651.142857         26.857143    1178.261905   \n",
       "std     6.204837    600.454701     98.317997         14.118377     150.113675   \n",
       "min     1.000000   3133.000000    408.000000         13.000000     783.250000   \n",
       "25%     6.000000   4422.000000    592.000000         19.000000    1105.500000   \n",
       "50%    11.000000   4792.000000    651.000000         23.000000    1198.000000   \n",
       "75%    16.000000   5049.000000    716.000000         24.000000    1262.250000   \n",
       "max    21.000000   5733.000000    806.000000         63.000000    1433.250000   \n",
       "\n",
       "       num_chunks  \n",
       "count   21.000000  \n",
       "mean     6.000000  \n",
       "std      3.507136  \n",
       "min      3.000000  \n",
       "25%      4.000000  \n",
       "50%      5.000000  \n",
       "75%      5.000000  \n",
       "max     15.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[2]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5e3a14d-6873-420f-a0cd-46e5472cd92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:31.108245Z",
     "iopub.status.busy": "2024-04-03T14:51:31.107088Z",
     "iopub.status.idle": "2024-04-03T14:51:31.129906Z",
     "shell.execute_reply": "2024-04-03T14:51:31.129315Z",
     "shell.execute_reply.started": "2024-04-03T14:51:31.108144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>2324.854839</td>\n",
       "      <td>294.064516</td>\n",
       "      <td>11.983871</td>\n",
       "      <td>581.213710</td>\n",
       "      <td>2.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.041619</td>\n",
       "      <td>1125.285987</td>\n",
       "      <td>150.230192</td>\n",
       "      <td>8.864170</td>\n",
       "      <td>281.321497</td>\n",
       "      <td>2.236423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.250000</td>\n",
       "      <td>1292.250000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>323.062500</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>2419.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>604.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.750000</td>\n",
       "      <td>3361.000000</td>\n",
       "      <td>413.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>840.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>4105.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1026.250000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  62.000000     62.000000     62.000000         62.000000      62.000000   \n",
       "mean   31.500000   2324.854839    294.064516         11.983871     581.213710   \n",
       "std    18.041619   1125.285987    150.230192          8.864170     281.321497   \n",
       "min     1.000000    587.000000     87.000000          1.000000     146.750000   \n",
       "25%    16.250000   1292.250000    125.500000          4.250000     323.062500   \n",
       "50%    31.500000   2419.000000    329.000000         11.000000     604.750000   \n",
       "75%    46.750000   3361.000000    413.750000         17.000000     840.250000   \n",
       "max    62.000000   4105.000000    559.000000         36.000000    1026.250000   \n",
       "\n",
       "       num_chunks  \n",
       "count   62.000000  \n",
       "mean     2.419355  \n",
       "std      2.236423  \n",
       "min      0.000000  \n",
       "25%      0.250000  \n",
       "50%      2.000000  \n",
       "75%      4.000000  \n",
       "max      8.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[3]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307ae1cd-6aa0-4cc8-9efd-fb3f1db3811e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:32.899097Z",
     "iopub.status.busy": "2024-04-03T14:51:32.898133Z",
     "iopub.status.idle": "2024-04-03T14:51:32.904670Z",
     "shell.execute_reply": "2024-04-03T14:51:32.903869Z",
     "shell.execute_reply.started": "2024-04-03T14:51:32.899061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the sentence_chunks into it's own individual chunks to reduce size further.\n",
    "import re\n",
    "all_pdf_formatted = []\n",
    "def final_chunk_dict(all_content, all_pdf_formatted):\n",
    "    for doc in tqdm(all_content):\n",
    "        for page in doc:\n",
    "            for sentence_chunk in page[\"sentence_chunks\"]:\n",
    "                chunk_ = {}\n",
    "                chunk_[\"pg_num\"] = page[\"pg_num\"]\n",
    "                # Join sentences like a paragraph structure\n",
    "                joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "                joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # spacing issue after join.\n",
    "                chunk_[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "                #write metadata\n",
    "                chunk_[\"chunk_num_chars\"] = len(joined_sentence_chunk)\n",
    "                chunk_[\"chunk_num_tokens\"] = len(joined_sentence_chunk) / 4\n",
    "                chunk_[\"chunk_num_words\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "                chunk_[\"doc_name\"] = page[\"doc_name\"]\n",
    "                all_pdf_formatted.append(chunk_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ddfa4b0-a5c3-48c7-aede-27464f121c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:34.516720Z",
     "iopub.status.busy": "2024-04-03T14:51:34.516074Z",
     "iopub.status.idle": "2024-04-03T14:51:34.588423Z",
     "shell.execute_reply": "2024-04-03T14:51:34.587797Z",
     "shell.execute_reply.started": "2024-04-03T14:51:34.516678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9ecaf0b9d4dbc9f492a5e71cb5c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_chunk_dict(all_content_, all_pdf_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cfa6892-493c-4473-bd53-9d1ad33c9ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:36.160130Z",
     "iopub.status.busy": "2024-04-03T14:51:36.159305Z",
     "iopub.status.idle": "2024-04-03T14:51:36.164704Z",
     "shell.execute_reply": "2024-04-03T14:51:36.164124Z",
     "shell.execute_reply.started": "2024-04-03T14:51:36.160097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pg_num': 7,\n",
       "  'sentence_chunk': '45620.9Summary',\n",
       "  'chunk_num_chars': 14,\n",
       "  'chunk_num_tokens': 3.5,\n",
       "  'chunk_num_words': 1,\n",
       "  'doc_name': 'Standford NLP'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_pdf_formatted,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c23de83b-4b7b-4101-b314-77b702494f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:37.425106Z",
     "iopub.status.busy": "2024-04-03T14:51:37.424029Z",
     "iopub.status.idle": "2024-04-03T14:51:37.436316Z",
     "shell.execute_reply": "2024-04-03T14:51:37.435223Z",
     "shell.execute_reply.started": "2024-04-03T14:51:37.425075Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = pd.DataFrame(all_pdf_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8c02a5a-9cec-4932-bedb-880c7d12f996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:38.405733Z",
     "iopub.status.busy": "2024-04-03T14:51:38.404605Z",
     "iopub.status.idle": "2024-04-03T14:51:38.421378Z",
     "shell.execute_reply": "2024-04-03T14:51:38.420815Z",
     "shell.execute_reply.started": "2024-04-03T14:51:38.405699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>273.468599</td>\n",
       "      <td>417.125814</td>\n",
       "      <td>104.281453</td>\n",
       "      <td>58.060912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>245.631995</td>\n",
       "      <td>545.919045</td>\n",
       "      <td>136.479761</td>\n",
       "      <td>76.180003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>257.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>189.500000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  4761.000000      4761.000000       4761.000000      4761.000000\n",
       "mean    273.468599       417.125814        104.281453        58.060912\n",
       "std     245.631995       545.919045        136.479761        76.180003\n",
       "min       1.000000         0.000000          0.000000         1.000000\n",
       "25%       7.000000        27.000000          6.750000         3.000000\n",
       "50%     257.000000       134.000000         33.500000        15.000000\n",
       "75%     548.000000       758.000000        189.500000       109.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9ccb5bd-4d6a-4a8d-9498-dd215852e5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:39.270498Z",
     "iopub.status.busy": "2024-04-03T14:51:39.269653Z",
     "iopub.status.idle": "2024-04-03T14:51:39.275424Z",
     "shell.execute_reply": "2024-04-03T14:51:39.274793Z",
     "shell.execute_reply.started": "2024-04-03T14:51:39.270466Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = all_pdf_formatted_df[all_pdf_formatted_df['chunk_num_tokens'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c257ff8-57f3-4d3f-b73b-3ba09ac70d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:40.086299Z",
     "iopub.status.busy": "2024-04-03T14:51:40.085502Z",
     "iopub.status.idle": "2024-04-03T14:51:40.099781Z",
     "shell.execute_reply": "2024-04-03T14:51:40.099229Z",
     "shell.execute_reply.started": "2024-04-03T14:51:40.086267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "      <th>doc_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>51</td>\n",
       "      <td>It was my first time in the Big Apple, and I h...</td>\n",
       "      <td>351</td>\n",
       "      <td>87.75</td>\n",
       "      <td>70</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>51</td>\n",
       "      <td>Iloved running around and playing fetchWe also...</td>\n",
       "      <td>321</td>\n",
       "      <td>80.25</td>\n",
       "      <td>55</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>52</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>704</td>\n",
       "      <td>176.00</td>\n",
       "      <td>107</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>53</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>347</td>\n",
       "      <td>86.75</td>\n",
       "      <td>61</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>53</td>\n",
       "      <td>The roots of this equation are 𝑥1 = 5 and𝑥2 = ...</td>\n",
       "      <td>353</td>\n",
       "      <td>88.25</td>\n",
       "      <td>59</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>53</td>\n",
       "      <td>The model shows good understanding of the task...</td>\n",
       "      <td>472</td>\n",
       "      <td>118.00</td>\n",
       "      <td>69</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>54</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>687</td>\n",
       "      <td>171.75</td>\n",
       "      <td>109</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>57</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>398</td>\n",
       "      <td>99.50</td>\n",
       "      <td>62</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>60</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>2132</td>\n",
       "      <td>533.00</td>\n",
       "      <td>345</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>62</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>627</td>\n",
       "      <td>156.75</td>\n",
       "      <td>94</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>1</td>\n",
       "      <td>BART: Denoising Sequence-to-Sequence Pre-train...</td>\n",
       "      <td>2061</td>\n",
       "      <td>515.25</td>\n",
       "      <td>268</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>1</td>\n",
       "      <td>Wealso report ablation experiments that replic...</td>\n",
       "      <td>1360</td>\n",
       "      <td>340.00</td>\n",
       "      <td>186</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>1</td>\n",
       "      <td>BART is a denoising autoencoder builtwith a se...</td>\n",
       "      <td>1733</td>\n",
       "      <td>433.25</td>\n",
       "      <td>244</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>2</td>\n",
       "      <td>Bidirectional EncoderA _ C _ E B    D  (a) BER...</td>\n",
       "      <td>1504</td>\n",
       "      <td>376.00</td>\n",
       "      <td>229</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>2</td>\n",
       "      <td>The corrupted document (left) is encoded witha...</td>\n",
       "      <td>2180</td>\n",
       "      <td>545.00</td>\n",
       "      <td>306</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>2</td>\n",
       "      <td>The architecture is closely related to that us...</td>\n",
       "      <td>1362</td>\n",
       "      <td>340.50</td>\n",
       "      <td>184</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>3</td>\n",
       "      <td>D _ E . A _C _ E . C D E A BDocument RotationT...</td>\n",
       "      <td>188</td>\n",
       "      <td>47.00</td>\n",
       "      <td>35</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>3</td>\n",
       "      <td>A B C . Sentence PermutationFigure 2: Transfor...</td>\n",
       "      <td>904</td>\n",
       "      <td>226.00</td>\n",
       "      <td>134</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>3</td>\n",
       "      <td>Text inﬁll-ing teaches the model to predict ho...</td>\n",
       "      <td>1756</td>\n",
       "      <td>439.00</td>\n",
       "      <td>245</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>3</td>\n",
       "      <td>Here, the encoder in-put is the input sequence...</td>\n",
       "      <td>1059</td>\n",
       "      <td>264.75</td>\n",
       "      <td>154</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>3</td>\n",
       "      <td>The new encoder can use aseparate vocabulary f...</td>\n",
       "      <td>1127</td>\n",
       "      <td>281.75</td>\n",
       "      <td>157</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>4</td>\n",
       "      <td>Pre-trained DecoderPre-trained EncoderlabelA B...</td>\n",
       "      <td>1186</td>\n",
       "      <td>296.50</td>\n",
       "      <td>175</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>4</td>\n",
       "      <td>For refer-ence, we compare our implementations...</td>\n",
       "      <td>2187</td>\n",
       "      <td>546.75</td>\n",
       "      <td>317</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>4</td>\n",
       "      <td>We ﬁnd the former works better for BARTmodels,...</td>\n",
       "      <td>1398</td>\n",
       "      <td>349.50</td>\n",
       "      <td>198</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>5</td>\n",
       "      <td>ModelSQuAD 1.1MNLIELI5XSumConvAI2CNN/DMF1AccPP...</td>\n",
       "      <td>1343</td>\n",
       "      <td>335.75</td>\n",
       "      <td>129</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>5</td>\n",
       "      <td>Performance varies considerably across tasks, ...</td>\n",
       "      <td>1689</td>\n",
       "      <td>422.25</td>\n",
       "      <td>209</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>5</td>\n",
       "      <td>Some of this dif-ference is likely due to not ...</td>\n",
       "      <td>1291</td>\n",
       "      <td>322.75</td>\n",
       "      <td>187</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>6</td>\n",
       "      <td>SQuAD 1.1SQuAD 2.0MNLISSTQQPQNLISTS-BRTEMRPCCo...</td>\n",
       "      <td>1860</td>\n",
       "      <td>465.00</td>\n",
       "      <td>186</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>6</td>\n",
       "      <td>We use the same pre-training data as Liu et al...</td>\n",
       "      <td>1684</td>\n",
       "      <td>421.00</td>\n",
       "      <td>223</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>6</td>\n",
       "      <td>During generation, we set beam size as 5,remov...</td>\n",
       "      <td>1315</td>\n",
       "      <td>328.75</td>\n",
       "      <td>162</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>7</td>\n",
       "      <td>ELI5R1R2RLBest Extractive23.53.117.5Language M...</td>\n",
       "      <td>925</td>\n",
       "      <td>231.25</td>\n",
       "      <td>98</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>7</td>\n",
       "      <td>We ﬁnd BART outperforms the best pre-vious wor...</td>\n",
       "      <td>1841</td>\n",
       "      <td>460.25</td>\n",
       "      <td>246</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>7</td>\n",
       "      <td>However, model output is also highly ab-stract...</td>\n",
       "      <td>974</td>\n",
       "      <td>243.50</td>\n",
       "      <td>129</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>7</td>\n",
       "      <td>GPT (Radford et al., 2018) only models left-wa...</td>\n",
       "      <td>919</td>\n",
       "      <td>229.75</td>\n",
       "      <td>128</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>7</td>\n",
       "      <td>Predictions are not made auto-regressively, re...</td>\n",
       "      <td>712</td>\n",
       "      <td>178.00</td>\n",
       "      <td>101</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>8</td>\n",
       "      <td>Source Document (abbreviated)BART SummaryThe r...</td>\n",
       "      <td>1245</td>\n",
       "      <td>311.25</td>\n",
       "      <td>188</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>8</td>\n",
       "      <td>He said, “I hope that Anne Sacoolas will come ...</td>\n",
       "      <td>979</td>\n",
       "      <td>244.75</td>\n",
       "      <td>146</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>8</td>\n",
       "      <td>On Wednesday, Turkey began a militaryoffensive...</td>\n",
       "      <td>808</td>\n",
       "      <td>202.00</td>\n",
       "      <td>121</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>8</td>\n",
       "      <td>It was an event speciﬁcally designed tohelp Ki...</td>\n",
       "      <td>789</td>\n",
       "      <td>197.25</td>\n",
       "      <td>117</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>8</td>\n",
       "      <td>Summaries combine information from across the ...</td>\n",
       "      <td>1079</td>\n",
       "      <td>269.75</td>\n",
       "      <td>139</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>9</td>\n",
       "      <td>ReferencesEneko Agirre, Llu’is M‘arquez, and R...</td>\n",
       "      <td>643</td>\n",
       "      <td>160.75</td>\n",
       "      <td>69</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>9</td>\n",
       "      <td>Springer, 2006. Jacob Devlin, Ming-Wei Chang, ...</td>\n",
       "      <td>788</td>\n",
       "      <td>197.00</td>\n",
       "      <td>85</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>9</td>\n",
       "      <td>doi: 10.18653/v1/N19-1423. URL https://www.acl...</td>\n",
       "      <td>833</td>\n",
       "      <td>208.25</td>\n",
       "      <td>92</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>9</td>\n",
       "      <td>arXiv preprint arXiv:1905.03197, 2019. Sergey ...</td>\n",
       "      <td>693</td>\n",
       "      <td>173.25</td>\n",
       "      <td>82</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>9</td>\n",
       "      <td>Gaussian error lin-ear units (gelus)arXiv prep...</td>\n",
       "      <td>385</td>\n",
       "      <td>96.25</td>\n",
       "      <td>45</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>9</td>\n",
       "      <td>1693–1701, 2015. Mandar Joshi, Danqi Chen, Yin...</td>\n",
       "      <td>617</td>\n",
       "      <td>154.25</td>\n",
       "      <td>70</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>9</td>\n",
       "      <td>The Winograd schema challengeIn AAAISpring Sym...</td>\n",
       "      <td>895</td>\n",
       "      <td>223.75</td>\n",
       "      <td>103</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>9</td>\n",
       "      <td>Efﬁcient estimation of word representationsin ...</td>\n",
       "      <td>917</td>\n",
       "      <td>229.25</td>\n",
       "      <td>86</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>10</td>\n",
       "      <td>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyr...</td>\n",
       "      <td>1131</td>\n",
       "      <td>282.75</td>\n",
       "      <td>134</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4760</th>\n",
       "      <td>10</td>\n",
       "      <td>In Advances in neural information processingsy...</td>\n",
       "      <td>703</td>\n",
       "      <td>175.75</td>\n",
       "      <td>79</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pg_num                                     sentence_chunk  \\\n",
       "4710      51  It was my first time in the Big Apple, and I h...   \n",
       "4711      51  Iloved running around and playing fetchWe also...   \n",
       "4712      52  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4713      53  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4714      53  The roots of this equation are 𝑥1 = 5 and𝑥2 = ...   \n",
       "4715      53  The model shows good understanding of the task...   \n",
       "4716      54  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4717      57  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4718      60  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4719      62  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4720       1  BART: Denoising Sequence-to-Sequence Pre-train...   \n",
       "4721       1  Wealso report ablation experiments that replic...   \n",
       "4722       1  BART is a denoising autoencoder builtwith a se...   \n",
       "4723       2  Bidirectional EncoderA _ C _ E B    D  (a) BER...   \n",
       "4724       2  The corrupted document (left) is encoded witha...   \n",
       "4725       2  The architecture is closely related to that us...   \n",
       "4727       3  D _ E . A _C _ E . C D E A BDocument RotationT...   \n",
       "4728       3  A B C . Sentence PermutationFigure 2: Transfor...   \n",
       "4729       3  Text inﬁll-ing teaches the model to predict ho...   \n",
       "4730       3  Here, the encoder in-put is the input sequence...   \n",
       "4731       3  The new encoder can use aseparate vocabulary f...   \n",
       "4732       4  Pre-trained DecoderPre-trained EncoderlabelA B...   \n",
       "4733       4  For refer-ence, we compare our implementations...   \n",
       "4734       4  We ﬁnd the former works better for BARTmodels,...   \n",
       "4735       5  ModelSQuAD 1.1MNLIELI5XSumConvAI2CNN/DMF1AccPP...   \n",
       "4736       5  Performance varies considerably across tasks, ...   \n",
       "4737       5  Some of this dif-ference is likely due to not ...   \n",
       "4738       6  SQuAD 1.1SQuAD 2.0MNLISSTQQPQNLISTS-BRTEMRPCCo...   \n",
       "4739       6  We use the same pre-training data as Liu et al...   \n",
       "4740       6  During generation, we set beam size as 5,remov...   \n",
       "4741       7  ELI5R1R2RLBest Extractive23.53.117.5Language M...   \n",
       "4742       7  We ﬁnd BART outperforms the best pre-vious wor...   \n",
       "4743       7  However, model output is also highly ab-stract...   \n",
       "4744       7  GPT (Radford et al., 2018) only models left-wa...   \n",
       "4745       7  Predictions are not made auto-regressively, re...   \n",
       "4746       8  Source Document (abbreviated)BART SummaryThe r...   \n",
       "4747       8  He said, “I hope that Anne Sacoolas will come ...   \n",
       "4748       8  On Wednesday, Turkey began a militaryoffensive...   \n",
       "4749       8  It was an event speciﬁcally designed tohelp Ki...   \n",
       "4750       8  Summaries combine information from across the ...   \n",
       "4751       9  ReferencesEneko Agirre, Llu’is M‘arquez, and R...   \n",
       "4752       9  Springer, 2006. Jacob Devlin, Ming-Wei Chang, ...   \n",
       "4753       9  doi: 10.18653/v1/N19-1423. URL https://www.acl...   \n",
       "4754       9  arXiv preprint arXiv:1905.03197, 2019. Sergey ...   \n",
       "4755       9  Gaussian error lin-ear units (gelus)arXiv prep...   \n",
       "4756       9  1693–1701, 2015. Mandar Joshi, Danqi Chen, Yin...   \n",
       "4757       9  The Winograd schema challengeIn AAAISpring Sym...   \n",
       "4758       9  Efﬁcient estimation of word representationsin ...   \n",
       "4759      10  Pranav Rajpurkar, Jian Zhang, Konstantin Lopyr...   \n",
       "4760      10  In Advances in neural information processingsy...   \n",
       "\n",
       "      chunk_num_chars  chunk_num_tokens  chunk_num_words      doc_name  \n",
       "4710              351             87.75               70  Gemini_paper  \n",
       "4711              321             80.25               55  Gemini_paper  \n",
       "4712              704            176.00              107  Gemini_paper  \n",
       "4713              347             86.75               61  Gemini_paper  \n",
       "4714              353             88.25               59  Gemini_paper  \n",
       "4715              472            118.00               69  Gemini_paper  \n",
       "4716              687            171.75              109  Gemini_paper  \n",
       "4717              398             99.50               62  Gemini_paper  \n",
       "4718             2132            533.00              345  Gemini_paper  \n",
       "4719              627            156.75               94  Gemini_paper  \n",
       "4720             2061            515.25              268          BART  \n",
       "4721             1360            340.00              186          BART  \n",
       "4722             1733            433.25              244          BART  \n",
       "4723             1504            376.00              229          BART  \n",
       "4724             2180            545.00              306          BART  \n",
       "4725             1362            340.50              184          BART  \n",
       "4727              188             47.00               35          BART  \n",
       "4728              904            226.00              134          BART  \n",
       "4729             1756            439.00              245          BART  \n",
       "4730             1059            264.75              154          BART  \n",
       "4731             1127            281.75              157          BART  \n",
       "4732             1186            296.50              175          BART  \n",
       "4733             2187            546.75              317          BART  \n",
       "4734             1398            349.50              198          BART  \n",
       "4735             1343            335.75              129          BART  \n",
       "4736             1689            422.25              209          BART  \n",
       "4737             1291            322.75              187          BART  \n",
       "4738             1860            465.00              186          BART  \n",
       "4739             1684            421.00              223          BART  \n",
       "4740             1315            328.75              162          BART  \n",
       "4741              925            231.25               98          BART  \n",
       "4742             1841            460.25              246          BART  \n",
       "4743              974            243.50              129          BART  \n",
       "4744              919            229.75              128          BART  \n",
       "4745              712            178.00              101          BART  \n",
       "4746             1245            311.25              188          BART  \n",
       "4747              979            244.75              146          BART  \n",
       "4748              808            202.00              121          BART  \n",
       "4749              789            197.25              117          BART  \n",
       "4750             1079            269.75              139          BART  \n",
       "4751              643            160.75               69          BART  \n",
       "4752              788            197.00               85          BART  \n",
       "4753              833            208.25               92          BART  \n",
       "4754              693            173.25               82          BART  \n",
       "4755              385             96.25               45          BART  \n",
       "4756              617            154.25               70          BART  \n",
       "4757              895            223.75              103          BART  \n",
       "4758              917            229.25               86          BART  \n",
       "4759             1131            282.75              134          BART  \n",
       "4760              703            175.75               79          BART  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e89eddc-7e15-42e2-84e3-bede788e2097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:40.952171Z",
     "iopub.status.busy": "2024-04-03T14:51:40.951481Z",
     "iopub.status.idle": "2024-04-03T14:51:40.968934Z",
     "shell.execute_reply": "2024-04-03T14:51:40.968433Z",
     "shell.execute_reply.started": "2024-04-03T14:51:40.952133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dece0490-ecdd-4d8a-bfc8-061c0e893619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:42.199018Z",
     "iopub.status.busy": "2024-04-03T14:51:42.198102Z",
     "iopub.status.idle": "2024-04-03T14:51:42.207729Z",
     "shell.execute_reply": "2024-04-03T14:51:42.206865Z",
     "shell.execute_reply.started": "2024-04-03T14:51:42.198973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n",
      "979\n",
      "398CHAPTER 18•DEPENDENCY PARSINGleading to a parse for the following example. Book me the morningﬂightiobjobjdetcompoundroot(18.7)Let’s consider the state of the conﬁguration at Step 2, after the word me has beenpushed onto the stack. StackWord ListRelations[root, book, me] [the, morning, ﬂight]The correct operator to apply here is RIGHTARC which assigns book as the head ofme and pops me from the stack resulting in the following conﬁguration. StackWord ListRelations[root, book] [the, morning, ﬂight] (book → me)After several subsequent applications of the SHIFT and LEFTARC operators, the con-ﬁguration in Step 6 looks like the following:StackWord ListRelations[root, book, the, morning, ﬂight][](book → me)Here, all the remaining words have been passed onto the stack and all that is leftto do is to apply the appropriate reduce operatorsIn the current conﬁguration, weemploy the LEFTARC operator resulting in the following state. StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.\n",
      "234.0\n",
      "\n",
      "StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.\n"
     ]
    }
   ],
   "source": [
    "# Using only 1 step for reducing max_tokens\n",
    "# Optimize later using recursion , if max_tokens_length still greater than 384\n",
    "# Testing:\n",
    "\n",
    "sample = {'pg_num': 406,\n",
    "  'sentence_chunk': '398CHAPTER 18•DEPENDENCY PARSINGleading to a parse for the following example. Book me the morningﬂightiobjobjdetcompoundroot(18.7)Let’s consider the state of the conﬁguration at Step 2, after the word me has beenpushed onto the stack. StackWord ListRelations[root, book, me] [the, morning, ﬂight]The correct operator to apply here is RIGHTARC which assigns book as the head ofme and pops me from the stack resulting in the following conﬁguration. StackWord ListRelations[root, book] [the, morning, ﬂight] (book → me)After several subsequent applications of the SHIFT and LEFTARC operators, the con-ﬁguration in Step 6 looks like the following:StackWord ListRelations[root, book, the, morning, ﬂight][](book → me)Here, all the remaining words have been passed onto the stack and all that is leftto do is to apply the appropriate reduce operatorsIn the current conﬁguration, weemploy the LEFTARC operator resulting in the following state. StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.',\n",
    "  'chunk_num_chars': 1959,\n",
    "  'chunk_num_tokens': 489.75,\n",
    "  'chunk_num_words': 286,\n",
    "  'doc_name': 'Standford NLP'}\n",
    "\n",
    "\n",
    "\n",
    "length_chunk = len(sample['sentence_chunk'])\n",
    "print(length_chunk//2)\n",
    "# Split it into two\n",
    "\n",
    "midpoint = length_chunk // 2\n",
    "print(midpoint)\n",
    "# Find the last period before the midpoint\n",
    "split_point = sample['sentence_chunk'].rfind('. ', 0, midpoint)\n",
    "\n",
    "# Split the text into two parts\n",
    "first_half = sample['sentence_chunk'][:split_point+1]  # +1 to include the period\n",
    "second_half = sample['sentence_chunk'][split_point+2:]  # +2 to skip the period and space\n",
    "\n",
    "print(sample['sentence_chunk'])\n",
    "print(len(first_half)/4)\n",
    "print()\n",
    "print(second_half)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9534e519-4357-4938-9f88-f0235e1eb5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:43.603031Z",
     "iopub.status.busy": "2024-04-03T14:51:43.602118Z",
     "iopub.status.idle": "2024-04-03T14:51:43.610379Z",
     "shell.execute_reply": "2024-04-03T14:51:43.609817Z",
     "shell.execute_reply.started": "2024-04-03T14:51:43.602995Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Optimize later using recursion , if max_tokens_length still greater than 384.\n",
    "# For now just using 1/2 the length\n",
    "# Rectifying the max_length tokens\n",
    "def check_and_rectify_token_length(docs_df):\n",
    "    # 384 is the max_token_length for some smaller models\n",
    "    df_exceeding_length = docs_df[docs_df['chunk_num_tokens'] > 384]\n",
    "    # Split further\n",
    "    # Remove the df\n",
    "    docs_df = docs_df[docs_df['chunk_num_tokens'] <= 384]\n",
    "    # Convert them to dict\n",
    "    doc_token_length_exceeded = df_exceeding_length.to_dict(\"records\")\n",
    "    # Run the splitter further. Split the chunks into two\n",
    "    for doc in doc_token_length_exceeded:\n",
    "        # Get sentencfe length\n",
    "        doc_new_1 = {}\n",
    "        doc_new_2 = {}\n",
    "        length_chunk = len(doc['sentence_chunk'])\n",
    "        # Split it into two\n",
    "        # Assume `text` is your long text\n",
    "        # Find the midpoint\n",
    "        midpoint = length_chunk // 2\n",
    "\n",
    "        # Find the last period before the midpoint\n",
    "        split_point = doc['sentence_chunk'].rfind('. ', 0, midpoint)\n",
    "\n",
    "        # Split the text into two parts\n",
    "        first_half = doc['sentence_chunk'][:split_point+1]  # +1 to include the period\n",
    "        second_half = doc['sentence_chunk'][split_point+2:]  # +2 to skip the period and space\n",
    "\n",
    "        # Reclaculate all metadata except pg_num and doc_name            \n",
    "        doc_new_1['pg_num'] = doc['pg_num']\n",
    "        doc_new_2['pg_num'] = doc['pg_num']\n",
    "\n",
    "        doc_new_1['doc_name'] = doc['doc_name']\n",
    "        doc_new_2['doc_name'] = doc['doc_name']\n",
    "\n",
    "\n",
    "        #write metadata\n",
    "        doc_new_1['sentence_chunk'] = first_half\n",
    "        doc_new_1[\"chunk_num_chars\"] = len(first_half)\n",
    "        doc_new_1[\"chunk_num_tokens\"] = len(first_half) / 4\n",
    "        doc_new_1[\"chunk_num_words\"] = len([word for word in first_half.split(\" \")])\n",
    "\n",
    "        #write metadata\n",
    "        doc_new_2['sentence_chunk'] = second_half\n",
    "        doc_new_2[\"chunk_num_chars\"] = len(first_half)\n",
    "        doc_new_2[\"chunk_num_tokens\"] = len(first_half) / 4\n",
    "        doc_new_2[\"chunk_num_words\"] = len([word for word in first_half.split(\" \")])\n",
    "        \n",
    "\n",
    "        # Add it to the original dataframe\n",
    "\n",
    "        docs_df = pd.concat([docs_df, pd.DataFrame([doc_new_1]), pd.DataFrame([doc_new_2])], ignore_index=True) \n",
    "    return docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b861a578-c8e8-4513-864f-b187f295e7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:44.887536Z",
     "iopub.status.busy": "2024-04-03T14:51:44.886826Z",
     "iopub.status.idle": "2024-04-03T14:51:44.900445Z",
     "shell.execute_reply": "2024-04-03T14:51:44.899806Z",
     "shell.execute_reply.started": "2024-04-03T14:51:44.887501Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_backup = all_pdf_formatted_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fce5eea-49da-43b8-a1c4-eb045d3cca5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:46.020786Z",
     "iopub.status.busy": "2024-04-03T14:51:46.019947Z",
     "iopub.status.idle": "2024-04-03T14:51:46.041635Z",
     "shell.execute_reply": "2024-04-03T14:51:46.041058Z",
     "shell.execute_reply.started": "2024-04-03T14:51:46.020749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_pdf_formatted_backup).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f723275-1048-4dfe-917b-848f14e07f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:47.601820Z",
     "iopub.status.busy": "2024-04-03T14:51:47.600874Z",
     "iopub.status.idle": "2024-04-03T14:51:47.915754Z",
     "shell.execute_reply": "2024-04-03T14:51:47.915051Z",
     "shell.execute_reply.started": "2024-04-03T14:51:47.601760Z"
    }
   },
   "outputs": [],
   "source": [
    "#Running rectified\n",
    "\n",
    "all_pdf_formatted_df = check_and_rectify_token_length(all_pdf_formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21288ebb-439e-4fe0-96e6-8b7a6d9038c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:48.604957Z",
     "iopub.status.busy": "2024-04-03T14:51:48.604135Z",
     "iopub.status.idle": "2024-04-03T14:51:48.621539Z",
     "shell.execute_reply": "2024-04-03T14:51:48.620887Z",
     "shell.execute_reply.started": "2024-04-03T14:51:48.604925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>355.840078</td>\n",
       "      <td>503.923807</td>\n",
       "      <td>125.980952</td>\n",
       "      <td>70.375384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.237183</td>\n",
       "      <td>431.908522</td>\n",
       "      <td>107.977130</td>\n",
       "      <td>64.635809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>456.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>552.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>212.500000</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>1534.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3583.000000      3583.000000       3583.000000      3583.000000\n",
       "mean    355.840078       503.923807        125.980952        70.375384\n",
       "std     217.237183       431.908522        107.977130        64.635809\n",
       "min       1.000000         0.000000          0.000000         1.000000\n",
       "25%     136.000000       117.000000         29.250000        13.000000\n",
       "50%     456.000000       355.000000         88.750000        46.000000\n",
       "75%     552.000000       850.000000        212.500000       123.000000\n",
       "max     570.000000      1534.000000        383.500000       287.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the increase in chunk_num_tokens count \n",
    "# max_ is less than 384\n",
    "# min token 0\n",
    "# \n",
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "649284c6-537d-4dd9-a0d1-4b4b22edeac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:49.742673Z",
     "iopub.status.busy": "2024-04-03T14:51:49.741656Z",
     "iopub.status.idle": "2024-04-03T14:51:49.763434Z",
     "shell.execute_reply": "2024-04-03T14:51:49.762905Z",
     "shell.execute_reply.started": "2024-04-03T14:51:49.742673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_pdf_formatted_backup).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f509e93b-3a25-407c-a4aa-b07dbe3b3886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:51.935426Z",
     "iopub.status.busy": "2024-04-03T14:51:51.934412Z",
     "iopub.status.idle": "2024-04-03T14:51:51.948652Z",
     "shell.execute_reply": "2024-04-03T14:51:51.947728Z",
     "shell.execute_reply.started": "2024-04-03T14:51:51.935380Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_dict = all_pdf_formatted_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1be24a2d-85a0-4caf-aa90-397e6fe19d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:53.062755Z",
     "iopub.status.busy": "2024-04-03T14:51:53.061840Z",
     "iopub.status.idle": "2024-04-03T14:51:53.067666Z",
     "shell.execute_reply": "2024-04-03T14:51:53.067099Z",
     "shell.execute_reply.started": "2024-04-03T14:51:53.062721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pg_num': 568,\n",
       "  'sentence_chunk': 'Hen-derson2016The dialog state track-ing challenge series: A reviewDia-logue & Discourse, 7(3):4–33. Williams, JD',\n",
       "  'chunk_num_chars': 113,\n",
       "  'chunk_num_tokens': 28.25,\n",
       "  'chunk_num_words': 13,\n",
       "  'doc_name': 'Standford NLP'},\n",
       " {'pg_num': 547,\n",
       "  'sentence_chunk': 'Agnew, GIlharco, DGroen-eveld, MMitchell, and MGardner.2021. Documenting large webtextcorpora: A case study on the colos-sal clean crawled corpus',\n",
       "  'chunk_num_chars': 145,\n",
       "  'chunk_num_tokens': 36.25,\n",
       "  'chunk_num_words': 18,\n",
       "  'doc_name': 'Standford NLP'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_pdf_formatted_dict,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea76dc7-f4b1-4dac-a5fb-b75b7b11a974",
   "metadata": {},
   "source": [
    "## Embedding and the retriever\n",
    "- Generate the embeddings for query and generate embeddings for the documents\n",
    "- Store the document embeddings in the vector store : Use FAISS\n",
    "- Serialize the vector store for later use\n",
    "- Test it later using load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57be59c9-3de0-428b-af6c-f9a77338f2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:51:56.543088Z",
     "iopub.status.busy": "2024-04-03T14:51:56.542113Z",
     "iopub.status.idle": "2024-04-03T14:52:03.503266Z",
     "shell.execute_reply": "2024-04-03T14:52:03.502157Z",
     "shell.execute_reply.started": "2024-04-03T14:51:56.543083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the embeddings for query and generate embeddings for the documents\n",
    "# Store the document embeddings in the vector store : Use FAISS\n",
    "# Serialize the vector store for later use\n",
    "# Test it later using load\n",
    "# Create the Retriever function to return the scores and indices. Create the print function to print relevant score, docs\n",
    "# Import the llm for generation. Use bitsandBytes config. Create prompt template\n",
    "# Add the context to prompt along with query format.\n",
    "# apply the chat template \n",
    "# Generate the answer using LLM\n",
    "\n",
    "# Sample testing\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "query_sample = \"What does Darryl's friends do?\"\n",
    "answer_samples = [\"Darryl pursued his Masters in Computer Science\", \"Darryl's friends study Information systems\",\"Studying Generative AI is a boost to the mind\"]\n",
    "\n",
    "answer_embeddings = embed_model.encode(answer_samples)\n",
    "query_embedding = embed_model.encode(query_sample)\n",
    "\n",
    "scores = util.cos_sim(query_embedding, answer_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e50a8ab-4945-4ef9-990b-535bb4db0c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:52:05.619355Z",
     "iopub.status.busy": "2024-04-03T14:52:05.618363Z",
     "iopub.status.idle": "2024-04-03T14:52:05.624883Z",
     "shell.execute_reply": "2024-04-03T14:52:05.623308Z",
     "shell.execute_reply.started": "2024-04-03T14:52:05.619318Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_similarity(scores, query_embedding, answer_embeddings, query, answers):\n",
    "    print(answer_embeddings.shape)\n",
    "    score = util.cos_sim(query_embedding, answer_embeddings)\n",
    "    score,idx = score, score.argmax(-1)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"ANSWER: {answers[idx]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1d82036-9f62-493d-9b6c-4adcdc947d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:52:07.050546Z",
     "iopub.status.busy": "2024-04-03T14:52:07.049712Z",
     "iopub.status.idle": "2024-04-03T14:52:07.055876Z",
     "shell.execute_reply": "2024-04-03T14:52:07.055109Z",
     "shell.execute_reply.started": "2024-04-03T14:52:07.050511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 768)\n",
      "QUERY: What does Darryl's friends do?\n",
      "ANSWER: Darryl's friends study Information systems\n"
     ]
    }
   ],
   "source": [
    "sentence_similarity(scores, query_embedding, answer_embeddings, query_sample, answer_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef52138a-a230-46bd-89b8-3f765dd77fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:52:20.004045Z",
     "iopub.status.busy": "2024-04-03T14:52:20.003711Z",
     "iopub.status.idle": "2024-04-03T14:54:26.204492Z",
     "shell.execute_reply": "2024-04-03T14:54:26.203603Z",
     "shell.execute_reply.started": "2024-04-03T14:52:20.004020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16d6b865e2c47ad908f92366ed1877a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 58s, sys: 4.39 s, total: 8min 2s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Encoding and Retriever\n",
    "\n",
    "# Change embed_model to 'cuda'\n",
    "embed_model.to('cuda')\n",
    "\n",
    "# Returns\n",
    "# By default, a 2d numpy array with shape [num_inputs, output_dimension] is returned.\n",
    "# If only one string input is provided, then the output is a 1d array with shape [output_dimension]. \n",
    "# If convert_to_tensor, a torch Tensor is returned instead.\n",
    "\n",
    "#Utility for encoding chunks of documents\n",
    "def encode_sentences(documents):\n",
    "    for doc in tqdm(documents):\n",
    "        doc[\"embeddings\"] = embed_model.encode(doc[\"sentence_chunk\"], convert_to_tensor=True)\n",
    "        \n",
    "encode_sentences(all_pdf_formatted_dict)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8964748e-df4e-40c2-a29d-643cdee76e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:55:58.155637Z",
     "iopub.status.busy": "2024-04-03T14:55:58.155208Z",
     "iopub.status.idle": "2024-04-03T14:55:58.160542Z",
     "shell.execute_reply": "2024-04-03T14:55:58.159519Z",
     "shell.execute_reply.started": "2024-04-03T14:55:58.155599Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74822bb4-fe86-4049-a8d1-1626465fc042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:00:41.020308Z",
     "iopub.status.busy": "2024-04-03T15:00:41.019230Z",
     "iopub.status.idle": "2024-04-03T15:01:12.638705Z",
     "shell.execute_reply": "2024-04-03T15:01:12.637720Z",
     "shell.execute_reply.started": "2024-04-03T15:00:41.020248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "3583\n",
      "CPU times: user 58.3 s, sys: 8.31 s, total: 1min 6s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using batched mode\n",
    "# sentence_chunks = [doc['sentence_chunk'] for doc in all_pdf_formatted_dict]\n",
    "# print(len(sentence_chunks))\n",
    "# print(len(all_pdf_formatted_dict))\n",
    "# print(sentence_chunks[3341])\n",
    "embed_model.to('cuda')\n",
    "\n",
    "\n",
    "def encode_sentences_batched(documents):\n",
    "    sentence_chunks = [doc['sentence_chunk'] for doc in documents]\n",
    "    print(len(sentence_chunks))\n",
    "    print(len(all_pdf_formatted_dict))\n",
    "    batched_sentence_embeddings = embed_model.encode(sentence_chunks, batch_size=15, convert_to_tensor=True)\n",
    "    return batched_sentence_embeddings\n",
    "\n",
    "batched_sentence_embeddings = encode_sentences_batched(all_pdf_formatted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fca0d177-bd63-4dc0-a1c9-0f4a1c90c991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:01:20.181044Z",
     "iopub.status.busy": "2024-04-03T15:01:20.180761Z",
     "iopub.status.idle": "2024-04-03T15:01:20.185525Z",
     "shell.execute_reply": "2024-04-03T15:01:20.184749Z",
     "shell.execute_reply.started": "2024-04-03T15:01:20.181017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings using batch_size=15: torch.Size([3583, 768])\n",
      "Embeddings without batched  3583 torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings using batch_size=15:\",batched_sentence_embeddings.shape)\n",
    "print(\"Embeddings without batched \",len(all_pdf_formatted_dict) , all_pdf_formatted_dict[0]['embeddings'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a3bae95-0566-4fc8-bc2c-0040021bc72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:19:38.937208Z",
     "iopub.status.busy": "2024-04-03T15:19:38.936862Z",
     "iopub.status.idle": "2024-04-03T15:19:38.942581Z",
     "shell.execute_reply": "2024-04-03T15:19:38.941706Z",
     "shell.execute_reply.started": "2024-04-03T15:19:38.937199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(batched_sentence_embeddings[0].type())\n",
    "print(batched_sentence_embeddings[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c9f8038-527e-4e54-bf7f-bda00470acd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:01:23.521294Z",
     "iopub.status.busy": "2024-04-03T15:01:23.520880Z",
     "iopub.status.idle": "2024-04-03T15:01:23.526876Z",
     "shell.execute_reply": "2024-04-03T15:01:23.525869Z",
     "shell.execute_reply.started": "2024-04-03T15:01:23.521259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_pdf_formatted_dict[0]['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e328a347-9e49-4d5b-b767-a5632a2a3e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:06:09.595925Z",
     "iopub.status.busy": "2024-04-03T15:06:09.594942Z",
     "iopub.status.idle": "2024-04-03T15:06:13.372458Z",
     "shell.execute_reply": "2024-04-03T15:06:13.371178Z",
     "shell.execute_reply.started": "2024-04-03T15:06:09.595880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu==1.8.0 in /usr/local/lib/python3.9/dist-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Storing embeddings in vectorStore\n",
    "# Experimental: Can use Pinecone, Milvus, AstraDB, MongoDB etc\n",
    "# Using FAISS as the vector store\n",
    "%pip install  faiss-cpu==1.8.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cdb97bcc-38ed-4276-8f05-eb641508332b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:32:14.866533Z",
     "iopub.status.busy": "2024-04-03T15:32:14.865959Z",
     "iopub.status.idle": "2024-04-03T15:32:14.905932Z",
     "shell.execute_reply": "2024-04-03T15:32:14.905060Z",
     "shell.execute_reply.started": "2024-04-03T15:32:14.866503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed_model SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "Dimension : 768\n",
      "Embeddings shape : (3583, 768) and type <class 'numpy.ndarray'>\n",
      "Adding FAISS index\n",
      "Added total indexes: 3583\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dimension = embed_model[1].word_embedding_dimension\n",
    "print(f\"Embed_model\",embed_model)\n",
    "print(f\"Dimension : {dimension}\")\n",
    "\n",
    "# def get_dimension(embedding_model):\n",
    "    \n",
    "index = faiss.IndexFlatL2(dimension)   \n",
    "\n",
    "# build the index, d=size of vectors \n",
    "# assume xb contains a n-by-d numpy matrix of type float32\n",
    "# index.add(xb)                          \n",
    "# add vectors to the index\n",
    "\n",
    "# TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "\n",
    "# Sol: https://stackoverflow.com/questions/53467215/convert-pytorch-cuda-tensor-to-numpy-array\n",
    "\n",
    "\n",
    "def convert_to_np(embeddings):\n",
    "    batched_embeddings_np = embeddings.detach().cpu().numpy()\n",
    "    return batched_embeddings_np\n",
    "\n",
    "# type(batched_embeddings_np)\n",
    "\n",
    "batched_sentence_embeddings_np = convert_to_np(batched_sentence_embeddings)\n",
    "print(f\"Embeddings shape : {batched_sentence_embeddings_np.shape} and type {type(batched_sentence_embeddings_np)}\")\n",
    "print(\"Adding FAISS index\")\n",
    "index.add(batched_sentence_embeddings_np)\n",
    "print(f\"Added total indexes: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b74339c1-f60f-486f-bafc-b57706dbac94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T15:35:50.774013Z",
     "iopub.status.busy": "2024-04-03T15:35:50.773213Z",
     "iopub.status.idle": "2024-04-03T15:35:50.796024Z",
     "shell.execute_reply": "2024-04-03T15:35:50.794917Z",
     "shell.execute_reply.started": "2024-04-03T15:35:50.773981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Serialize the index\n",
    "faiss.write_index(index, \"index_embeddings.bin\")\n",
    "index2 = faiss.read_index(\"index_embeddings.bin\")  # index2 is identical to index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1426e34-97f8-4358-b804-ecf64e121511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T16:04:24.723692Z",
     "iopub.status.busy": "2024-04-03T16:04:24.722706Z",
     "iopub.status.idle": "2024-04-03T16:05:08.837639Z",
     "shell.execute_reply": "2024-04-03T16:05:08.836803Z",
     "shell.execute_reply.started": "2024-04-03T16:04:24.723640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Database mapping of sentence-chunks and embeddings\n",
    "# For now use a csv to store the embeddings and text chunk mapping\n",
    "# For scaling: Database required : use mongodb or sql \n",
    "data_csv = pd.DataFrame(all_pdf_formatted_dict).to_csv(\"data_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d475b6f8-71a0-47bb-8899-a02e5d3e536a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T16:28:02.106236Z",
     "iopub.status.busy": "2024-04-03T16:28:02.105903Z",
     "iopub.status.idle": "2024-04-03T16:28:02.150531Z",
     "shell.execute_reply": "2024-04-03T16:28:02.149788Z",
     "shell.execute_reply.started": "2024-04-03T16:28:02.106209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) <class 'numpy.ndarray'>\n",
      "QUERY:How was Gemini invented? \n",
      "\n",
      ": ANS:{'pg_num': 57, 'sentence_chunk': 'Gemini: A Family of Highly Capable Multimodal Models9.4.1Reasoning and code generationPromptCreate a web app called \"Opossum Search\":1Every time you make a search query, it should redirect you to a google search with the samequery, but the word opossum before it.2It should be visually similar to Google search,3Instead of the google logo, it should have a picture of an opossum from the internet.4', 'chunk_num_chars': 398, 'chunk_num_tokens': 99.5, 'chunk_num_words': 62, 'doc_name': 'Gemini_paper', 'embeddings': tensor([ 5.7879e-02,  7.4607e-02, -3.0555e-02, -3.1337e-02, -1.6592e-02,\n",
      "        -2.1249e-02,  2.0056e-02,  1.6419e-02, -4.9016e-02, -4.0856e-02,\n",
      "        -2.3328e-03, -6.0466e-03, -4.7642e-02,  1.1492e-01, -5.0542e-03,\n",
      "        -1.0370e-01,  3.7736e-02, -4.6329e-03, -5.8520e-02, -2.2963e-02,\n",
      "        -3.4077e-02, -1.3310e-02, -5.1538e-03,  1.1935e-02,  6.6984e-03,\n",
      "        -5.1249e-02, -5.7770e-02,  2.8465e-02, -1.6979e-02, -6.2326e-02,\n",
      "        -2.7486e-02,  1.4423e-02, -6.4040e-03,  8.0667e-02,  2.4149e-06,\n",
      "        -4.0273e-02, -2.6936e-02,  8.3505e-03, -1.6559e-02, -1.0012e-02,\n",
      "         1.4826e-01,  3.8348e-02,  2.2073e-02,  1.0254e-02, -3.5411e-02,\n",
      "         6.9450e-03,  4.3633e-02, -9.7887e-03,  6.2993e-03,  5.7367e-02,\n",
      "         1.2876e-02,  3.3614e-02, -4.0589e-03, -4.2266e-03,  3.2912e-02,\n",
      "         3.9884e-02, -1.4570e-02, -1.7669e-02,  4.9093e-02,  8.0338e-02,\n",
      "         1.5139e-02,  2.5078e-02,  3.8542e-03,  3.9392e-03, -1.2802e-02,\n",
      "         1.6084e-02, -4.8851e-02, -7.2896e-02, -3.0366e-02, -2.7939e-02,\n",
      "         1.6939e-02,  6.3289e-04,  1.1739e-04,  9.5776e-02, -1.7846e-02,\n",
      "        -1.0823e-02, -1.6921e-02,  4.1661e-02,  2.9159e-02, -3.8153e-02,\n",
      "        -2.6747e-02,  1.4201e-02,  2.0431e-03, -7.1593e-03, -4.3956e-02,\n",
      "         5.6663e-02,  4.8020e-02,  1.3223e-02, -1.9456e-02, -4.4568e-02,\n",
      "        -2.6988e-02, -1.6907e-02,  8.5663e-03,  2.8711e-02, -3.5708e-02,\n",
      "        -2.1853e-02, -6.2002e-02,  1.6671e-02,  3.2494e-02, -3.4364e-02,\n",
      "         2.0129e-02,  2.6303e-02, -3.0503e-02,  2.1592e-02,  1.4061e-02,\n",
      "        -1.9161e-02, -3.7898e-02, -1.0835e-02, -1.3768e-02,  1.0588e-02,\n",
      "        -2.2562e-02,  6.5108e-03, -5.8800e-04,  1.8297e-02, -2.1286e-02,\n",
      "        -6.0064e-02, -1.1277e-02,  4.2738e-02,  2.7211e-02, -4.8846e-03,\n",
      "        -1.8147e-02,  3.3245e-02,  2.5449e-02,  8.2869e-03, -2.1629e-02,\n",
      "        -1.5143e-02,  2.0149e-02, -2.1453e-02,  3.4844e-02, -8.6405e-02,\n",
      "         2.1250e-02,  1.4669e-02, -2.7725e-02, -9.9053e-03, -4.2114e-03,\n",
      "         1.1004e-01,  1.3521e-02, -6.7876e-02, -2.2631e-03, -1.6326e-02,\n",
      "         3.1717e-02,  9.0162e-03, -3.1699e-02, -1.0847e-02, -4.6885e-02,\n",
      "         3.8791e-03,  8.5432e-03,  3.4320e-02,  1.9357e-02,  6.4005e-03,\n",
      "         1.9299e-02,  5.0219e-02, -7.6548e-02,  1.3288e-02, -2.4174e-03,\n",
      "         2.1916e-02,  3.4811e-02,  1.0952e-02, -1.5430e-02,  4.8874e-02,\n",
      "         3.5812e-02, -1.0800e-02, -3.3599e-02,  2.0401e-02, -7.2748e-02,\n",
      "        -6.5841e-03,  4.5588e-02, -5.6296e-03,  1.8112e-02,  1.8059e-02,\n",
      "        -3.4783e-02,  1.8665e-02, -5.4660e-06,  4.4785e-03,  5.2569e-02,\n",
      "        -3.3296e-02, -9.2599e-03,  5.2738e-02,  7.7308e-03, -4.6146e-02,\n",
      "        -6.1701e-02, -6.0966e-02, -3.0782e-02,  6.7743e-02, -4.2992e-02,\n",
      "         1.4094e-03, -5.5932e-02,  6.2492e-02, -1.2861e-02, -1.4434e-04,\n",
      "        -1.1794e-02, -9.2849e-03, -7.0974e-02,  8.1408e-03,  3.5328e-02,\n",
      "        -3.0749e-02, -6.0215e-03, -1.3834e-02,  2.3845e-02, -3.0092e-02,\n",
      "        -2.3482e-02, -4.2849e-02, -7.8706e-03,  5.2011e-02,  4.2945e-02,\n",
      "        -1.5644e-02, -1.1550e-02, -3.8039e-03, -1.9669e-02,  7.8719e-02,\n",
      "         1.1201e-01,  1.2754e-02, -3.2313e-02, -7.3753e-03, -1.1752e-02,\n",
      "        -3.8253e-03,  3.3245e-02,  4.2772e-02, -5.4255e-02,  4.7203e-02,\n",
      "         9.3998e-03,  6.7093e-02,  2.2844e-02,  8.7563e-03,  2.5428e-03,\n",
      "        -6.8890e-03, -3.1231e-02,  1.3230e-02, -5.9839e-03, -1.9833e-02,\n",
      "         1.0258e-02,  2.7627e-02,  2.8979e-02,  1.0023e-02,  1.9800e-02,\n",
      "         1.6723e-02,  5.4037e-02,  7.5039e-02,  4.3057e-02, -1.1445e-01,\n",
      "         3.9259e-02,  7.4645e-02,  1.8381e-02, -2.8921e-02,  6.4053e-02,\n",
      "        -5.0139e-02,  7.6114e-02, -1.7853e-02,  4.9688e-02, -2.7882e-03,\n",
      "         4.8268e-04,  2.9412e-02,  5.7888e-03, -7.1351e-03,  4.0198e-02,\n",
      "         1.2531e-02, -3.9707e-03,  6.5466e-03, -5.3448e-02, -4.8516e-02,\n",
      "        -1.9622e-02, -2.5210e-02,  1.7452e-02, -1.9213e-02,  1.2712e-02,\n",
      "         2.2685e-02, -2.2369e-02, -1.0316e-01, -6.7769e-03,  1.1906e-02,\n",
      "         1.7405e-04,  5.0811e-02,  3.2881e-02,  6.7049e-03, -2.4261e-02,\n",
      "         4.1706e-02,  2.3489e-03, -1.2490e-02, -2.9624e-02,  1.3649e-02,\n",
      "        -2.7433e-02, -1.0355e-01, -4.6670e-02, -4.1413e-02, -4.2910e-03,\n",
      "         1.8434e-02,  4.2455e-02,  1.7143e-02, -1.6984e-02, -1.5131e-02,\n",
      "        -4.0973e-02,  2.3570e-02,  1.2162e-02, -3.5059e-03,  3.4402e-02,\n",
      "        -3.3396e-02, -2.5306e-02,  6.0489e-02,  3.4271e-02,  3.5096e-02,\n",
      "         3.4704e-02, -2.7886e-02,  3.4755e-04, -1.9936e-02, -3.2859e-02,\n",
      "        -3.8418e-02,  2.1990e-02, -8.1151e-02,  1.9291e-02,  5.5134e-02,\n",
      "        -5.3710e-02, -1.3501e-02,  3.2778e-02,  1.2448e-02, -1.0618e-02,\n",
      "        -2.5940e-02, -6.7859e-03,  4.5768e-02, -3.3599e-02,  2.1601e-02,\n",
      "         2.9880e-03, -3.9555e-02,  8.2263e-03, -2.0916e-02,  1.8462e-02,\n",
      "         4.6675e-02, -7.9533e-03,  3.9460e-03,  1.2857e-02, -2.9740e-02,\n",
      "         3.0483e-02,  6.0116e-02, -4.1721e-03,  8.3267e-03,  4.7152e-02,\n",
      "         4.0168e-02, -3.4048e-02, -2.4456e-02, -7.2521e-03, -4.2209e-02,\n",
      "         3.1238e-03, -3.9607e-02, -3.5658e-02, -2.1292e-02, -2.7531e-02,\n",
      "         3.8389e-02,  5.6767e-02, -3.2279e-02, -1.5036e-01,  5.7643e-03,\n",
      "        -2.6544e-02, -5.2647e-03, -1.2412e-02,  7.7974e-03, -9.6166e-03,\n",
      "        -5.4897e-02,  8.2704e-03,  3.7873e-02,  1.3223e-02,  1.8357e-02,\n",
      "        -1.9036e-02, -7.3737e-03, -4.1753e-03, -2.1696e-02, -5.5464e-02,\n",
      "         3.9329e-02,  4.5523e-02,  3.2231e-03, -6.6518e-02, -1.1812e-02,\n",
      "        -4.8118e-02,  1.7833e-02,  7.5255e-03,  3.6056e-02,  2.3930e-02,\n",
      "         1.8974e-02, -2.5191e-03, -5.1772e-02, -2.1260e-02,  4.9999e-02,\n",
      "        -6.3759e-03, -2.5175e-02, -1.4829e-03, -1.7279e-02, -1.2485e-02,\n",
      "        -1.0860e-03,  1.3068e-02,  1.2459e-02,  2.4814e-02, -2.0815e-02,\n",
      "        -6.1585e-03, -1.1006e-02,  5.7226e-02, -3.3145e-02, -1.1426e-02,\n",
      "        -3.2099e-02, -6.9487e-02,  4.5407e-02, -4.6491e-02,  1.1748e-02,\n",
      "         1.5746e-02,  9.1807e-02,  4.2637e-02,  1.0088e-02, -2.6689e-02,\n",
      "        -3.8975e-02,  6.9840e-02,  2.4223e-02, -1.9442e-02, -9.6658e-02,\n",
      "        -5.4039e-02,  7.2404e-03,  4.4058e-02,  1.8852e-02,  1.6626e-02,\n",
      "        -3.0348e-02, -2.3016e-03, -3.9122e-02, -4.6400e-03, -3.6175e-02,\n",
      "         3.5773e-02, -1.9919e-02, -2.2155e-02, -2.3941e-02,  3.1901e-02,\n",
      "        -5.0716e-02, -1.1437e-02, -2.3804e-02,  2.7567e-02, -2.4902e-02,\n",
      "         1.6476e-02, -6.0066e-02, -4.3340e-03,  5.3340e-02, -2.4311e-02,\n",
      "        -1.1807e-02,  2.4385e-02,  2.3526e-02, -2.2669e-02, -3.9924e-02,\n",
      "         1.9537e-02, -1.5130e-02,  4.3630e-02,  3.9361e-02, -7.5836e-02,\n",
      "        -2.5126e-02,  1.9880e-02, -3.1899e-02,  1.2979e-03,  3.0446e-02,\n",
      "         1.4965e-03, -6.0998e-02,  3.0795e-02, -1.2672e-02,  6.7540e-04,\n",
      "        -9.7563e-03,  7.4802e-02, -3.3844e-02, -6.2342e-04,  3.2623e-02,\n",
      "         5.3756e-02,  5.1184e-02, -1.0330e-01,  1.2554e-02, -6.8593e-03,\n",
      "        -4.2730e-02,  1.8363e-02,  5.3521e-02,  6.6087e-03, -1.3345e-02,\n",
      "        -3.2879e-02,  9.7797e-03, -3.0812e-02,  3.6464e-03,  4.6105e-03,\n",
      "        -5.7796e-03, -1.8928e-02, -2.0202e-02,  9.5475e-03,  2.8841e-02,\n",
      "         1.8990e-02,  5.5025e-02, -7.3408e-02, -1.4344e-02,  1.9589e-02,\n",
      "         1.1048e-02, -1.7538e-02,  2.1261e-03, -4.7578e-03,  1.6972e-02,\n",
      "         3.2983e-03,  2.7780e-02,  4.8679e-02,  7.8915e-02,  7.9445e-03,\n",
      "        -2.0370e-02, -3.1969e-03, -8.1373e-04,  2.8566e-02, -3.5006e-02,\n",
      "         3.8115e-04,  9.3437e-03, -1.6445e-02,  3.3380e-02, -3.8262e-02,\n",
      "         1.9445e-02, -1.5465e-02,  1.3842e-02, -2.4331e-03, -2.2266e-02,\n",
      "        -7.0741e-03,  2.5741e-02, -3.7221e-02, -2.5458e-02,  7.3020e-03,\n",
      "         8.1078e-02,  8.3304e-02,  1.9387e-02, -1.4905e-02, -3.8083e-02,\n",
      "        -5.8870e-04, -1.1541e-02, -1.0802e-02,  1.6137e-04, -4.1251e-02,\n",
      "        -1.9068e-02,  1.4547e-02, -3.7383e-03, -5.7595e-02,  5.0040e-02,\n",
      "        -3.8574e-02,  3.5811e-03,  1.9551e-03,  1.0796e-02, -2.7181e-02,\n",
      "         4.7609e-02,  4.4126e-02,  4.0480e-02, -1.9921e-03, -4.8034e-02,\n",
      "        -3.6186e-02, -3.3927e-02,  1.4736e-02,  3.8873e-02,  3.2251e-02,\n",
      "        -4.5125e-03,  3.9269e-02,  1.1171e-02, -5.4275e-04, -9.8819e-02,\n",
      "         1.7522e-02, -6.6797e-03, -5.8345e-02,  2.7659e-02, -1.0571e-02,\n",
      "        -7.1097e-33, -4.0412e-02,  9.4384e-03, -3.0011e-02, -2.5912e-02,\n",
      "        -3.5681e-02, -1.8184e-02,  2.8450e-03,  3.4262e-02, -2.7387e-02,\n",
      "        -4.7345e-02,  1.0427e-02, -2.0742e-02,  5.5684e-03, -5.5032e-03,\n",
      "         1.6942e-02,  9.0162e-02,  3.3841e-02,  9.5499e-04, -2.9513e-02,\n",
      "        -6.9649e-02,  7.0603e-02,  3.1183e-02, -1.8830e-02,  4.8603e-02,\n",
      "         5.7489e-04, -5.6603e-02, -5.0779e-02,  1.4966e-02, -2.6351e-02,\n",
      "         3.5862e-02, -3.0993e-02, -2.5968e-02, -2.7877e-02,  4.8705e-02,\n",
      "         1.7295e-02,  7.0699e-03,  1.5782e-03, -2.7558e-02,  2.4235e-02,\n",
      "        -1.0672e-02,  5.4041e-03, -1.4637e-03, -9.7860e-03, -3.4961e-02,\n",
      "        -1.5814e-02,  1.2061e-03,  2.3360e-02, -4.1146e-02, -3.7543e-02,\n",
      "         6.6050e-02, -3.4550e-02,  2.1049e-02,  1.4305e-02, -1.7967e-02,\n",
      "         3.6886e-02,  2.4276e-02,  1.8782e-03, -5.0724e-02,  4.8311e-02,\n",
      "         5.2242e-02, -6.4403e-03,  2.2967e-02,  4.1214e-02,  7.7280e-02,\n",
      "         3.6564e-02,  6.6034e-02, -5.7464e-03, -1.4890e-02,  1.0578e-02,\n",
      "         1.6633e-02,  2.1572e-02,  1.1412e-01,  5.1495e-02, -1.1835e-02,\n",
      "        -2.5847e-02, -3.9744e-02,  2.0098e-02,  1.7121e-02,  2.8813e-03,\n",
      "        -2.7229e-02,  1.8697e-03, -1.3621e-03, -3.2976e-02,  4.3729e-02,\n",
      "         5.0267e-02, -7.0380e-02, -3.9196e-02, -6.0830e-02,  1.7681e-02,\n",
      "         1.6978e-02,  4.7189e-04,  5.6092e-02, -1.9929e-02, -2.9892e-02,\n",
      "        -1.3716e-02, -7.3572e-02,  1.7742e-02,  2.1667e-02, -2.8204e-02,\n",
      "        -2.3194e-02,  6.9739e-02, -1.6651e-02,  1.4001e-02,  3.8357e-03,\n",
      "         7.7740e-03,  2.2020e-02, -1.1035e-02,  9.0919e-04, -5.9910e-02,\n",
      "        -3.8629e-04,  7.4494e-03, -2.4721e-02,  6.6580e-03, -8.1635e-02,\n",
      "         4.9512e-02, -3.3784e-02, -4.7996e-04, -4.2828e-03,  2.7077e-02,\n",
      "         4.0942e-02, -4.9534e-02, -2.1417e-02, -2.6076e-02,  4.6750e-02,\n",
      "        -1.1308e-02, -2.0551e-03, -7.1420e-02, -2.8313e-02, -2.4557e-02,\n",
      "        -6.3250e-02, -3.1751e-02,  1.9439e-02,  3.0630e-07,  1.4010e-02,\n",
      "         3.4514e-02,  3.0708e-03,  5.4976e-02, -5.9406e-03,  1.5678e-02,\n",
      "        -2.2767e-02,  2.4141e-02, -3.6457e-03, -3.5346e-02, -3.1284e-03,\n",
      "        -3.9174e-02,  1.4585e-02, -8.0560e-04, -7.9634e-03,  1.5543e-02,\n",
      "        -4.8075e-03, -8.0621e-02, -3.6271e-02, -1.2782e-03,  7.7938e-02,\n",
      "         3.4433e-02,  4.6614e-02,  2.3044e-03, -1.3435e-02, -6.8992e-02,\n",
      "         7.5128e-03, -2.4723e-02,  4.1603e-04,  1.1852e-03, -4.9568e-02,\n",
      "         4.4205e-03, -3.7591e-02, -6.7851e-03, -2.1279e-02, -4.7738e-02,\n",
      "         3.3146e-02,  3.9005e-02, -7.9152e-03,  4.4954e-02,  2.9992e-02,\n",
      "        -8.2837e-04, -3.8260e-03, -4.7292e-02,  2.5864e-02,  4.7947e-02,\n",
      "        -3.9466e-03, -4.8547e-03, -3.1814e-02, -5.5494e-03,  5.0746e-03,\n",
      "        -4.0210e-02, -4.9681e-03,  1.7492e-02,  1.6164e-03,  1.1294e-02,\n",
      "         1.5114e-02, -1.0438e-02,  3.8530e-02,  3.1459e-02, -5.8181e-02,\n",
      "        -5.6628e-02, -3.0879e-02,  1.5284e-03,  8.7645e-02,  1.0695e-02,\n",
      "        -4.6125e-02,  2.7202e-34,  2.0352e-02,  2.2040e-02, -9.7095e-03,\n",
      "         1.2045e-02, -2.9728e-03,  8.7777e-03,  8.5258e-02, -2.3191e-02,\n",
      "         2.2574e-02, -3.7408e-02, -4.2357e-02], device='cuda:0')} , DISTANCE: 1.1432485580444336\n"
     ]
    }
   ],
   "source": [
    "#Testing search\n",
    "query = \"How was Gemini invented?\"\n",
    "embed_model.to('cuda')\n",
    "\n",
    "query_test = embed_model.encode(query)\n",
    "print(query_test.shape, type(query_test))\n",
    "distance, ids = index2.search(np.expand_dims(query_test, axis=0), 5)\n",
    "\n",
    "# second argument specifies the number of closest documents you want to retrieve\n",
    "#Matrix distance is the matrix of squared distances. It has the same shape as I and indicates for each result vector at the query’s squared Euclidean distance.\n",
    "\n",
    "first_doc_id = ids[0][0]\n",
    "original_doc = all_pdf_formatted_dict[first_doc_id]\n",
    "\n",
    "print(f\"QUERY:{query} \\n\\n: ANS:{original_doc} , DISTANCE: {distance[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72f44896-bbe5-4a10-b387-c8f4eec60c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T16:21:57.491145Z",
     "iopub.status.busy": "2024-04-03T16:21:57.490433Z",
     "iopub.status.idle": "2024-04-03T16:21:57.495577Z",
     "shell.execute_reply": "2024-04-03T16:21:57.494647Z",
     "shell.execute_reply.started": "2024-04-03T16:21:57.491111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making the output pretty\n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text , wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c2501dd8-5fca-4822-a7d6-4fe809803bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T16:44:26.396479Z",
     "iopub.status.busy": "2024-04-03T16:44:26.396111Z",
     "iopub.status.idle": "2024-04-03T16:44:26.404022Z",
     "shell.execute_reply": "2024-04-03T16:44:26.403133Z",
     "shell.execute_reply.started": "2024-04-03T16:44:26.396450Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import perf_counter as timer\n",
    "# Function for retriver\n",
    "def retrieve_docs(query, doc_embeddings, all_docs_array, model, faiss_index,n_return_docs=5, print_time=True, ):\n",
    "    \"\"\" Embed the query , and return the top docs distance, indices\"\"\"\n",
    "    model = model.to('cuda')\n",
    "    # Query embedding\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    # Reshaping since faiss expects nxd ndarry format\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "    \n",
    "    # start time\n",
    "    time_strt = timer()\n",
    "    distances, retrieved_ids = faiss_index.search(query_embedding, n_return_docs)\n",
    "    time_end = timer()\n",
    "    \n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get search on {len(doc_embeddings)} embeddings: {time_end-time_strt:.5f} seconds\")\n",
    "\n",
    "    print(f\"QUERY: {query} \\n\")\n",
    "    print(\"Retrieved Docs: \\n\")\n",
    "    for doc_num,doc_id in enumerate(retrieved_ids[0]):\n",
    "        print(f\"DOC {doc_num}\")\n",
    "        print(f\"\\n {all_pdf_formatted_dict[doc_id]['sentence_chunk']}\")\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c26805f2-4dba-43c9-a85d-7625320d520f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T16:47:12.110908Z",
     "iopub.status.busy": "2024-04-03T16:47:12.110570Z",
     "iopub.status.idle": "2024-04-03T16:47:12.150767Z",
     "shell.execute_reply": "2024-04-03T16:47:12.149705Z",
     "shell.execute_reply.started": "2024-04-03T16:47:12.110882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get search on 3583 embeddings: 0.00111 seconds\n",
      "QUERY: What are transformers? \n",
      "\n",
      "Retrieved Docs: \n",
      "\n",
      "DOC 0\n",
      "\n",
      " 10.1•THE TRANSFORMER: A SELF-ATTENTION NETWORK215transformers are a neural architecture that can handle distant informationBut unlikeLSTMs, transformers are not based on recurrent connections (which can be hard toparallelize), which means that transformers can be more efﬁcient to implement atscale. Transformers are made up of stacks of transformer blocks, each of which is amultilayer network that maps sequences of input vectors (x1,...,xn) to sequences ofoutput vectors (z1,...,zn) of the same lengthThese blocks are made by combin-ing simple linear layers, feedforward networks, and self-attention layers, the keyself-attentioninnovation of transformersSelf-attention allows a network to directly extract anduse information from arbitrarily large contextsWe’ll start by describing how self-attention works and then return to how it ﬁts into larger transformer blocks\n",
      "\n",
      "\n",
      "DOC 1\n",
      "\n",
      " We can thinkof these representations as a contextualized version of the static vectors we saw inChapter 6, which each represented the meaning of a word typeBy contrast, our goalin transformers is to produce a contextualized version, something that representswhat this word means in the particular context in which it occurs. We thus need a mechanism that tells us how to weigh and combine the represen-tations of the different words from the context at the prior level in order to computeour representation at this layerThis mechanism must be able to look broadly in thecontext, since words have rich linguistic relationships with words that can be manysentences awayEven within the sentence, words have important linguistic relation-ships with contextual wordsConsider these examples, each exhibiting linguisticrelationships that we’ll discuss in more depth in later chapters:(10.1) The keys to the cabinet are on the table.(10.2) The chicken crossed the road because it wanted to get to the other side.(10.3) I walked along the pond, and noticed that one of the trees along the bankhad fallen into the water after the storm. In (10.1), the phrase The keys is the subject of the sentence, and in English andmany languages, must agree in grammatical number with the verb are; in this caseboth are plural\n",
      "\n",
      "\n",
      "DOC 2\n",
      "\n",
      " We’ll refer to this role as a key.key• And ﬁnally, as a value used to compute the output for the current focus ofvalueattention. To capture these three different roles, transformers introduce weight matricesWQ, WK, and WVThese weights will be used to project each input vector xi intoa representation of its role as a key, query, or value.qi = xiWQ; ki = xiWK; vi = xiWV(10.8)The inputs x and outputs y of transformers, as well as the intermediate vectors afterthe various layers like the attention output vector a, all have the same dimensionality1 × dWe’ll have a dimension dk for the key and query vectors, and a separatedimension dv for the value vectorsIn the original transformer work (Vaswani et al.,2017), d was 512, dk and dv were both 64The shapes of the transform matrices arethen WQ ∈ Rd×dk, WK ∈ Rd×dk, and WV ∈ Rd×dv. Given these projections, the score between a current focus of attention, xi, andan element in the preceding context, xj, consists of a dot product between its queryvector qi and the preceding element’s key vectors k j\n",
      "\n",
      "\n",
      "DOC 3\n",
      "\n",
      " Figure 1: The Transformer - model architecture. The Transformer follows this overall architecture using stacked self-attention and point-wise, fullyconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,respectively.3.1Encoder and Decoder StacksEncoder:The encoder is composed of a stack of N = 6 identical layersEach layer has twosub-layersThe first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward networkWe employ a residual connection [11] around each ofthe two sub-layers, followed by layer normalization [1]That is, the output of each sub-layer isLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layeritself\n",
      "\n",
      "\n",
      "DOC 4\n",
      "\n",
      " IBLIOGRAPHICAL AND HISTORICAL NOTES241• Transformers are non-recurrent networks based on self-attentionA self-attention layer maps input sequences to output sequences of the same length,using attention heads that model how the surrounding words are relevant forthe processing of the current word.• A transformer block consists of a single attention layer followed by a feed-forward layer with residual connections and layer normalizations followingeachTransformer blocks can be stacked to make deeper and more powerfulnetworks.• Language models can be built out of stacks of transformer blocks, with a linearand softmax max layer at the top.• Transformer-based language models have a wide context window (as wide as4096 tokens for current models) allowing them to draw on enormous amountsof context to predict upcoming words.• Many NLP tasks—such as question answering, summarization, sentiment,and machine translation—can be cast as tasks of word prediction and henceaddressed with Large language models.• The choice of which word to generate in large language models is generallydone by using a sampling algorithm.• Because of their ability to be used in so many ways, language models alsohave the potential to cause harmsSome harms include hallucinations, bias,stereotypes, misinformation and propaganda, and violations of privacy andcopyright. Bibliographical and Historical NotesThe transformer (Vaswani et al., 2017) was developed drawing on two lines of priorresearch: self-attention and memory networksEncoder-decoder attention, theidea of using a soft weighting over the encodings of input words to inform a gen-erative decoder (see Chapter 13) was developed by Graves (2013) in the context ofhandwriting generation, and Bahdanau et al\n",
      "\n",
      "\n",
      "DOC 5\n",
      "\n",
      " 224CHAPTER 10•TRANSFORMERS AND LARGE LANGUAGE MODELSCrucially, the input and output dimensions of transformer blocks are matched sothey can be stackedEach token xi at the input to the block has dimensionality d,and so the input X and output H are both of shape [N ×d]. Transformers for large language models stack many of these blocks, from 12layers (used for the T5 or GPT-3-small language models) to 96 layers (used forGPT-3 large), to even more for more recent modelsWe’ll come back to this issuesof stacking in a bit.10.4The Residual Stream view of the Transformer BlockThe previous sections viewed the transformer block as applied to the entire N-tokeninput X of shape [N ×d], producing an output also of shape [N ×d]. While packing everything this way is a computationally efﬁcient way to imple-ment the transformer block, it’s not always the most perspicuous way to understandwhat the transformer is doingIt’s often clearer to instead visualize what is hap-pening to an individual token vector xi in the input as it is processed through eachtransformer blockAfter all, most of the components of the transformer are de-signed to take a single vector of dimensionality d, corresponding to a single token,and produce an output vector also of dimensionality d\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieve_docs(\"What are transformers?\", batched_sentence_embeddings_np,all_pdf_formatted_dict, embed_model, \\\n",
    "              index2, n_return_docs=6, print_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087fa1d-f8be-41d9-a751-fb131a73a853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea0717-e3f1-4736-91ba-29057b7a787a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097c664-e5de-4b23-8d16-cd6b3d4833ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee251b95-aab3-4fdb-b71c-eda060fa470a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671303f-cbb2-4518-99fb-87786fcf7d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146e676-e304-44e8-8fb0-b94d9b6f1f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e7d86-66d5-4d00-ba8f-3032ed5bbff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e78dd9-6daa-486c-8349-40ee477a6a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d351057-6e72-400a-be11-ccaeaa8615ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00d64c-afd5-4c8a-8e27-f456e6800400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccefab-299b-4bb2-9a22-c68ffa435f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b6ed9-aac2-4058-b8f7-05cbed350cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6a0f0-470d-4b44-a549-459c2eb0e31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1bffd-b9ba-49be-a7f3-a8c9315df5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768cfd9f-419c-4e03-8774-babf845f35ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5d3bd-3053-470d-87bc-05ea9a69f20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
