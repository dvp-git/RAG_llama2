{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324812b5-edfc-4501-9ded-ecd559725cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T18:57:12.442652Z",
     "iopub.status.busy": "2024-04-03T18:57:12.442053Z",
     "iopub.status.idle": "2024-04-03T18:58:33.202400Z",
     "shell.execute_reply": "2024-04-03T18:58:33.201650Z",
     "shell.execute_reply.started": "2024-04-03T18:57:12.442621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF==1.23.26 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.23.26)\n",
      "Requirement already satisfied: matplotlib==3.8.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (3.8.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pandas==2.2.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: Requests==2.31.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: sentence_transformers==2.5.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.66.2)\n",
      "Requirement already satisfied: transformers==4.38.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (4.38.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (0.28.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (0.43.0)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (0.35.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.9/dist-packages (from PyMuPDF==1.23.26->-r requirements.txt (line 1)) (1.23.22)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (5.10.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==2.2.1->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/dist-packages (from pandas==2.2.1->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (1.26.14)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (0.22.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (0.15.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (66.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 10)) (5.9.4)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (7.2.9)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.16.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.5.2)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (5.5.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (8.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (4.10.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.8.3->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 7)) (6.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.0.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (3.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (12.4.99)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.5.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.6.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (7.3.4)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (5.8.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (25.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (6.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (8.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (0.1.6)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (3.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (4.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (2.14.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (5.1.5)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (3.0.36)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (5.7.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.11.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.4.8)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 12)) (2.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.18.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter->-r requirements.txt (line 12)) (2.6.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.23.5)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (4.17.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 12)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11.0->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (18.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.57.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==2.1.1\n",
      "  Using cached torch-2.1.1-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (3.9.0)\n",
      "Collecting triton==2.1.0\n",
      "  Using cached triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (4.10.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (3.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (11.4.5.107)\n",
      "Collecting nvidia-nccl-cu12==2.18.1\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch==2.1.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.1.1) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.1.1) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nccl-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.17.2 requires torch==2.2.2, but you have torch 2.1.1 which is incompatible.\n",
      "torchaudio 2.2.2 requires torch==2.2.2, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.18.1 torch-2.1.1 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.17.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (9.2.0)\n",
      "Collecting torch==2.2.2\n",
      "  Using cached torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (3.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Collecting triton==2.2.0\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (3.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (1.12)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (10.3.2.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (4.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchvision) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.2.2->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nccl-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.1\n",
      "    Uninstalling torch-2.1.1:\n",
      "      Successfully uninstalled torch-2.1.1\n",
      "Successfully installed nvidia-nccl-cu12-2.19.3 torch-2.2.2 triton-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
      "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.9/dist-packages (from torchaudio) (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (4.10.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (2.19.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchaudio) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.2.2->torchaudio) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.2.2->torchaudio) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "\n",
    "%pip install torch==2.1.1\n",
    "%pip install --upgrade torchvision\n",
    "%pip install --upgrade torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ca8e7f-485d-43bc-bb8a-b5332868591b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:20.609648Z",
     "iopub.status.busy": "2024-04-03T19:00:20.608421Z",
     "iopub.status.idle": "2024-04-03T19:00:20.785086Z",
     "shell.execute_reply": "2024-04-03T19:00:20.784215Z",
     "shell.execute_reply.started": "2024-04-03T19:00:20.609582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import fitz\n",
    "import os\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f05e79-77f3-4fde-b9bf-f6bda82205d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:21.527243Z",
     "iopub.status.busy": "2024-04-03T19:00:21.526333Z",
     "iopub.status.idle": "2024-04-03T19:00:21.531634Z",
     "shell.execute_reply": "2024-04-03T19:00:21.531088Z",
     "shell.execute_reply.started": "2024-04-03T19:00:21.527207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Standford NLP.pdf', 'Attn_paper.pdf', 'Faiss.pdf', 'Gemini_paper.pdf', 'BART.pdf']\n"
     ]
    }
   ],
   "source": [
    "pdf_path = './'\n",
    "pdf_files = [f for f in os.listdir(pdf_path) if f.endswith(\".pdf\")]\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553c8a31-8540-475a-a6d1-13624086aaca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:22.076484Z",
     "iopub.status.busy": "2024-04-03T19:00:22.075933Z",
     "iopub.status.idle": "2024-04-03T19:00:22.079733Z",
     "shell.execute_reply": "2024-04-03T19:00:22.079216Z",
     "shell.execute_reply.started": "2024-04-03T19:00:22.076450Z"
    }
   },
   "outputs": [],
   "source": [
    "books_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f57935-34e4-40ae-bad8-5d1928230c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:22.674098Z",
     "iopub.status.busy": "2024-04-03T19:00:22.673189Z",
     "iopub.status.idle": "2024-04-03T19:00:22.680478Z",
     "shell.execute_reply": "2024-04-03T19:00:22.679870Z",
     "shell.execute_reply.started": "2024-04-03T19:00:22.674063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Text content of the pdf\n",
    "# For each pdf , get the pdf file contents \n",
    "# Store meta-data information about each pdf.\n",
    "\n",
    "def format_text(text):\n",
    "    text = text.strip(\"\\n\\n\")\n",
    "    text=text.replace(\"\\n\",'')\n",
    "    return text\n",
    "\n",
    "# # https://community.adobe.com/t5/acrobat-discussions/page-number-in-print-does-not-display-in-adobe-s-page-number-box/td-p/13781534\n",
    "# Doesn't use Logical Page numbers. Use the normal Page numbers\n",
    "# Logical causes issues during the rendering as you can't generalize to multiple pdfs\n",
    "\n",
    "def get_text_content(pdf_text_, pdf_):\n",
    "    doc = fitz.open(pdf_)\n",
    "    print(len(doc))\n",
    "    for page_num, page in enumerate(doc):\n",
    "        # Extract the text content of the page\n",
    "        text = page.get_text()\n",
    "        text = format_text(text)\n",
    "        name = pdf_.strip('.pdf')\n",
    "        pdf_text_.append((text, page_num+1, name))\n",
    "    return pdf_text_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240ec7a0-14df-4311-b574-22817bcda0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:23.382607Z",
     "iopub.status.busy": "2024-04-03T19:00:23.381543Z",
     "iopub.status.idle": "2024-04-03T19:00:26.407526Z",
     "shell.execute_reply": "2024-04-03T19:00:26.406216Z",
     "shell.execute_reply.started": "2024-04-03T19:00:23.382572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "15\n",
      "21\n",
      "62\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "books_ = []\n",
    "books_ = [get_text_content([], pdf_) for pdf_ in pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e7ba8b-f5f9-4a52-9168-67d7bf68b45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:26.409724Z",
     "iopub.status.busy": "2024-04-03T19:00:26.409479Z",
     "iopub.status.idle": "2024-04-03T19:00:26.417185Z",
     "shell.execute_reply": "2024-04-03T19:00:26.416471Z",
     "shell.execute_reply.started": "2024-04-03T19:00:26.409698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107,\n",
       " ('Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on theEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.ModelBLEUTraining Cost (FLOPs)EN-DEEN-FREN-DEEN-FRByteNet [18]23.75Deep-Att + PosUnk [39]39.21.0 · 1020GNMT + RL [38]24.639.922.3 · 10191.4 · 1020ConvS2S [9]25.1640.469.6 · 10181.5 · 1020MoE [32]26.0340.562.0 · 10191.2 · 1020Deep-Att + PosUnk Ensemble [39]40.48.0 · 1020GNMT + RL Ensemble [38]26.3041.161.8 · 10201.1 · 1021ConvS2S Ensemble [9]26.3641.297.7 · 10191.2 · 1021Transformer (base model)27.338.13.3 · 1018Transformer (big)28.441.82.3 · 1019Residual DropoutWe apply dropout [33] to the output of each sub-layer, before it is added to thesub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and thepositional encodings in both the encoder and decoder stacks. For the base model, we use a rate ofPdrop = 0.1.Label SmoothingDuring training, we employed label smoothing of value ϵls = 0.1 [36]. Thishurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.6Results6.1Machine TranslationOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model islisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base modelsurpasses all previously published models and ensembles, at a fraction of the training cost of any ofthe competitive models.On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,outperforming all of the previously published single models, at less than 1/4 the training cost of theprevious state-of-the-art model. The Transformer (big) model trained for English-to-French useddropout rate Pdrop = 0.1, instead of 0.3.For the base models, we used a single model obtained by averaging the last 5 checkpoints, whichwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. Weused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameterswere chosen after experimentation on the development set. We set the maximum output length duringinference to input length + 50, but terminate early when possible [38].Table 2 summarizes our results and compares our translation quality and training costs to other modelarchitectures from the literature. We estimate the number of floating point operations used to train amodel by multiplying the training time, the number of GPUs used, and an estimate of the sustainedsingle-precision floating-point capacity of each GPU 5.6.2Model VariationsTo evaluate the importance of different components of the Transformer, we varied our base modelin different ways, measuring the change in performance on English-to-German translation on the5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.8',\n",
       "  8,\n",
       "  'Attn_paper'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_[1][7][0]) , books_[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372100f9-c04e-4888-9d57-0e28f2d2a578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:26.418990Z",
     "iopub.status.busy": "2024-04-03T19:00:26.418450Z",
     "iopub.status.idle": "2024-04-03T19:00:26.491451Z",
     "shell.execute_reply": "2024-04-03T19:00:26.490606Z",
     "shell.execute_reply.started": "2024-04-03T19:00:26.418964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Books_  -> [List[List[(text_content, page_num)]]\n",
    "\n",
    "# Create a dictionary to store each pages documents into sentences\n",
    "\n",
    "# Estimating that each token is 4 characters\n",
    "# Page Info\n",
    "def page_formatter(page):\n",
    "    page_ = {}\n",
    "    for pg in page:\n",
    "        page_['doc_name'] = page[2]\n",
    "        page_['text'] = page[0]\n",
    "        page_['pg_num'] = page[1]\n",
    "        page_['pg_num_chars'] = len(page[0])\n",
    "        page_['pg_num_words'] = len(page[0].split(' '))\n",
    "        page_['pg_num_sentences'] = len(page[0].split('. ')) # Since sentences usually begin with '. '\n",
    "        page_['pg_num_tokens'] = page_['pg_num_chars'] / 4\n",
    "    return page_\n",
    "                                        \n",
    "# Testing with a single page\n",
    "# page_formatter(books_[1][6])\n",
    "\n",
    "all_content_ = [[page_formatter(page) for page in books] for books in books_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d8f3a9c-4daf-448c-bde8-00c044a642e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:26.493500Z",
     "iopub.status.busy": "2024-04-03T19:00:26.493250Z",
     "iopub.status.idle": "2024-04-03T19:00:26.498913Z",
     "shell.execute_reply": "2024-04-03T19:00:26.498250Z",
     "shell.execute_reply.started": "2024-04-03T19:00:26.493477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_name': 'Gemini_paper',\n",
       " 'text': 'Gemini: A Family of Highly Capable Multimodal ModelsFigure 2 | Gemini supports interleaved sequences of text, image, audio, and video as inputs (illustratedby tokens of different colors in the input sequence). It can output responses with interleaved imageand text.tasks that require fine-grained understanding. In addition, Gemini can directly ingest audio signals at16kHz from Universal Speech Model (USM) (Zhang et al., 2023) features. This enables the model tocapture nuances that are typically lost when the audio is naively mapped to a text input (for example,see audio understanding demo on the website).Training the Gemini family of models required innovations in training algorithms, dataset, andinfrastructure. For the Pro model, the inherent scalability of our infrastructure and learning algorithmsenable us to complete pretraining in a matter of weeks, leveraging a fraction of the Ultra’s resources.The Nano series of models leverage additional advancements in distillation and training algorithmsto produce the best-in-class small language models for a wide variety of tasks, such as summarizationand reading comprehension, which power our next generation on-device experiences.3. Training InfrastructureWe trained Gemini models using TPUv5e and TPUv4 (Jouppi et al., 2023), depending on their sizesand configuration. Training Gemini Ultra used a large fleet of TPUv4 accelerators across multipledatacenters. This represents a significant increase in scale over our prior flagship model PaLM-2which presented new infrastructure challenges. Scaling up the number of accelerators results in aproportionate decrease in the mean time between failure of hardware in the overall system. Weminimized the rate of planned reschedules and preemptions, but genuine machine failures arecommonplace across all hardware accelerators at such large scales.TPUv4 accelerators are deployed in “SuperPods” of 4096 chips, each connected to a dedicatedoptical switch, which can dynamically reconfigure 4x4x4 chip cubes into arbitrary 3D torus topologiesin around 10 seconds (Jouppi et al., 2023). For Gemini Ultra, we decided to retain a small number ofcubes per superpod to allow for hot standbys and rolling maintenance.TPU accelerators primarily communicate over the high speed inter-chip-interconnect, but atGemini Ultra scale, we combine SuperPods in multiple datacenters using Google’s intra-cluster andinter-cluster network (Poutievski et al., 2022; Wetherall et al., 2023; yao Hong et al., 2018). Google’snetwork latencies and bandwidths are sufficient to support the commonly used synchronous training4',\n",
       " 'pg_num': 4,\n",
       " 'pg_num_chars': 2605,\n",
       " 'pg_num_words': 360,\n",
       " 'pg_num_sentences': 12,\n",
       " 'pg_num_tokens': 651.25}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[3][3] # List[List[dictionaries]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11cd74a8-2aa4-45cd-951e-c0849a2015a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:26.500419Z",
     "iopub.status.busy": "2024-04-03T19:00:26.500175Z",
     "iopub.status.idle": "2024-04-03T19:00:26.897351Z",
     "shell.execute_reply": "2024-04-03T19:00:26.896634Z",
     "shell.execute_reply.started": "2024-04-03T19:00:26.500390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
      "Token_mean , Sentences_mean (642.45, 17.0)\n",
      "Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
      "Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
      "Token_mean , Sentences_mean (1003.2, 18.7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df_p1_mean = pd.DataFrame(all_content_[0])['pg_num_tokens'].mean()\n",
    "# # df_p2 = pd.DataFrame(all_content_[1])\n",
    "# # df_p3 = pd.DataFrame(all_content_[2])\n",
    "# # df_p4 = pd.DataFrame(all_content_[3])\n",
    "# print(df_p1_mean)\n",
    "\n",
    "# Calculate the mean number of sentences in each document.Then use sentence_splitter \n",
    "# to split the long sentences\n",
    "def calc_mean(doc):\n",
    "    doc_df = pd.DataFrame(doc)\n",
    "    doc_mean = doc_df['pg_num_tokens'].mean()\n",
    "    doc_sentences_mean = doc_df['pg_num_sentences'].mean()\n",
    "    return doc_mean, doc_sentences_mean\n",
    "\n",
    "for doc in all_content_:\n",
    "    print(\"Token_mean , Sentences_mean\",calc_mean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490938ae-971f-4fc3-83d1-7a8a6271b570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:26.899056Z",
     "iopub.status.busy": "2024-04-03T19:00:26.898713Z",
     "iopub.status.idle": "2024-04-03T19:00:26.902934Z",
     "shell.execute_reply": "2024-04-03T19:00:26.902234Z",
     "shell.execute_reply.started": "2024-04-03T19:00:26.899029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each sentence is long , the mean token size are above and won't fit the embedding model for tokenization\n",
    "# Split sentences into smaller chunks\n",
    "\n",
    "# Method to put all sentences in an array called sentences for making the splitting easier\n",
    "def sentence_formatter_per_page(doc):\n",
    "    for page in doc:\n",
    "        page['sentences'] = [sentence for sentence in page['text'].split('. ')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c910ef41-1429-4e27-96c4-8e92fa6976fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:27.960150Z",
     "iopub.status.busy": "2024-04-03T19:00:27.959167Z",
     "iopub.status.idle": "2024-04-03T19:00:27.964108Z",
     "shell.execute_reply": "2024-04-03T19:00:27.963269Z",
     "shell.execute_reply.started": "2024-04-03T19:00:27.960111Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_formatter_all_books(books):\n",
    "    for item in books:\n",
    "        sentence_formatter_per_page(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53290f2f-9396-45b9-9a45-2f4302595bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:28.846324Z",
     "iopub.status.busy": "2024-04-03T19:00:28.845344Z",
     "iopub.status.idle": "2024-04-03T19:00:28.858950Z",
     "shell.execute_reply": "2024-04-03T19:00:28.858064Z",
     "shell.execute_reply.started": "2024-04-03T19:00:28.846289Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_formatter_all_books(all_content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0592b64-379c-485c-bb8e-e206894488f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:30.117311Z",
     "iopub.status.busy": "2024-04-03T19:00:30.116839Z",
     "iopub.status.idle": "2024-04-03T19:00:30.124228Z",
     "shell.execute_reply": "2024-04-03T19:00:30.123369Z",
     "shell.execute_reply.started": "2024-04-03T19:00:30.117279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_name': 'Standford NLP',\n",
       "  'text': '2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence. With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions. The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe. Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way. Consider the expression /[a-z]*/when matching against the text once upon a time. Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once. In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer. The operator *? is a Kleene star that matches as little text as*?possible. The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the. A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The). This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology). So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/. We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25). We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line. This is because the regular expression [ˆa-zA-Z], which',\n",
       "  'pg_num': 17,\n",
       "  'pg_num_chars': 2646,\n",
       "  'pg_num_words': 398,\n",
       "  'pg_num_sentences': 15,\n",
       "  'pg_num_tokens': 661.5,\n",
       "  'sentences': ['2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence',\n",
       "   'With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions',\n",
       "   'The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe',\n",
       "   'Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way',\n",
       "   'Consider the expression /[a-z]*/when matching against the text once upon a time',\n",
       "   'Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once',\n",
       "   'In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer',\n",
       "   'The operator *? is a Kleene star that matches as little text as*?possible',\n",
       "   'The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the',\n",
       "   'A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The)',\n",
       "   'This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology)',\n",
       "   'So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/',\n",
       "   'We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25)',\n",
       "   'We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line',\n",
       "   'This is because the regular expression [ˆa-zA-Z], which']},\n",
       " {'doc_name': 'Standford NLP',\n",
       "  'text': '10CHAPTER 2•REGULAR EXPRESSIONS, TEXT NORMALIZATION, EDIT DISTANCEwe used to avoid embedded instances of the, implies that there must be some single(although non-alphabetic) character before the the. We can avoid this by specify-ing that before the the we require either the beginning-of-line or a non-alphabeticcharacter, and the same at the end of the line:/(ˆ|[ˆa-zA-Z])[tT]he([ˆa-zA-Z]|$)/The process we just went through was based on ﬁxing two kinds of errors: falsepositives, strings that we incorrectly matched like other or there, and false nega-false positivestives, strings that we incorrectly missed, like The. Addressing these two kinds offalse negativeserrors comes up again and again in implementing speech and language processingsystems. Reducing the overall error rate for an application thus involves two antag-onistic efforts:• Increasing precision (minimizing false positives)• Increasing recall (minimizing false negatives)We’ll come back to precision and recall with more precise deﬁnitions in Chapter 4.2.1.4More OperatorsFigure 2.8 shows some aliases for common ranges, which can be used mainly tosave typing. Besides the Kleene * and Kleene + we can also use explicit numbers ascounters, by enclosing them in curly brackets. The regular expression /{3}/ means“exactly 3 occurrences of the previous character or expression”. So /a\\\\.{24}z/will match a followed by 24 dots followed by z (but not a followed by 23 or 25 dotsfollowed by a z).RegexExpansionMatchFirst Matches\\\\d[0-9]any digitParty␣of␣5\\\\D[ˆ0-9]any non-digitBlue␣moon\\\\w[a-zA-Z0-9_]any alphanumeric/underscoreDaiyu\\\\W[ˆ\\\\w]a non-alphanumeric!!!!\\\\s[␣\\\\r\\\\t\\\\n\\\\f]whitespace (space, tab)in Concord\\\\S[ˆ\\\\s]Non-whitespacein␣ConcordFigure 2.8Aliases for common sets of characters.A range of numbers can also be speciﬁed. So /{n,m}/ speciﬁes from n to moccurrences of the previous char or expression, and /{n,}/ means at least n occur-rences of the previous expression. REs for counting are summarized in Fig. 2.9.RegexMatch*zero or more occurrences of the previous char or expression+one or more occurrences of the previous char or expression?zero or one occurrence of the previous char or expression{n}exactly n occurrences of the previous char or expression{n,m}from n to m occurrences of the previous char or expression{n,}at least n occurrences of the previous char or expression{,m}up to m occurrences of the previous char or expressionFigure 2.9Regular expression operators for counting.Finally, certain special characters are referred to by special notation based on thebackslash (\\\\) (see Fig. 2.10). The most common of these are the newline characternewline',\n",
       "  'pg_num': 18,\n",
       "  'pg_num_chars': 2634,\n",
       "  'pg_num_words': 357,\n",
       "  'pg_num_sentences': 12,\n",
       "  'pg_num_tokens': 658.5,\n",
       "  'sentences': ['10CHAPTER 2•REGULAR EXPRESSIONS, TEXT NORMALIZATION, EDIT DISTANCEwe used to avoid embedded instances of the, implies that there must be some single(although non-alphabetic) character before the the',\n",
       "   'We can avoid this by specify-ing that before the the we require either the beginning-of-line or a non-alphabeticcharacter, and the same at the end of the line:/(ˆ|[ˆa-zA-Z])[tT]he([ˆa-zA-Z]|$)/The process we just went through was based on ﬁxing two kinds of errors: falsepositives, strings that we incorrectly matched like other or there, and false nega-false positivestives, strings that we incorrectly missed, like The',\n",
       "   'Addressing these two kinds offalse negativeserrors comes up again and again in implementing speech and language processingsystems',\n",
       "   'Reducing the overall error rate for an application thus involves two antag-onistic efforts:• Increasing precision (minimizing false positives)• Increasing recall (minimizing false negatives)We’ll come back to precision and recall with more precise deﬁnitions in Chapter 4.2.1.4More OperatorsFigure 2.8 shows some aliases for common ranges, which can be used mainly tosave typing',\n",
       "   'Besides the Kleene * and Kleene + we can also use explicit numbers ascounters, by enclosing them in curly brackets',\n",
       "   'The regular expression /{3}/ means“exactly 3 occurrences of the previous character or expression”',\n",
       "   'So /a\\\\.{24}z/will match a followed by 24 dots followed by z (but not a followed by 23 or 25 dotsfollowed by a z).RegexExpansionMatchFirst Matches\\\\d[0-9]any digitParty␣of␣5\\\\D[ˆ0-9]any non-digitBlue␣moon\\\\w[a-zA-Z0-9_]any alphanumeric/underscoreDaiyu\\\\W[ˆ\\\\w]a non-alphanumeric!!!!\\\\s[␣\\\\r\\\\t\\\\n\\\\f]whitespace (space, tab)in Concord\\\\S[ˆ\\\\s]Non-whitespacein␣ConcordFigure 2.8Aliases for common sets of characters.A range of numbers can also be speciﬁed',\n",
       "   'So /{n,m}/ speciﬁes from n to moccurrences of the previous char or expression, and /{n,}/ means at least n occur-rences of the previous expression',\n",
       "   'REs for counting are summarized in Fig',\n",
       "   '2.9.RegexMatch*zero or more occurrences of the previous char or expression+one or more occurrences of the previous char or expression?zero or one occurrence of the previous char or expression{n}exactly n occurrences of the previous char or expression{n,m}from n to m occurrences of the previous char or expression{n,}at least n occurrences of the previous char or expression{,m}up to m occurrences of the previous char or expressionFigure 2.9Regular expression operators for counting.Finally, certain special characters are referred to by special notation based on thebackslash (\\\\) (see Fig',\n",
       "   '2.10)',\n",
       "   'The most common of these are the newline characternewline']}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[0][16:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98814d44-297b-4e64-8629-b1428e7e4d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:30.841133Z",
     "iopub.status.busy": "2024-04-03T19:00:30.840358Z",
     "iopub.status.idle": "2024-04-03T19:00:30.846382Z",
     "shell.execute_reply": "2024-04-03T19:00:30.845625Z",
     "shell.execute_reply.started": "2024-04-03T19:00:30.841098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "def slice_sentences(page_sentences, overlap_size, slice_size):\n",
    "    return [page_sentences[i:i + slice_size] for i in range(0, len(page_sentences) - slice_size + 1, slice_size - overlap_size)]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "page_sentences = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "overlap_size = 2\n",
    "slice_size = 3\n",
    "result = slice_sentences(page_sentences, overlap_size, slice_size)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d78c1e6-fac7-4c67-8be1-4a3380158b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:31.998044Z",
     "iopub.status.busy": "2024-04-03T19:00:31.997282Z",
     "iopub.status.idle": "2024-04-03T19:00:32.002535Z",
     "shell.execute_reply": "2024-04-03T19:00:32.001811Z",
     "shell.execute_reply.started": "2024-04-03T19:00:31.998012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on this , splitting texts into size 8 since sizes are divisible by 6 (more or less)\n",
    "# Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
    "# Token_mean , Sentences_mean (642.45, 17.0)\n",
    "# Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
    "# Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
    "# Token_mean , Sentences_mean (1003.2, 18.7)\n",
    "\n",
    "# Keep overlap of 1 sentence default for every 6 sentences\n",
    "def slice_sentences(page_sentences, slice_size=5,overlap_size=1) :\n",
    "    return [page_sentences[i:i + slice_size] for i in range(0, len(page_sentences) - slice_size + 1, slice_size - overlap_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34cc056e-e4b2-41d5-bf11-3800a69177e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:32.795640Z",
     "iopub.status.busy": "2024-04-03T19:00:32.794609Z",
     "iopub.status.idle": "2024-04-03T19:00:32.800833Z",
     "shell.execute_reply": "2024-04-03T19:00:32.799735Z",
     "shell.execute_reply.started": "2024-04-03T19:00:32.795606Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def all_content_sentence_splitter(all_content):\n",
    "    for book in all_content:\n",
    "        for page in tqdm(book):\n",
    "            page[\"sentence_chunks\"] = slice_sentences(page[\"sentences\"],5,1)\n",
    "\n",
    "            page[\"num_chunks\"] = len(page[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d94c8fe-f37b-4b9b-9459-9f78b3b21c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:33.789335Z",
     "iopub.status.busy": "2024-04-03T19:00:33.788707Z",
     "iopub.status.idle": "2024-04-03T19:00:33.844636Z",
     "shell.execute_reply": "2024-04-03T19:00:33.843782Z",
     "shell.execute_reply.started": "2024-04-03T19:00:33.789304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251373a36dc4401d927bb868dd80cd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6208b239e54a2cbc6980b259930bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf53f99707e4655a60f0f6e8a469536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee44545ccdab4fdf9f2b7ef40a3bfc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f56e1947dd4407a256e661c4983fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_content_sentence_splitter(all_content_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05128216-2d66-435a-8080-bd35c3562472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:35.470758Z",
     "iopub.status.busy": "2024-04-03T19:00:35.470046Z",
     "iopub.status.idle": "2024-04-03T19:00:35.478860Z",
     "shell.execute_reply": "2024-04-03T19:00:35.478287Z",
     "shell.execute_reply.started": "2024-04-03T19:00:35.470728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_name': 'Faiss',\n",
       "  'text': 'and a second level refinement of the residual (moreabout this in Section 5.1).4.5Binary indexesBinary quantization with symmetric distance com-putations is a pattern that has been commonlyused [Wang et al., 2015, Cao et al., 2017]. In this setup,distances are computed in the compressed domain asHamming distances. Equation (11) reduces to:n = argminn=1..N∥C(q) − Cn∥(17)where C(q), Cn ∈ {0, 1}d. Although binary quantizersare crude approximations for continuous domain dis-tances, the Hamming distances are integers in {0..d},that are fast to compute, do not require any specificcontext, and are easy to calibrate in practice.The Faiss IndexBinary indexes support additionand search directly from binary vectors. They offera compact representation and leverage optimized in-structions for distance computations.The simplest IndexBinaryFlat index performs ex-haustive search. Three options are offered for non-exhaustive search:• IndexBinaryIVF is a binary counterpart for theinverted-list IndexIVF index described in 5.1.• IndexBinaryHNSW is a binary counterpart for thehierarchical graph-based IndexHNSW index de-scribed in 5.2.• IndexBinaryHash uses prefix vectors as hashesto cluster the database (rather than spheroids aswith inverted lists), and searches only the clusterswith closests prefixes.Finally, a convenience IndexBinaryFromFloat in-dex is provided that simply wraps an arbitrary indexand offers a binary vector interface for its operations.5Non-exhaustive searchNon-exhaustive search is the cornerstone of fastsearch implementations for medium-sized datasets.In that case, the aim of the indexing method is toquickly focus on a subset of database vectors that aremost likely to contain the search results.An early method to do this is Locality SensitiveHashing (LSH). It amounts to projecting the vectorson a random direction [Datar et al., 2004].The off-sets on that direction are then discretized into bucketswhere the database vectors are stored. At search time,the buckets nearest to the query vector’s projection arevisited. In practice, several projection directions areneeded to make it accurate, at the cost of search time.A fundamental drawback of this method is that it isnot data-adaptive, although some improvements arepossible [Paulev´e et al., 2010].An alternative way of pruning the search space isto use tree-based indexing. In that case, the dataset isstored in the leaves of a tree [Muja and Lowe, 2014].When querying a vector, the search starts at the rootnode. At each internal node, the search descends intoone of the child nodes depending on a decision rule.The decision rule depends on how the tree was built:for a KD-tree it is the position w.r.t. a hyperplane, for ahierarchical k-means, it is the proximity to a centroid.Both in the case of LSH and tree-based methods,the hope is to extend classical database search struc-tures to vector search, because they have a favorablecomplexity (constant or logarithmic in N). However,it turns out that these methods do not scale well fordimensions above 10.Faiss implements two non-exhaustive search ap-proaches that operate at different memory vs. speedtradeoffs: inverted file and graph-based.5.1Inverted filesIVF indexing is a technique that clusters the databasevectors at indexing time. This clustering uses a vec-tor quantizer (the coarse quantizer) that outputs KIVFdistinct indices (Faiss’s nlist parameter). The coarsequantizer’s KIVF reproduction values are called cen-troids.The vectors of each cluster (possibly com-pressed) are stored contiguously into inverted lists,forming an inverted file (IVF). At search time, only asubset of PIVF clusters are visited (a.k.a. nprobe). Thesubset is formed by searching the PIVF nearest cen-troids, as in Equation (2).Setting the number of lists.The KIVF parameter iscentral. In the simplest case, when PIVF is fixed, thecoarse quantizer is exhaustive, the inverted lists con-tain uncompressed vectors, and the inverted lists areall the same size, then the number of distance compu-tations isNdistances = KIVF + PIVF × N/KIVF(18)which reaches a minimum when KIVF = √PIVFN.This yields the usual recommendation to set PIVF pro-portional to√N.In practice, this is just a rough approximation be-cause (1) the PIVF has to increase with the numberof lists in order to keep a fixed accuracy (2) often thecoarse quantizer is not exhaustive itself, so the quanti-zation uses fewer than KIVF distance computations,for example it is common to use a non-exhaustiveHNSW index to perform the coarse quantization.Figure 5 shows the optimal settings of KIVF forvarious database sizes.For a small KIVF = 4096,the coarse quantization runtime is negligible and thesearch time increases linearly with the database size.For larger datasets it is beneficial to increase the KIVF.As in equation (18), the ratio KIVF/√N is roughly 15to 20. Note that this ratio depends on the data dis-tribution and the target accuracy. Interestingly, in aregime where KIVF is larger than the optimal settingfor N (e.g. KIVF = 218 and N =5M), the PIVF neededto reach the target accuracy decreases with the dataset10',\n",
       "  'pg_num': 10,\n",
       "  'pg_num_chars': 5109,\n",
       "  'pg_num_words': 733,\n",
       "  'pg_num_sentences': 23,\n",
       "  'pg_num_tokens': 1277.25,\n",
       "  'sentences': ['and a second level refinement of the residual (moreabout this in Section 5.1).4.5Binary indexesBinary quantization with symmetric distance com-putations is a pattern that has been commonlyused [Wang et al., 2015, Cao et al., 2017]',\n",
       "   'In this setup,distances are computed in the compressed domain asHamming distances',\n",
       "   'Equation (11) reduces to:n = argminn=1..N∥C(q) − Cn∥(17)where C(q), Cn ∈ {0, 1}d',\n",
       "   'Although binary quantizersare crude approximations for continuous domain dis-tances, the Hamming distances are integers in {0..d},that are fast to compute, do not require any specificcontext, and are easy to calibrate in practice.The Faiss IndexBinary indexes support additionand search directly from binary vectors',\n",
       "   'They offera compact representation and leverage optimized in-structions for distance computations.The simplest IndexBinaryFlat index performs ex-haustive search',\n",
       "   'Three options are offered for non-exhaustive search:• IndexBinaryIVF is a binary counterpart for theinverted-list IndexIVF index described in 5.1.• IndexBinaryHNSW is a binary counterpart for thehierarchical graph-based IndexHNSW index de-scribed in 5.2.• IndexBinaryHash uses prefix vectors as hashesto cluster the database (rather than spheroids aswith inverted lists), and searches only the clusterswith closests prefixes.Finally, a convenience IndexBinaryFromFloat in-dex is provided that simply wraps an arbitrary indexand offers a binary vector interface for its operations.5Non-exhaustive searchNon-exhaustive search is the cornerstone of fastsearch implementations for medium-sized datasets.In that case, the aim of the indexing method is toquickly focus on a subset of database vectors that aremost likely to contain the search results.An early method to do this is Locality SensitiveHashing (LSH)',\n",
       "   'It amounts to projecting the vectorson a random direction [Datar et al., 2004].The off-sets on that direction are then discretized into bucketswhere the database vectors are stored',\n",
       "   'At search time,the buckets nearest to the query vector’s projection arevisited',\n",
       "   'In practice, several projection directions areneeded to make it accurate, at the cost of search time.A fundamental drawback of this method is that it isnot data-adaptive, although some improvements arepossible [Paulev´e et al., 2010].An alternative way of pruning the search space isto use tree-based indexing',\n",
       "   'In that case, the dataset isstored in the leaves of a tree [Muja and Lowe, 2014].When querying a vector, the search starts at the rootnode',\n",
       "   'At each internal node, the search descends intoone of the child nodes depending on a decision rule.The decision rule depends on how the tree was built:for a KD-tree it is the position w.r.t',\n",
       "   'a hyperplane, for ahierarchical k-means, it is the proximity to a centroid.Both in the case of LSH and tree-based methods,the hope is to extend classical database search struc-tures to vector search, because they have a favorablecomplexity (constant or logarithmic in N)',\n",
       "   'However,it turns out that these methods do not scale well fordimensions above 10.Faiss implements two non-exhaustive search ap-proaches that operate at different memory vs',\n",
       "   'speedtradeoffs: inverted file and graph-based.5.1Inverted filesIVF indexing is a technique that clusters the databasevectors at indexing time',\n",
       "   'This clustering uses a vec-tor quantizer (the coarse quantizer) that outputs KIVFdistinct indices (Faiss’s nlist parameter)',\n",
       "   'The coarsequantizer’s KIVF reproduction values are called cen-troids.The vectors of each cluster (possibly com-pressed) are stored contiguously into inverted lists,forming an inverted file (IVF)',\n",
       "   'At search time, only asubset of PIVF clusters are visited (a.k.a',\n",
       "   'nprobe)',\n",
       "   'Thesubset is formed by searching the PIVF nearest cen-troids, as in Equation (2).Setting the number of lists.The KIVF parameter iscentral',\n",
       "   'In the simplest case, when PIVF is fixed, thecoarse quantizer is exhaustive, the inverted lists con-tain uncompressed vectors, and the inverted lists areall the same size, then the number of distance compu-tations isNdistances = KIVF + PIVF × N/KIVF(18)which reaches a minimum when KIVF = √PIVFN.This yields the usual recommendation to set PIVF pro-portional to√N.In practice, this is just a rough approximation be-cause (1) the PIVF has to increase with the numberof lists in order to keep a fixed accuracy (2) often thecoarse quantizer is not exhaustive itself, so the quanti-zation uses fewer than KIVF distance computations,for example it is common to use a non-exhaustiveHNSW index to perform the coarse quantization.Figure 5 shows the optimal settings of KIVF forvarious database sizes.For a small KIVF = 4096,the coarse quantization runtime is negligible and thesearch time increases linearly with the database size.For larger datasets it is beneficial to increase the KIVF.As in equation (18), the ratio KIVF/√N is roughly 15to 20',\n",
       "   'Note that this ratio depends on the data dis-tribution and the target accuracy',\n",
       "   'Interestingly, in aregime where KIVF is larger than the optimal settingfor N (e.g',\n",
       "   'KIVF = 218 and N =5M), the PIVF neededto reach the target accuracy decreases with the dataset10'],\n",
       "  'sentence_chunks': [['and a second level refinement of the residual (moreabout this in Section 5.1).4.5Binary indexesBinary quantization with symmetric distance com-putations is a pattern that has been commonlyused [Wang et al., 2015, Cao et al., 2017]',\n",
       "    'In this setup,distances are computed in the compressed domain asHamming distances',\n",
       "    'Equation (11) reduces to:n = argminn=1..N∥C(q) − Cn∥(17)where C(q), Cn ∈ {0, 1}d',\n",
       "    'Although binary quantizersare crude approximations for continuous domain dis-tances, the Hamming distances are integers in {0..d},that are fast to compute, do not require any specificcontext, and are easy to calibrate in practice.The Faiss IndexBinary indexes support additionand search directly from binary vectors',\n",
       "    'They offera compact representation and leverage optimized in-structions for distance computations.The simplest IndexBinaryFlat index performs ex-haustive search'],\n",
       "   ['They offera compact representation and leverage optimized in-structions for distance computations.The simplest IndexBinaryFlat index performs ex-haustive search',\n",
       "    'Three options are offered for non-exhaustive search:• IndexBinaryIVF is a binary counterpart for theinverted-list IndexIVF index described in 5.1.• IndexBinaryHNSW is a binary counterpart for thehierarchical graph-based IndexHNSW index de-scribed in 5.2.• IndexBinaryHash uses prefix vectors as hashesto cluster the database (rather than spheroids aswith inverted lists), and searches only the clusterswith closests prefixes.Finally, a convenience IndexBinaryFromFloat in-dex is provided that simply wraps an arbitrary indexand offers a binary vector interface for its operations.5Non-exhaustive searchNon-exhaustive search is the cornerstone of fastsearch implementations for medium-sized datasets.In that case, the aim of the indexing method is toquickly focus on a subset of database vectors that aremost likely to contain the search results.An early method to do this is Locality SensitiveHashing (LSH)',\n",
       "    'It amounts to projecting the vectorson a random direction [Datar et al., 2004].The off-sets on that direction are then discretized into bucketswhere the database vectors are stored',\n",
       "    'At search time,the buckets nearest to the query vector’s projection arevisited',\n",
       "    'In practice, several projection directions areneeded to make it accurate, at the cost of search time.A fundamental drawback of this method is that it isnot data-adaptive, although some improvements arepossible [Paulev´e et al., 2010].An alternative way of pruning the search space isto use tree-based indexing'],\n",
       "   ['In practice, several projection directions areneeded to make it accurate, at the cost of search time.A fundamental drawback of this method is that it isnot data-adaptive, although some improvements arepossible [Paulev´e et al., 2010].An alternative way of pruning the search space isto use tree-based indexing',\n",
       "    'In that case, the dataset isstored in the leaves of a tree [Muja and Lowe, 2014].When querying a vector, the search starts at the rootnode',\n",
       "    'At each internal node, the search descends intoone of the child nodes depending on a decision rule.The decision rule depends on how the tree was built:for a KD-tree it is the position w.r.t',\n",
       "    'a hyperplane, for ahierarchical k-means, it is the proximity to a centroid.Both in the case of LSH and tree-based methods,the hope is to extend classical database search struc-tures to vector search, because they have a favorablecomplexity (constant or logarithmic in N)',\n",
       "    'However,it turns out that these methods do not scale well fordimensions above 10.Faiss implements two non-exhaustive search ap-proaches that operate at different memory vs'],\n",
       "   ['However,it turns out that these methods do not scale well fordimensions above 10.Faiss implements two non-exhaustive search ap-proaches that operate at different memory vs',\n",
       "    'speedtradeoffs: inverted file and graph-based.5.1Inverted filesIVF indexing is a technique that clusters the databasevectors at indexing time',\n",
       "    'This clustering uses a vec-tor quantizer (the coarse quantizer) that outputs KIVFdistinct indices (Faiss’s nlist parameter)',\n",
       "    'The coarsequantizer’s KIVF reproduction values are called cen-troids.The vectors of each cluster (possibly com-pressed) are stored contiguously into inverted lists,forming an inverted file (IVF)',\n",
       "    'At search time, only asubset of PIVF clusters are visited (a.k.a'],\n",
       "   ['At search time, only asubset of PIVF clusters are visited (a.k.a',\n",
       "    'nprobe)',\n",
       "    'Thesubset is formed by searching the PIVF nearest cen-troids, as in Equation (2).Setting the number of lists.The KIVF parameter iscentral',\n",
       "    'In the simplest case, when PIVF is fixed, thecoarse quantizer is exhaustive, the inverted lists con-tain uncompressed vectors, and the inverted lists areall the same size, then the number of distance compu-tations isNdistances = KIVF + PIVF × N/KIVF(18)which reaches a minimum when KIVF = √PIVFN.This yields the usual recommendation to set PIVF pro-portional to√N.In practice, this is just a rough approximation be-cause (1) the PIVF has to increase with the numberof lists in order to keep a fixed accuracy (2) often thecoarse quantizer is not exhaustive itself, so the quanti-zation uses fewer than KIVF distance computations,for example it is common to use a non-exhaustiveHNSW index to perform the coarse quantization.Figure 5 shows the optimal settings of KIVF forvarious database sizes.For a small KIVF = 4096,the coarse quantization runtime is negligible and thesearch time increases linearly with the database size.For larger datasets it is beneficial to increase the KIVF.As in equation (18), the ratio KIVF/√N is roughly 15to 20',\n",
       "    'Note that this ratio depends on the data dis-tribution and the target accuracy']],\n",
       "  'num_chunks': 5},\n",
       " {'doc_name': 'Faiss',\n",
       "  'text': 'THE FAISS LIBRARYMatthijs DouzeFAIR, MetaAlexandr GuzhvaZillizChengqi DengZhejiang UniversityJeff JohnsonFAIR, MetaGergely SzilvasyFAIR, MetaPierre-Emmanuel Mazar´eFAIR, MetaMaria LomeliFAIR, MetaLucas HosseiniSkip LabsHerv´e J´egouKyutaiAbstractVector databases manage large collections of embed-ding vectors. As AI applications are growing rapidly,so are the number of embeddings that need to bestored and indexed. The Faiss library is dedicated tovector similarity search, a core functionality of vectordatabases. Faiss is a toolkit of indexing methods andrelated primitives used to search, cluster, compressand transform vectors. This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing. We benchmark key featuresof the library and discuss a few selected applicationsto highlight its broad applicability.1IntroductionThe emergence of deep learning has induced a shift inhow complex data is stored and searched, noticeablyby the development of embeddings. Embeddings arevector representations, typically produced by a neuralnetwork, whose main objective is to map (embed)the input media item into a vector space, where thelocality encodes the semantics of the input. Embed-dings are extracted from various forms of media:words [Mikolov et al., 2013, Bojanowski et al., 2017],text[Devlin et al., 2018,Izacard et al., 2021],im-ages[Caron et al., 2021,Pizzi et al., 2022],usersanditemsforrecommendation[Paterek, 2007].They can even encode object relations,for in-stance multi-modal text-image or text-audio rela-tions [Duquenne et al., 2023, Radford et al., 2021].Embeddings are employed as an intermediaterepresentationforfurtherprocessing,e.g.self-supervised image embeddings can input to shal-low supervised image classifiers [Caron et al., 2018,Caron et al., 2021].They are also leveraged asa pretext task for self-supervision,e.g. in Sim-CLR [Chen et al., 2020]. The purpose that we considerin this paper is when embeddings are used directlyto compare media items.The embedding extractoris designed such that the distance between embed-dings reflects the similarity between their correspond-ing media. As a result, neighborhood search in thisvector space offers a direct implementation of similar-ity search between media items.Embeddings are popular in industrial setting fortasks where end-to-end learning would not be cost-efficient.For example, a k nearest-neighbor classi-fier is more efficient to upgrade than a classificationdeep neural net. In that case, embeddings are par-ticularly useful as a compact intermediate representa-tion that can be re-used for several purposes. This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years. TheseDBMS are at the junction of traditional databases andApproximate Nearest Neighbor Search (ANNS) algo-rithms. Until recently, the latter were mostly consid-ered for specific use-cases or in research.From a practical point of view, there are multipleadvantages to maintain a clear separation of roles be-tween the embedding extraction and the vector searchalgorithm. Both are bound by an “embedding con-tract” on the embedding distance:• The embedding extractor, which is typically aneural network in modern systems, is trained sothat distances between embeddings are alignedwith the task to perform.• The vector index aims at performing neighborsearch among the embedding vectors as accu-rately as possible w.r.t. exact search results giventhe agreed distance metric.Faiss is an industrial-grade library for ANNS. It isdesigned to be used both from simple scripts and asa building block of a DBMS. In contrast with other li-braries that focus on a single indexing method, Faissis a toolbox that contains indexing methods that com-monly involve a chain of components (preprocessing,compression, non-exhaustive search, etc.). This is nec-essary: depending on the usage constraints, the mostefficient indexing methods are different.Let us also summarize what Faiss is not: Faiss doesnot extract features – it only indexes embeddings thathave been extracted by a different mechanism; Faissis not a service – it only provides functions that are1arXiv:2401.08281v1  [cs.LG]  16 Jan 2024',\n",
       "  'pg_num': 1,\n",
       "  'pg_num_chars': 4338,\n",
       "  'pg_num_words': 577,\n",
       "  'pg_num_sentences': 20,\n",
       "  'pg_num_tokens': 1084.5,\n",
       "  'sentences': ['THE FAISS LIBRARYMatthijs DouzeFAIR, MetaAlexandr GuzhvaZillizChengqi DengZhejiang UniversityJeff JohnsonFAIR, MetaGergely SzilvasyFAIR, MetaPierre-Emmanuel Mazar´eFAIR, MetaMaria LomeliFAIR, MetaLucas HosseiniSkip LabsHerv´e J´egouKyutaiAbstractVector databases manage large collections of embed-ding vectors',\n",
       "   'As AI applications are growing rapidly,so are the number of embeddings that need to bestored and indexed',\n",
       "   'The Faiss library is dedicated tovector similarity search, a core functionality of vectordatabases',\n",
       "   'Faiss is a toolkit of indexing methods andrelated primitives used to search, cluster, compressand transform vectors',\n",
       "   'This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing',\n",
       "   'We benchmark key featuresof the library and discuss a few selected applicationsto highlight its broad applicability.1IntroductionThe emergence of deep learning has induced a shift inhow complex data is stored and searched, noticeablyby the development of embeddings',\n",
       "   'Embeddings arevector representations, typically produced by a neuralnetwork, whose main objective is to map (embed)the input media item into a vector space, where thelocality encodes the semantics of the input',\n",
       "   'Embed-dings are extracted from various forms of media:words [Mikolov et al., 2013, Bojanowski et al., 2017],text[Devlin et al., 2018,Izacard et al., 2021],im-ages[Caron et al., 2021,Pizzi et al., 2022],usersanditemsforrecommendation[Paterek, 2007].They can even encode object relations,for in-stance multi-modal text-image or text-audio rela-tions [Duquenne et al., 2023, Radford et al., 2021].Embeddings are employed as an intermediaterepresentationforfurtherprocessing,e.g.self-supervised image embeddings can input to shal-low supervised image classifiers [Caron et al., 2018,Caron et al., 2021].They are also leveraged asa pretext task for self-supervision,e.g',\n",
       "   'in Sim-CLR [Chen et al., 2020]',\n",
       "   'The purpose that we considerin this paper is when embeddings are used directlyto compare media items.The embedding extractoris designed such that the distance between embed-dings reflects the similarity between their correspond-ing media',\n",
       "   'As a result, neighborhood search in thisvector space offers a direct implementation of similar-ity search between media items.Embeddings are popular in industrial setting fortasks where end-to-end learning would not be cost-efficient.For example, a k nearest-neighbor classi-fier is more efficient to upgrade than a classificationdeep neural net',\n",
       "   'In that case, embeddings are par-ticularly useful as a compact intermediate representa-tion that can be re-used for several purposes',\n",
       "   'This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years',\n",
       "   'TheseDBMS are at the junction of traditional databases andApproximate Nearest Neighbor Search (ANNS) algo-rithms',\n",
       "   'Until recently, the latter were mostly consid-ered for specific use-cases or in research.From a practical point of view, there are multipleadvantages to maintain a clear separation of roles be-tween the embedding extraction and the vector searchalgorithm',\n",
       "   'Both are bound by an “embedding con-tract” on the embedding distance:• The embedding extractor, which is typically aneural network in modern systems, is trained sothat distances between embeddings are alignedwith the task to perform.• The vector index aims at performing neighborsearch among the embedding vectors as accu-rately as possible w.r.t',\n",
       "   'exact search results giventhe agreed distance metric.Faiss is an industrial-grade library for ANNS',\n",
       "   'It isdesigned to be used both from simple scripts and asa building block of a DBMS',\n",
       "   'In contrast with other li-braries that focus on a single indexing method, Faissis a toolbox that contains indexing methods that com-monly involve a chain of components (preprocessing,compression, non-exhaustive search, etc.)',\n",
       "   'This is nec-essary: depending on the usage constraints, the mostefficient indexing methods are different.Let us also summarize what Faiss is not: Faiss doesnot extract features – it only indexes embeddings thathave been extracted by a different mechanism; Faissis not a service – it only provides functions that are1arXiv:2401.08281v1  [cs.LG]  16 Jan 2024'],\n",
       "  'sentence_chunks': [['THE FAISS LIBRARYMatthijs DouzeFAIR, MetaAlexandr GuzhvaZillizChengqi DengZhejiang UniversityJeff JohnsonFAIR, MetaGergely SzilvasyFAIR, MetaPierre-Emmanuel Mazar´eFAIR, MetaMaria LomeliFAIR, MetaLucas HosseiniSkip LabsHerv´e J´egouKyutaiAbstractVector databases manage large collections of embed-ding vectors',\n",
       "    'As AI applications are growing rapidly,so are the number of embeddings that need to bestored and indexed',\n",
       "    'The Faiss library is dedicated tovector similarity search, a core functionality of vectordatabases',\n",
       "    'Faiss is a toolkit of indexing methods andrelated primitives used to search, cluster, compressand transform vectors',\n",
       "    'This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing'],\n",
       "   ['This paper first describes thetradeoff space of vector search, then the design prin-ciples of Faiss in terms of structure, approach to opti-mization and interfacing',\n",
       "    'We benchmark key featuresof the library and discuss a few selected applicationsto highlight its broad applicability.1IntroductionThe emergence of deep learning has induced a shift inhow complex data is stored and searched, noticeablyby the development of embeddings',\n",
       "    'Embeddings arevector representations, typically produced by a neuralnetwork, whose main objective is to map (embed)the input media item into a vector space, where thelocality encodes the semantics of the input',\n",
       "    'Embed-dings are extracted from various forms of media:words [Mikolov et al., 2013, Bojanowski et al., 2017],text[Devlin et al., 2018,Izacard et al., 2021],im-ages[Caron et al., 2021,Pizzi et al., 2022],usersanditemsforrecommendation[Paterek, 2007].They can even encode object relations,for in-stance multi-modal text-image or text-audio rela-tions [Duquenne et al., 2023, Radford et al., 2021].Embeddings are employed as an intermediaterepresentationforfurtherprocessing,e.g.self-supervised image embeddings can input to shal-low supervised image classifiers [Caron et al., 2018,Caron et al., 2021].They are also leveraged asa pretext task for self-supervision,e.g',\n",
       "    'in Sim-CLR [Chen et al., 2020]'],\n",
       "   ['in Sim-CLR [Chen et al., 2020]',\n",
       "    'The purpose that we considerin this paper is when embeddings are used directlyto compare media items.The embedding extractoris designed such that the distance between embed-dings reflects the similarity between their correspond-ing media',\n",
       "    'As a result, neighborhood search in thisvector space offers a direct implementation of similar-ity search between media items.Embeddings are popular in industrial setting fortasks where end-to-end learning would not be cost-efficient.For example, a k nearest-neighbor classi-fier is more efficient to upgrade than a classificationdeep neural net',\n",
       "    'In that case, embeddings are par-ticularly useful as a compact intermediate representa-tion that can be re-used for several purposes',\n",
       "    'This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years'],\n",
       "   ['This ex-plains why industrial database management systems(DBMS) that offer a vector storage and search func-tionality have gained adoption in the last years',\n",
       "    'TheseDBMS are at the junction of traditional databases andApproximate Nearest Neighbor Search (ANNS) algo-rithms',\n",
       "    'Until recently, the latter were mostly consid-ered for specific use-cases or in research.From a practical point of view, there are multipleadvantages to maintain a clear separation of roles be-tween the embedding extraction and the vector searchalgorithm',\n",
       "    'Both are bound by an “embedding con-tract” on the embedding distance:• The embedding extractor, which is typically aneural network in modern systems, is trained sothat distances between embeddings are alignedwith the task to perform.• The vector index aims at performing neighborsearch among the embedding vectors as accu-rately as possible w.r.t',\n",
       "    'exact search results giventhe agreed distance metric.Faiss is an industrial-grade library for ANNS']],\n",
       "  'num_chunks': 4},\n",
       " {'doc_name': 'Faiss',\n",
       "  'text': 'exponentially with the code size. Therefore, k-meansis impractical to use beyond 3-byte codes, correspond-ing to 16M centroids.Scalar quantizersScalar quantizers encode each di-mension of a vector independently.A very classical and simple scalar quantizer is LSH(IndexLSH), where each vector component is encodedin a single bit by comparing it to a threshold. Thethreshold can be set to 0 or trained.Faiss furthersupports efficient search of binary vectors via theIndexBinary objects, see Section 4.5.The Faiss ScalarQuantizer also supports uniformquantizers that encode a vector component into 8,6 or 4 bits – referred to as SQ8, SQ6, SQ4.A per-component scale and offset determine which valuesare reconstructed. They can be set separately for eachdimension or uniformly on the whole vector.TheIndexRowwiseMinMax stores vectors with per-vectornormalizing coefficients. The ranges are trained be-forehand on a set of representative vectors. The lower-precision float16 representation is also considered as ascalar quantizer, SQfp16.Multi-codebook quantizers.Faiss contains severalmulti-codebook quantization options. They are builtfrom M vector quantizers that can reconstruct K dis-tinct values each. The codes produced by these meth-ods are of the form (c1, ..., cM) ∈ {1, ..., K}M, i.e. eachcode indexes one of the quantizers. The number of re-constructed vectors is KM and the code size is thusM⌈log2(K)⌉.The product quantizer (ProductQuantizer, alsonoted PQ) is a simple multi-codebook quantizer thatsplits the input vector into M sub-vectors and quan-tizes them separately [J´egou et al., 2010] with a k-means quantizer. At reconstruction time, the individ-ual reconstructions are concatenated to produce the fi-nal code. In the following, we will use the notationPQ6x10 for a product quantizer with 6 sub-vectorseach encoded in 10 bits (M = 6, K = 210).Additive quantizers are a family of multi-codebookquantizerswherethereconstructionsfromsub-quantizers are summed up together. Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers. Each quantizer can representthe set of reproduction values of the enclosed quantizers.Faiss also supports a combination of PQ andresidual quantizer, ProductResidualQuantizer.Inthat case, the vector is split in sub-vectors thatare encoded independently with additive quantiz-ers [Babenko and Lempitsky, 2015]. The codes fromthe sub-quantizers are concatenated. We use the no-tation PRQ2x6x10 to indicate that vectors are split in2 and encoded independently with RQ6x10, yieldinga total of 12 codebooks of size 210.Hierarchy of quantizersAlthough this is not by de-sign, it turns out that there is a strict ordering be-tween the quantizers described before. This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive. The hierarchy of quantizers is shownin Figure 2:1. the binary representation with bits +1 and -1 canbe represented as a scalar quantizer with 1 bit percomponent;2. the scalar quantizer can be represented as a prod-uct quantizer with 1 dimension per sub-vectorand uniform per-dimension quantizer;3. the product quantizer can be represented as aproduct-additive quantizer where the additivequantizer has a single level;4. the product additive quantizer is an addi-tive quantizer where within each codebook allcomponents outside one sub-vector are set to0 [Babenko and Lempitsky, 2014];5. the additive quantizer (and any other quantizer)can be represented as a vector quantizer wherethe codebook entries are the explicit enumerationof all possible reconstructions.The implications of this hierarchy are (1) the de-grees of freedom for the reproduction values of quan-tizer i + 1 are larger than for i, so it is more accurate(2) quantizer i+1 has a higher capacity so it consumesmore resources in terms of training time and storageoverhead than i. In practice, the product quantizer of-ten offers a good tradeoff, which explains its adoption.7',\n",
       "  'pg_num': 7,\n",
       "  'pg_num_chars': 4774,\n",
       "  'pg_num_words': 649,\n",
       "  'pg_num_sentences': 24,\n",
       "  'pg_num_tokens': 1193.5,\n",
       "  'sentences': ['exponentially with the code size',\n",
       "   'Therefore, k-meansis impractical to use beyond 3-byte codes, correspond-ing to 16M centroids.Scalar quantizersScalar quantizers encode each di-mension of a vector independently.A very classical and simple scalar quantizer is LSH(IndexLSH), where each vector component is encodedin a single bit by comparing it to a threshold',\n",
       "   'Thethreshold can be set to 0 or trained.Faiss furthersupports efficient search of binary vectors via theIndexBinary objects, see Section 4.5.The Faiss ScalarQuantizer also supports uniformquantizers that encode a vector component into 8,6 or 4 bits – referred to as SQ8, SQ6, SQ4.A per-component scale and offset determine which valuesare reconstructed',\n",
       "   'They can be set separately for eachdimension or uniformly on the whole vector.TheIndexRowwiseMinMax stores vectors with per-vectornormalizing coefficients',\n",
       "   'The ranges are trained be-forehand on a set of representative vectors',\n",
       "   'The lower-precision float16 representation is also considered as ascalar quantizer, SQfp16.Multi-codebook quantizers.Faiss contains severalmulti-codebook quantization options',\n",
       "   'They are builtfrom M vector quantizers that can reconstruct K dis-tinct values each',\n",
       "   'The codes produced by these meth-ods are of the form (c1, ..., cM) ∈ {1, ..., K}M, i.e',\n",
       "   'eachcode indexes one of the quantizers',\n",
       "   'The number of re-constructed vectors is KM and the code size is thusM⌈log2(K)⌉.The product quantizer (ProductQuantizer, alsonoted PQ) is a simple multi-codebook quantizer thatsplits the input vector into M sub-vectors and quan-tizes them separately [J´egou et al., 2010] with a k-means quantizer',\n",
       "   'At reconstruction time, the individ-ual reconstructions are concatenated to produce the fi-nal code',\n",
       "   'In the following, we will use the notationPQ6x10 for a product quantizer with 6 sub-vectorseach encoded in 10 bits (M = 6, K = 210).Additive quantizers are a family of multi-codebookquantizerswherethereconstructionsfromsub-quantizers are summed up together',\n",
       "   'Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers',\n",
       "   'Each quantizer can representthe set of reproduction values of the enclosed quantizers.Faiss also supports a combination of PQ andresidual quantizer, ProductResidualQuantizer.Inthat case, the vector is split in sub-vectors thatare encoded independently with additive quantiz-ers [Babenko and Lempitsky, 2015]',\n",
       "   'The codes fromthe sub-quantizers are concatenated',\n",
       "   'We use the no-tation PRQ2x6x10 to indicate that vectors are split in2 and encoded independently with RQ6x10, yieldinga total of 12 codebooks of size 210.Hierarchy of quantizersAlthough this is not by de-sign, it turns out that there is a strict ordering be-tween the quantizers described before',\n",
       "   'This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive',\n",
       "   'The hierarchy of quantizers is shownin Figure 2:1',\n",
       "   'the binary representation with bits +1 and -1 canbe represented as a scalar quantizer with 1 bit percomponent;2',\n",
       "   'the scalar quantizer can be represented as a prod-uct quantizer with 1 dimension per sub-vectorand uniform per-dimension quantizer;3',\n",
       "   'the product quantizer can be represented as aproduct-additive quantizer where the additivequantizer has a single level;4',\n",
       "   'the product additive quantizer is an addi-tive quantizer where within each codebook allcomponents outside one sub-vector are set to0 [Babenko and Lempitsky, 2014];5',\n",
       "   'the additive quantizer (and any other quantizer)can be represented as a vector quantizer wherethe codebook entries are the explicit enumerationof all possible reconstructions.The implications of this hierarchy are (1) the de-grees of freedom for the reproduction values of quan-tizer i + 1 are larger than for i, so it is more accurate(2) quantizer i+1 has a higher capacity so it consumesmore resources in terms of training time and storageoverhead than i',\n",
       "   'In practice, the product quantizer of-ten offers a good tradeoff, which explains its adoption.7'],\n",
       "  'sentence_chunks': [['exponentially with the code size',\n",
       "    'Therefore, k-meansis impractical to use beyond 3-byte codes, correspond-ing to 16M centroids.Scalar quantizersScalar quantizers encode each di-mension of a vector independently.A very classical and simple scalar quantizer is LSH(IndexLSH), where each vector component is encodedin a single bit by comparing it to a threshold',\n",
       "    'Thethreshold can be set to 0 or trained.Faiss furthersupports efficient search of binary vectors via theIndexBinary objects, see Section 4.5.The Faiss ScalarQuantizer also supports uniformquantizers that encode a vector component into 8,6 or 4 bits – referred to as SQ8, SQ6, SQ4.A per-component scale and offset determine which valuesare reconstructed',\n",
       "    'They can be set separately for eachdimension or uniformly on the whole vector.TheIndexRowwiseMinMax stores vectors with per-vectornormalizing coefficients',\n",
       "    'The ranges are trained be-forehand on a set of representative vectors'],\n",
       "   ['The ranges are trained be-forehand on a set of representative vectors',\n",
       "    'The lower-precision float16 representation is also considered as ascalar quantizer, SQfp16.Multi-codebook quantizers.Faiss contains severalmulti-codebook quantization options',\n",
       "    'They are builtfrom M vector quantizers that can reconstruct K dis-tinct values each',\n",
       "    'The codes produced by these meth-ods are of the form (c1, ..., cM) ∈ {1, ..., K}M, i.e',\n",
       "    'eachcode indexes one of the quantizers'],\n",
       "   ['eachcode indexes one of the quantizers',\n",
       "    'The number of re-constructed vectors is KM and the code size is thusM⌈log2(K)⌉.The product quantizer (ProductQuantizer, alsonoted PQ) is a simple multi-codebook quantizer thatsplits the input vector into M sub-vectors and quan-tizes them separately [J´egou et al., 2010] with a k-means quantizer',\n",
       "    'At reconstruction time, the individ-ual reconstructions are concatenated to produce the fi-nal code',\n",
       "    'In the following, we will use the notationPQ6x10 for a product quantizer with 6 sub-vectorseach encoded in 10 bits (M = 6, K = 210).Additive quantizers are a family of multi-codebookquantizerswherethereconstructionsfromsub-quantizers are summed up together',\n",
       "    'Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers'],\n",
       "   ['Finding the opti-mal encoding for a vector given the codebooks is NP-hard, so practical additive quantizers are heuristics tofind near-optimal codes.Faiss supports two types of additive quantiz-ers.The residual quantizer (ResidualQuantizer)proceedssequentially,byencodingthediffer-ence (residual) of the vector to encode and theone that is reconstructed by the previous sub-quantizers [Chen et al., 2010].The localsearchquantizer(LocalSearchQuantizer)startsfromasub-optimal encoding of the vector and locally ex-plores neighbording codes in a simulated annealingprocess [Martinez et al., 2016, Martinez et al., 2018].We use notations LSQ6x10 and RQ6x10 to refer toadditive quantizers with 6 codebooks of size 210.Additive quantizerProduct quantizerScalar quantizerBinarizationVector quantizerProduct - additive quantizerFigure 2: The hierarchy of quantizers',\n",
       "    'Each quantizer can representthe set of reproduction values of the enclosed quantizers.Faiss also supports a combination of PQ andresidual quantizer, ProductResidualQuantizer.Inthat case, the vector is split in sub-vectors thatare encoded independently with additive quantiz-ers [Babenko and Lempitsky, 2015]',\n",
       "    'The codes fromthe sub-quantizers are concatenated',\n",
       "    'We use the no-tation PRQ2x6x10 to indicate that vectors are split in2 and encoded independently with RQ6x10, yieldinga total of 12 codebooks of size 210.Hierarchy of quantizersAlthough this is not by de-sign, it turns out that there is a strict ordering be-tween the quantizers described before',\n",
       "    'This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive'],\n",
       "   ['This meansthat quantizer i+1 can have the same set of reproduc-tion values as quantizer i: it is more flexible and moredata adaptive',\n",
       "    'The hierarchy of quantizers is shownin Figure 2:1',\n",
       "    'the binary representation with bits +1 and -1 canbe represented as a scalar quantizer with 1 bit percomponent;2',\n",
       "    'the scalar quantizer can be represented as a prod-uct quantizer with 1 dimension per sub-vectorand uniform per-dimension quantizer;3',\n",
       "    'the product quantizer can be represented as aproduct-additive quantizer where the additivequantizer has a single level;4']],\n",
       "  'num_chunks': 5}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.sample(all_content_[2],k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ea2631b-bc9d-4ad5-b32f-b6eb07ec631f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:36.519052Z",
     "iopub.status.busy": "2024-04-03T19:00:36.518386Z",
     "iopub.status.idle": "2024-04-03T19:00:36.544648Z",
     "shell.execute_reply": "2024-04-03T19:00:36.543931Z",
     "shell.execute_reply.started": "2024-04-03T19:00:36.519020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2900.025997</td>\n",
       "      <td>418.400347</td>\n",
       "      <td>32.854419</td>\n",
       "      <td>725.006499</td>\n",
       "      <td>7.608319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>166.709828</td>\n",
       "      <td>1175.894326</td>\n",
       "      <td>155.640269</td>\n",
       "      <td>98.641975</td>\n",
       "      <td>293.973582</td>\n",
       "      <td>24.652779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>2349.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>587.250000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2773.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>693.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>433.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>11555.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>2888.750000</td>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pg_num  pg_num_chars  pg_num_words  pg_num_sentences  \\\n",
       "count  577.000000    577.000000    577.000000        577.000000   \n",
       "mean   289.000000   2900.025997    418.400347         32.854419   \n",
       "std    166.709828   1175.894326    155.640269         98.641975   \n",
       "min      1.000000      0.000000      1.000000          1.000000   \n",
       "25%    145.000000   2349.000000    340.000000         10.000000   \n",
       "50%    289.000000   2773.000000    412.000000         13.000000   \n",
       "75%    433.000000   3232.000000    476.000000         17.000000   \n",
       "max    577.000000  11555.000000   1474.000000        994.000000   \n",
       "\n",
       "       pg_num_tokens  num_chunks  \n",
       "count     577.000000  577.000000  \n",
       "mean      725.006499    7.608319  \n",
       "std       293.973582   24.652779  \n",
       "min         0.000000    0.000000  \n",
       "25%       587.250000    2.000000  \n",
       "50%       693.250000    3.000000  \n",
       "75%       808.000000    4.000000  \n",
       "max      2888.750000  248.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "501fbfcd-2c8e-44bb-90f4-2d0fc3b146fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:37.611611Z",
     "iopub.status.busy": "2024-04-03T19:00:37.610580Z",
     "iopub.status.idle": "2024-04-03T19:00:37.636868Z",
     "shell.execute_reply": "2024-04-03T19:00:37.635898Z",
     "shell.execute_reply.started": "2024-04-03T19:00:37.611559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2569.800000</td>\n",
       "      <td>338.40000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>642.450000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.472136</td>\n",
       "      <td>1084.092853</td>\n",
       "      <td>166.50474</td>\n",
       "      <td>11.814035</td>\n",
       "      <td>271.023213</td>\n",
       "      <td>2.947154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2132.500000</td>\n",
       "      <td>304.50000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>533.125000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3036.000000</td>\n",
       "      <td>383.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>3170.000000</td>\n",
       "      <td>459.00000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>792.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>4203.000000</td>\n",
       "      <td>570.00000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1050.750000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  15.000000     15.000000      15.00000         15.000000      15.000000   \n",
       "mean    8.000000   2569.800000     338.40000         17.000000     642.450000   \n",
       "std     4.472136   1084.092853     166.50474         11.814035     271.023213   \n",
       "min     1.000000    702.000000      45.00000          3.000000     175.500000   \n",
       "25%     4.500000   2132.500000     304.50000         12.000000     533.125000   \n",
       "50%     8.000000   3036.000000     383.00000         15.000000     759.000000   \n",
       "75%    11.500000   3170.000000     459.00000         18.500000     792.500000   \n",
       "max    15.000000   4203.000000     570.00000         43.000000    1050.750000   \n",
       "\n",
       "       num_chunks  \n",
       "count   15.000000  \n",
       "mean     3.600000  \n",
       "std      2.947154  \n",
       "min      0.000000  \n",
       "25%      2.500000  \n",
       "50%      3.000000  \n",
       "75%      4.000000  \n",
       "max     10.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[1]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f79a8345-70f0-427a-a1cb-22b30d1dcfdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:38.468572Z",
     "iopub.status.busy": "2024-04-03T19:00:38.467270Z",
     "iopub.status.idle": "2024-04-03T19:00:38.491522Z",
     "shell.execute_reply": "2024-04-03T19:00:38.490679Z",
     "shell.execute_reply.started": "2024-04-03T19:00:38.468520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4713.047619</td>\n",
       "      <td>651.142857</td>\n",
       "      <td>26.857143</td>\n",
       "      <td>1178.261905</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.204837</td>\n",
       "      <td>600.454701</td>\n",
       "      <td>98.317997</td>\n",
       "      <td>14.118377</td>\n",
       "      <td>150.113675</td>\n",
       "      <td>3.507136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3133.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>783.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1105.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4792.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>5049.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1262.250000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>5733.000000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1433.250000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  21.000000     21.000000     21.000000         21.000000      21.000000   \n",
       "mean   11.000000   4713.047619    651.142857         26.857143    1178.261905   \n",
       "std     6.204837    600.454701     98.317997         14.118377     150.113675   \n",
       "min     1.000000   3133.000000    408.000000         13.000000     783.250000   \n",
       "25%     6.000000   4422.000000    592.000000         19.000000    1105.500000   \n",
       "50%    11.000000   4792.000000    651.000000         23.000000    1198.000000   \n",
       "75%    16.000000   5049.000000    716.000000         24.000000    1262.250000   \n",
       "max    21.000000   5733.000000    806.000000         63.000000    1433.250000   \n",
       "\n",
       "       num_chunks  \n",
       "count   21.000000  \n",
       "mean     6.000000  \n",
       "std      3.507136  \n",
       "min      3.000000  \n",
       "25%      4.000000  \n",
       "50%      5.000000  \n",
       "75%      5.000000  \n",
       "max     15.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[2]).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e3a14d-6873-420f-a0cd-46e5472cd92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:39.262840Z",
     "iopub.status.busy": "2024-04-03T19:00:39.261732Z",
     "iopub.status.idle": "2024-04-03T19:00:39.285840Z",
     "shell.execute_reply": "2024-04-03T19:00:39.284919Z",
     "shell.execute_reply.started": "2024-04-03T19:00:39.262805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>pg_num_chars</th>\n",
       "      <th>pg_num_words</th>\n",
       "      <th>pg_num_sentences</th>\n",
       "      <th>pg_num_tokens</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>2324.854839</td>\n",
       "      <td>294.064516</td>\n",
       "      <td>11.983871</td>\n",
       "      <td>581.213710</td>\n",
       "      <td>2.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.041619</td>\n",
       "      <td>1125.285987</td>\n",
       "      <td>150.230192</td>\n",
       "      <td>8.864170</td>\n",
       "      <td>281.321497</td>\n",
       "      <td>2.236423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.250000</td>\n",
       "      <td>1292.250000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>323.062500</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>2419.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>604.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.750000</td>\n",
       "      <td>3361.000000</td>\n",
       "      <td>413.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>840.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>4105.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1026.250000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pg_num  pg_num_chars  pg_num_words  pg_num_sentences  pg_num_tokens  \\\n",
       "count  62.000000     62.000000     62.000000         62.000000      62.000000   \n",
       "mean   31.500000   2324.854839    294.064516         11.983871     581.213710   \n",
       "std    18.041619   1125.285987    150.230192          8.864170     281.321497   \n",
       "min     1.000000    587.000000     87.000000          1.000000     146.750000   \n",
       "25%    16.250000   1292.250000    125.500000          4.250000     323.062500   \n",
       "50%    31.500000   2419.000000    329.000000         11.000000     604.750000   \n",
       "75%    46.750000   3361.000000    413.750000         17.000000     840.250000   \n",
       "max    62.000000   4105.000000    559.000000         36.000000    1026.250000   \n",
       "\n",
       "       num_chunks  \n",
       "count   62.000000  \n",
       "mean     2.419355  \n",
       "std      2.236423  \n",
       "min      0.000000  \n",
       "25%      0.250000  \n",
       "50%      2.000000  \n",
       "75%      4.000000  \n",
       "max      8.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_content_[3]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "307ae1cd-6aa0-4cc8-9efd-fb3f1db3811e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:39.906835Z",
     "iopub.status.busy": "2024-04-03T19:00:39.905861Z",
     "iopub.status.idle": "2024-04-03T19:00:39.913278Z",
     "shell.execute_reply": "2024-04-03T19:00:39.912497Z",
     "shell.execute_reply.started": "2024-04-03T19:00:39.906801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the sentence_chunks into it's own individual chunks to reduce size further.\n",
    "import re\n",
    "all_pdf_formatted = []\n",
    "def final_chunk_dict(all_content, all_pdf_formatted):\n",
    "    for doc in tqdm(all_content):\n",
    "        for page in doc:\n",
    "            for sentence_chunk in page[\"sentence_chunks\"]:\n",
    "                chunk_ = {}\n",
    "                chunk_[\"pg_num\"] = page[\"pg_num\"]\n",
    "                # Join sentences like a paragraph structure\n",
    "                joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "                joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # spacing issue after join.\n",
    "                chunk_[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "                #write metadata\n",
    "                chunk_[\"chunk_num_chars\"] = len(joined_sentence_chunk)\n",
    "                chunk_[\"chunk_num_tokens\"] = len(joined_sentence_chunk) / 4\n",
    "                chunk_[\"chunk_num_words\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "                chunk_[\"doc_name\"] = page[\"doc_name\"]\n",
    "                all_pdf_formatted.append(chunk_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ddfa4b0-a5c3-48c7-aede-27464f121c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:41.031994Z",
     "iopub.status.busy": "2024-04-03T19:00:41.030673Z",
     "iopub.status.idle": "2024-04-03T19:00:41.110884Z",
     "shell.execute_reply": "2024-04-03T19:00:41.109655Z",
     "shell.execute_reply.started": "2024-04-03T19:00:41.031944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f173b87870794c89833a314e54165f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_chunk_dict(all_content_, all_pdf_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cfa6892-493c-4473-bd53-9d1ad33c9ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:42.397958Z",
     "iopub.status.busy": "2024-04-03T19:00:42.397013Z",
     "iopub.status.idle": "2024-04-03T19:00:42.403369Z",
     "shell.execute_reply": "2024-04-03T19:00:42.402481Z",
     "shell.execute_reply.started": "2024-04-03T19:00:42.397922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pg_num': 335,\n",
       "  'sentence_chunk': 'ﬁll back in correct slot values, resultingrelexicalizein “Au Midi has decent service”.15.4ChatbotsChatbots are systems that can carry on extended conversations with the goal ofchatbotmimicking the unstructured conversations or ‘chats’ characteristic of informal human-human interactionWhile early systems like ELIZA (Weizenbaum, 1966) or PARRY(Colby et al., 1971) had theoretical goals like testing theories of psychological coun-seling, for most of the last 50 years chatbots have been designed for entertainment. That changed with the recent rise of neural chatbots like ChatGPT, which incor-porate solutions to NLP tasks like question answering, writing tools, or machinetranslation into a conversational interfaceA conversation with ChatGPT is shownin Fig15.12In this section we describe neural chatbot architectures and datasets.[TBD]Figure 15.12A conversation with ChatGPT.15.4.1Training chatbotsDataChatbots are generally trained on a training set that includes standard largelanguage model training data of the type discussed in Section 10.9.2: versions of theweb from the Common Crawl, including news sites, Wikipedia, as well as books. For training chatbots, it is common to additionally add lots of dialogue data. This can include datasets created speciﬁcally for training chatbots by hiringspeakers of the language to have conversations, such as by having them take onpersonas or talk about knowledge provided to them',\n",
       "  'chunk_num_chars': 1429,\n",
       "  'chunk_num_tokens': 357.25,\n",
       "  'chunk_num_words': 195,\n",
       "  'doc_name': 'Standford NLP'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_pdf_formatted,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c23de83b-4b7b-4101-b314-77b702494f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:43.974498Z",
     "iopub.status.busy": "2024-04-03T19:00:43.973814Z",
     "iopub.status.idle": "2024-04-03T19:00:43.986319Z",
     "shell.execute_reply": "2024-04-03T19:00:43.985351Z",
     "shell.execute_reply.started": "2024-04-03T19:00:43.974467Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = pd.DataFrame(all_pdf_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8c02a5a-9cec-4932-bedb-880c7d12f996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:44.910874Z",
     "iopub.status.busy": "2024-04-03T19:00:44.909727Z",
     "iopub.status.idle": "2024-04-03T19:00:44.929402Z",
     "shell.execute_reply": "2024-04-03T19:00:44.928480Z",
     "shell.execute_reply.started": "2024-04-03T19:00:44.910835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>273.468599</td>\n",
       "      <td>417.125814</td>\n",
       "      <td>104.281453</td>\n",
       "      <td>58.060912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>245.631995</td>\n",
       "      <td>545.919045</td>\n",
       "      <td>136.479761</td>\n",
       "      <td>76.180003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>257.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>189.500000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  4761.000000      4761.000000       4761.000000      4761.000000\n",
       "mean    273.468599       417.125814        104.281453        58.060912\n",
       "std     245.631995       545.919045        136.479761        76.180003\n",
       "min       1.000000         0.000000          0.000000         1.000000\n",
       "25%       7.000000        27.000000          6.750000         3.000000\n",
       "50%     257.000000       134.000000         33.500000        15.000000\n",
       "75%     548.000000       758.000000        189.500000       109.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9ccb5bd-4d6a-4a8d-9498-dd215852e5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:45.716482Z",
     "iopub.status.busy": "2024-04-03T19:00:45.715719Z",
     "iopub.status.idle": "2024-04-03T19:00:45.723141Z",
     "shell.execute_reply": "2024-04-03T19:00:45.721763Z",
     "shell.execute_reply.started": "2024-04-03T19:00:45.716450Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_df = all_pdf_formatted_df[all_pdf_formatted_df['chunk_num_tokens'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c257ff8-57f3-4d3f-b73b-3ba09ac70d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:46.683988Z",
     "iopub.status.busy": "2024-04-03T19:00:46.683607Z",
     "iopub.status.idle": "2024-04-03T19:00:46.700044Z",
     "shell.execute_reply": "2024-04-03T19:00:46.699303Z",
     "shell.execute_reply.started": "2024-04-03T19:00:46.683957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "      <th>doc_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>51</td>\n",
       "      <td>It was my first time in the Big Apple, and I h...</td>\n",
       "      <td>351</td>\n",
       "      <td>87.75</td>\n",
       "      <td>70</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>51</td>\n",
       "      <td>Iloved running around and playing fetchWe also...</td>\n",
       "      <td>321</td>\n",
       "      <td>80.25</td>\n",
       "      <td>55</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>52</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>704</td>\n",
       "      <td>176.00</td>\n",
       "      <td>107</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>53</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>347</td>\n",
       "      <td>86.75</td>\n",
       "      <td>61</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>53</td>\n",
       "      <td>The roots of this equation are 𝑥1 = 5 and𝑥2 = ...</td>\n",
       "      <td>353</td>\n",
       "      <td>88.25</td>\n",
       "      <td>59</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>53</td>\n",
       "      <td>The model shows good understanding of the task...</td>\n",
       "      <td>472</td>\n",
       "      <td>118.00</td>\n",
       "      <td>69</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>54</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>687</td>\n",
       "      <td>171.75</td>\n",
       "      <td>109</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>57</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>398</td>\n",
       "      <td>99.50</td>\n",
       "      <td>62</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>60</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>2132</td>\n",
       "      <td>533.00</td>\n",
       "      <td>345</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>62</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>627</td>\n",
       "      <td>156.75</td>\n",
       "      <td>94</td>\n",
       "      <td>Gemini_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>1</td>\n",
       "      <td>BART: Denoising Sequence-to-Sequence Pre-train...</td>\n",
       "      <td>2061</td>\n",
       "      <td>515.25</td>\n",
       "      <td>268</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>1</td>\n",
       "      <td>Wealso report ablation experiments that replic...</td>\n",
       "      <td>1360</td>\n",
       "      <td>340.00</td>\n",
       "      <td>186</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>1</td>\n",
       "      <td>BART is a denoising autoencoder builtwith a se...</td>\n",
       "      <td>1733</td>\n",
       "      <td>433.25</td>\n",
       "      <td>244</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>2</td>\n",
       "      <td>Bidirectional EncoderA _ C _ E B    D  (a) BER...</td>\n",
       "      <td>1504</td>\n",
       "      <td>376.00</td>\n",
       "      <td>229</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>2</td>\n",
       "      <td>The corrupted document (left) is encoded witha...</td>\n",
       "      <td>2180</td>\n",
       "      <td>545.00</td>\n",
       "      <td>306</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>2</td>\n",
       "      <td>The architecture is closely related to that us...</td>\n",
       "      <td>1362</td>\n",
       "      <td>340.50</td>\n",
       "      <td>184</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>3</td>\n",
       "      <td>D _ E . A _C _ E . C D E A BDocument RotationT...</td>\n",
       "      <td>188</td>\n",
       "      <td>47.00</td>\n",
       "      <td>35</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>3</td>\n",
       "      <td>A B C . Sentence PermutationFigure 2: Transfor...</td>\n",
       "      <td>904</td>\n",
       "      <td>226.00</td>\n",
       "      <td>134</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>3</td>\n",
       "      <td>Text inﬁll-ing teaches the model to predict ho...</td>\n",
       "      <td>1756</td>\n",
       "      <td>439.00</td>\n",
       "      <td>245</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>3</td>\n",
       "      <td>Here, the encoder in-put is the input sequence...</td>\n",
       "      <td>1059</td>\n",
       "      <td>264.75</td>\n",
       "      <td>154</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>3</td>\n",
       "      <td>The new encoder can use aseparate vocabulary f...</td>\n",
       "      <td>1127</td>\n",
       "      <td>281.75</td>\n",
       "      <td>157</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>4</td>\n",
       "      <td>Pre-trained DecoderPre-trained EncoderlabelA B...</td>\n",
       "      <td>1186</td>\n",
       "      <td>296.50</td>\n",
       "      <td>175</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>4</td>\n",
       "      <td>For refer-ence, we compare our implementations...</td>\n",
       "      <td>2187</td>\n",
       "      <td>546.75</td>\n",
       "      <td>317</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>4</td>\n",
       "      <td>We ﬁnd the former works better for BARTmodels,...</td>\n",
       "      <td>1398</td>\n",
       "      <td>349.50</td>\n",
       "      <td>198</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>5</td>\n",
       "      <td>ModelSQuAD 1.1MNLIELI5XSumConvAI2CNN/DMF1AccPP...</td>\n",
       "      <td>1343</td>\n",
       "      <td>335.75</td>\n",
       "      <td>129</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>5</td>\n",
       "      <td>Performance varies considerably across tasks, ...</td>\n",
       "      <td>1689</td>\n",
       "      <td>422.25</td>\n",
       "      <td>209</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>5</td>\n",
       "      <td>Some of this dif-ference is likely due to not ...</td>\n",
       "      <td>1291</td>\n",
       "      <td>322.75</td>\n",
       "      <td>187</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>6</td>\n",
       "      <td>SQuAD 1.1SQuAD 2.0MNLISSTQQPQNLISTS-BRTEMRPCCo...</td>\n",
       "      <td>1860</td>\n",
       "      <td>465.00</td>\n",
       "      <td>186</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>6</td>\n",
       "      <td>We use the same pre-training data as Liu et al...</td>\n",
       "      <td>1684</td>\n",
       "      <td>421.00</td>\n",
       "      <td>223</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>6</td>\n",
       "      <td>During generation, we set beam size as 5,remov...</td>\n",
       "      <td>1315</td>\n",
       "      <td>328.75</td>\n",
       "      <td>162</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>7</td>\n",
       "      <td>ELI5R1R2RLBest Extractive23.53.117.5Language M...</td>\n",
       "      <td>925</td>\n",
       "      <td>231.25</td>\n",
       "      <td>98</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>7</td>\n",
       "      <td>We ﬁnd BART outperforms the best pre-vious wor...</td>\n",
       "      <td>1841</td>\n",
       "      <td>460.25</td>\n",
       "      <td>246</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>7</td>\n",
       "      <td>However, model output is also highly ab-stract...</td>\n",
       "      <td>974</td>\n",
       "      <td>243.50</td>\n",
       "      <td>129</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>7</td>\n",
       "      <td>GPT (Radford et al., 2018) only models left-wa...</td>\n",
       "      <td>919</td>\n",
       "      <td>229.75</td>\n",
       "      <td>128</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>7</td>\n",
       "      <td>Predictions are not made auto-regressively, re...</td>\n",
       "      <td>712</td>\n",
       "      <td>178.00</td>\n",
       "      <td>101</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>8</td>\n",
       "      <td>Source Document (abbreviated)BART SummaryThe r...</td>\n",
       "      <td>1245</td>\n",
       "      <td>311.25</td>\n",
       "      <td>188</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>8</td>\n",
       "      <td>He said, “I hope that Anne Sacoolas will come ...</td>\n",
       "      <td>979</td>\n",
       "      <td>244.75</td>\n",
       "      <td>146</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>8</td>\n",
       "      <td>On Wednesday, Turkey began a militaryoffensive...</td>\n",
       "      <td>808</td>\n",
       "      <td>202.00</td>\n",
       "      <td>121</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>8</td>\n",
       "      <td>It was an event speciﬁcally designed tohelp Ki...</td>\n",
       "      <td>789</td>\n",
       "      <td>197.25</td>\n",
       "      <td>117</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>8</td>\n",
       "      <td>Summaries combine information from across the ...</td>\n",
       "      <td>1079</td>\n",
       "      <td>269.75</td>\n",
       "      <td>139</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>9</td>\n",
       "      <td>ReferencesEneko Agirre, Llu’is M‘arquez, and R...</td>\n",
       "      <td>643</td>\n",
       "      <td>160.75</td>\n",
       "      <td>69</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>9</td>\n",
       "      <td>Springer, 2006. Jacob Devlin, Ming-Wei Chang, ...</td>\n",
       "      <td>788</td>\n",
       "      <td>197.00</td>\n",
       "      <td>85</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>9</td>\n",
       "      <td>doi: 10.18653/v1/N19-1423. URL https://www.acl...</td>\n",
       "      <td>833</td>\n",
       "      <td>208.25</td>\n",
       "      <td>92</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>9</td>\n",
       "      <td>arXiv preprint arXiv:1905.03197, 2019. Sergey ...</td>\n",
       "      <td>693</td>\n",
       "      <td>173.25</td>\n",
       "      <td>82</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>9</td>\n",
       "      <td>Gaussian error lin-ear units (gelus)arXiv prep...</td>\n",
       "      <td>385</td>\n",
       "      <td>96.25</td>\n",
       "      <td>45</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>9</td>\n",
       "      <td>1693–1701, 2015. Mandar Joshi, Danqi Chen, Yin...</td>\n",
       "      <td>617</td>\n",
       "      <td>154.25</td>\n",
       "      <td>70</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>9</td>\n",
       "      <td>The Winograd schema challengeIn AAAISpring Sym...</td>\n",
       "      <td>895</td>\n",
       "      <td>223.75</td>\n",
       "      <td>103</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>9</td>\n",
       "      <td>Efﬁcient estimation of word representationsin ...</td>\n",
       "      <td>917</td>\n",
       "      <td>229.25</td>\n",
       "      <td>86</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>10</td>\n",
       "      <td>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyr...</td>\n",
       "      <td>1131</td>\n",
       "      <td>282.75</td>\n",
       "      <td>134</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4760</th>\n",
       "      <td>10</td>\n",
       "      <td>In Advances in neural information processingsy...</td>\n",
       "      <td>703</td>\n",
       "      <td>175.75</td>\n",
       "      <td>79</td>\n",
       "      <td>BART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pg_num                                     sentence_chunk  \\\n",
       "4710      51  It was my first time in the Big Apple, and I h...   \n",
       "4711      51  Iloved running around and playing fetchWe also...   \n",
       "4712      52  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4713      53  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4714      53  The roots of this equation are 𝑥1 = 5 and𝑥2 = ...   \n",
       "4715      53  The model shows good understanding of the task...   \n",
       "4716      54  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4717      57  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4718      60  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4719      62  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "4720       1  BART: Denoising Sequence-to-Sequence Pre-train...   \n",
       "4721       1  Wealso report ablation experiments that replic...   \n",
       "4722       1  BART is a denoising autoencoder builtwith a se...   \n",
       "4723       2  Bidirectional EncoderA _ C _ E B    D  (a) BER...   \n",
       "4724       2  The corrupted document (left) is encoded witha...   \n",
       "4725       2  The architecture is closely related to that us...   \n",
       "4727       3  D _ E . A _C _ E . C D E A BDocument RotationT...   \n",
       "4728       3  A B C . Sentence PermutationFigure 2: Transfor...   \n",
       "4729       3  Text inﬁll-ing teaches the model to predict ho...   \n",
       "4730       3  Here, the encoder in-put is the input sequence...   \n",
       "4731       3  The new encoder can use aseparate vocabulary f...   \n",
       "4732       4  Pre-trained DecoderPre-trained EncoderlabelA B...   \n",
       "4733       4  For refer-ence, we compare our implementations...   \n",
       "4734       4  We ﬁnd the former works better for BARTmodels,...   \n",
       "4735       5  ModelSQuAD 1.1MNLIELI5XSumConvAI2CNN/DMF1AccPP...   \n",
       "4736       5  Performance varies considerably across tasks, ...   \n",
       "4737       5  Some of this dif-ference is likely due to not ...   \n",
       "4738       6  SQuAD 1.1SQuAD 2.0MNLISSTQQPQNLISTS-BRTEMRPCCo...   \n",
       "4739       6  We use the same pre-training data as Liu et al...   \n",
       "4740       6  During generation, we set beam size as 5,remov...   \n",
       "4741       7  ELI5R1R2RLBest Extractive23.53.117.5Language M...   \n",
       "4742       7  We ﬁnd BART outperforms the best pre-vious wor...   \n",
       "4743       7  However, model output is also highly ab-stract...   \n",
       "4744       7  GPT (Radford et al., 2018) only models left-wa...   \n",
       "4745       7  Predictions are not made auto-regressively, re...   \n",
       "4746       8  Source Document (abbreviated)BART SummaryThe r...   \n",
       "4747       8  He said, “I hope that Anne Sacoolas will come ...   \n",
       "4748       8  On Wednesday, Turkey began a militaryoffensive...   \n",
       "4749       8  It was an event speciﬁcally designed tohelp Ki...   \n",
       "4750       8  Summaries combine information from across the ...   \n",
       "4751       9  ReferencesEneko Agirre, Llu’is M‘arquez, and R...   \n",
       "4752       9  Springer, 2006. Jacob Devlin, Ming-Wei Chang, ...   \n",
       "4753       9  doi: 10.18653/v1/N19-1423. URL https://www.acl...   \n",
       "4754       9  arXiv preprint arXiv:1905.03197, 2019. Sergey ...   \n",
       "4755       9  Gaussian error lin-ear units (gelus)arXiv prep...   \n",
       "4756       9  1693–1701, 2015. Mandar Joshi, Danqi Chen, Yin...   \n",
       "4757       9  The Winograd schema challengeIn AAAISpring Sym...   \n",
       "4758       9  Efﬁcient estimation of word representationsin ...   \n",
       "4759      10  Pranav Rajpurkar, Jian Zhang, Konstantin Lopyr...   \n",
       "4760      10  In Advances in neural information processingsy...   \n",
       "\n",
       "      chunk_num_chars  chunk_num_tokens  chunk_num_words      doc_name  \n",
       "4710              351             87.75               70  Gemini_paper  \n",
       "4711              321             80.25               55  Gemini_paper  \n",
       "4712              704            176.00              107  Gemini_paper  \n",
       "4713              347             86.75               61  Gemini_paper  \n",
       "4714              353             88.25               59  Gemini_paper  \n",
       "4715              472            118.00               69  Gemini_paper  \n",
       "4716              687            171.75              109  Gemini_paper  \n",
       "4717              398             99.50               62  Gemini_paper  \n",
       "4718             2132            533.00              345  Gemini_paper  \n",
       "4719              627            156.75               94  Gemini_paper  \n",
       "4720             2061            515.25              268          BART  \n",
       "4721             1360            340.00              186          BART  \n",
       "4722             1733            433.25              244          BART  \n",
       "4723             1504            376.00              229          BART  \n",
       "4724             2180            545.00              306          BART  \n",
       "4725             1362            340.50              184          BART  \n",
       "4727              188             47.00               35          BART  \n",
       "4728              904            226.00              134          BART  \n",
       "4729             1756            439.00              245          BART  \n",
       "4730             1059            264.75              154          BART  \n",
       "4731             1127            281.75              157          BART  \n",
       "4732             1186            296.50              175          BART  \n",
       "4733             2187            546.75              317          BART  \n",
       "4734             1398            349.50              198          BART  \n",
       "4735             1343            335.75              129          BART  \n",
       "4736             1689            422.25              209          BART  \n",
       "4737             1291            322.75              187          BART  \n",
       "4738             1860            465.00              186          BART  \n",
       "4739             1684            421.00              223          BART  \n",
       "4740             1315            328.75              162          BART  \n",
       "4741              925            231.25               98          BART  \n",
       "4742             1841            460.25              246          BART  \n",
       "4743              974            243.50              129          BART  \n",
       "4744              919            229.75              128          BART  \n",
       "4745              712            178.00              101          BART  \n",
       "4746             1245            311.25              188          BART  \n",
       "4747              979            244.75              146          BART  \n",
       "4748              808            202.00              121          BART  \n",
       "4749              789            197.25              117          BART  \n",
       "4750             1079            269.75              139          BART  \n",
       "4751              643            160.75               69          BART  \n",
       "4752              788            197.00               85          BART  \n",
       "4753              833            208.25               92          BART  \n",
       "4754              693            173.25               82          BART  \n",
       "4755              385             96.25               45          BART  \n",
       "4756              617            154.25               70          BART  \n",
       "4757              895            223.75              103          BART  \n",
       "4758              917            229.25               86          BART  \n",
       "4759             1131            282.75              134          BART  \n",
       "4760              703            175.75               79          BART  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e89eddc-7e15-42e2-84e3-bede788e2097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:47.608846Z",
     "iopub.status.busy": "2024-04-03T19:00:47.608078Z",
     "iopub.status.idle": "2024-04-03T19:00:47.628225Z",
     "shell.execute_reply": "2024-04-03T19:00:47.627461Z",
     "shell.execute_reply.started": "2024-04-03T19:00:47.608812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dece0490-ecdd-4d8a-bfc8-061c0e893619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:48.501917Z",
     "iopub.status.busy": "2024-04-03T19:00:48.501428Z",
     "iopub.status.idle": "2024-04-03T19:00:48.513174Z",
     "shell.execute_reply": "2024-04-03T19:00:48.511898Z",
     "shell.execute_reply.started": "2024-04-03T19:00:48.501877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n",
      "979\n",
      "398CHAPTER 18•DEPENDENCY PARSINGleading to a parse for the following example. Book me the morningﬂightiobjobjdetcompoundroot(18.7)Let’s consider the state of the conﬁguration at Step 2, after the word me has beenpushed onto the stack. StackWord ListRelations[root, book, me] [the, morning, ﬂight]The correct operator to apply here is RIGHTARC which assigns book as the head ofme and pops me from the stack resulting in the following conﬁguration. StackWord ListRelations[root, book] [the, morning, ﬂight] (book → me)After several subsequent applications of the SHIFT and LEFTARC operators, the con-ﬁguration in Step 6 looks like the following:StackWord ListRelations[root, book, the, morning, ﬂight][](book → me)Here, all the remaining words have been passed onto the stack and all that is leftto do is to apply the appropriate reduce operatorsIn the current conﬁguration, weemploy the LEFTARC operator resulting in the following state. StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.\n",
      "234.0\n",
      "\n",
      "StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.\n"
     ]
    }
   ],
   "source": [
    "# Using only 1 step for reducing max_tokens\n",
    "# Optimize later using recursion , if max_tokens_length still greater than 384\n",
    "# Testing:\n",
    "\n",
    "sample = {'pg_num': 406,\n",
    "  'sentence_chunk': '398CHAPTER 18•DEPENDENCY PARSINGleading to a parse for the following example. Book me the morningﬂightiobjobjdetcompoundroot(18.7)Let’s consider the state of the conﬁguration at Step 2, after the word me has beenpushed onto the stack. StackWord ListRelations[root, book, me] [the, morning, ﬂight]The correct operator to apply here is RIGHTARC which assigns book as the head ofme and pops me from the stack resulting in the following conﬁguration. StackWord ListRelations[root, book] [the, morning, ﬂight] (book → me)After several subsequent applications of the SHIFT and LEFTARC operators, the con-ﬁguration in Step 6 looks like the following:StackWord ListRelations[root, book, the, morning, ﬂight][](book → me)Here, all the remaining words have been passed onto the stack and all that is leftto do is to apply the appropriate reduce operatorsIn the current conﬁguration, weemploy the LEFTARC operator resulting in the following state. StackWord ListRelations[root, book, the, ﬂight][](book → me)(morning ← ﬂight)At this point, the parse for this sentence consists of the following structure. Book me the morning ﬂightiobjcompound(18.8)There are several important things to note when examining sequences such asthe one in Figure 18.6First, the sequence given is not the only one that might leadto a reasonable parseIn general, there may be more than one path that leads to thesame result, and due to ambiguity, there may be other transition sequences that leadto different equally valid parses. Second, we are assuming that the oracle always provides the correct operatorat each point in the parse—an assumption that is unlikely to be true in practice. As a result, given the greedy nature of this algorithm, incorrect choices will lead toincorrect parses since the parser has no opportunity to go back and pursue alternativechoicesSection 18.2.4 will introduce several techniques that allow transition-basedapproaches to explore the search space more fully.',\n",
    "  'chunk_num_chars': 1959,\n",
    "  'chunk_num_tokens': 489.75,\n",
    "  'chunk_num_words': 286,\n",
    "  'doc_name': 'Standford NLP'}\n",
    "\n",
    "\n",
    "\n",
    "length_chunk = len(sample['sentence_chunk'])\n",
    "print(length_chunk//2)\n",
    "# Split it into two\n",
    "\n",
    "midpoint = length_chunk // 2\n",
    "print(midpoint)\n",
    "# Find the last period before the midpoint\n",
    "split_point = sample['sentence_chunk'].rfind('. ', 0, midpoint)\n",
    "\n",
    "# Split the text into two parts\n",
    "first_half = sample['sentence_chunk'][:split_point+1]  # +1 to include the period\n",
    "second_half = sample['sentence_chunk'][split_point+2:]  # +2 to skip the period and space\n",
    "\n",
    "print(sample['sentence_chunk'])\n",
    "print(len(first_half)/4)\n",
    "print()\n",
    "print(second_half)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9534e519-4357-4938-9f88-f0235e1eb5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:50.098072Z",
     "iopub.status.busy": "2024-04-03T19:00:50.097316Z",
     "iopub.status.idle": "2024-04-03T19:00:50.106275Z",
     "shell.execute_reply": "2024-04-03T19:00:50.105524Z",
     "shell.execute_reply.started": "2024-04-03T19:00:50.098040Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Optimize later using recursion , if max_tokens_length still greater than 384.\n",
    "# For now just using 1/2 the length\n",
    "# Rectifying the max_length tokens\n",
    "def check_and_rectify_token_length(docs_df):\n",
    "    # 384 is the max_token_length for some smaller models\n",
    "    df_exceeding_length = docs_df[docs_df['chunk_num_tokens'] > 384]\n",
    "    # Split further\n",
    "    # Remove the df\n",
    "    docs_df = docs_df[docs_df['chunk_num_tokens'] <= 384]\n",
    "    # Convert them to dict\n",
    "    doc_token_length_exceeded = df_exceeding_length.to_dict(\"records\")\n",
    "    # Run the splitter further. Split the chunks into two\n",
    "    for doc in doc_token_length_exceeded:\n",
    "        # Get sentencfe length\n",
    "        doc_new_1 = {}\n",
    "        doc_new_2 = {}\n",
    "        length_chunk = len(doc['sentence_chunk'])\n",
    "        # Split it into two\n",
    "        # Assume `text` is your long text\n",
    "        # Find the midpoint\n",
    "        midpoint = length_chunk // 2\n",
    "\n",
    "        # Find the last period before the midpoint\n",
    "        split_point = doc['sentence_chunk'].rfind('. ', 0, midpoint)\n",
    "\n",
    "        # Split the text into two parts\n",
    "        first_half = doc['sentence_chunk'][:split_point+1]  # +1 to include the period\n",
    "        second_half = doc['sentence_chunk'][split_point+2:]  # +2 to skip the period and space\n",
    "\n",
    "        # Reclaculate all metadata except pg_num and doc_name            \n",
    "        doc_new_1['pg_num'] = doc['pg_num']\n",
    "        doc_new_2['pg_num'] = doc['pg_num']\n",
    "\n",
    "        doc_new_1['doc_name'] = doc['doc_name']\n",
    "        doc_new_2['doc_name'] = doc['doc_name']\n",
    "\n",
    "\n",
    "        #write metadata\n",
    "        doc_new_1['sentence_chunk'] = first_half\n",
    "        doc_new_1[\"chunk_num_chars\"] = len(first_half)\n",
    "        doc_new_1[\"chunk_num_tokens\"] = len(first_half) / 4\n",
    "        doc_new_1[\"chunk_num_words\"] = len([word for word in first_half.split(\" \")])\n",
    "\n",
    "        #write metadata\n",
    "        doc_new_2['sentence_chunk'] = second_half\n",
    "        doc_new_2[\"chunk_num_chars\"] = len(first_half)\n",
    "        doc_new_2[\"chunk_num_tokens\"] = len(first_half) / 4\n",
    "        doc_new_2[\"chunk_num_words\"] = len([word for word in first_half.split(\" \")])\n",
    "        \n",
    "\n",
    "        # Add it to the original dataframe\n",
    "\n",
    "        docs_df = pd.concat([docs_df, pd.DataFrame([doc_new_1]), pd.DataFrame([doc_new_2])], ignore_index=True) \n",
    "    return docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b861a578-c8e8-4513-864f-b187f295e7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:51.448245Z",
     "iopub.status.busy": "2024-04-03T19:00:51.447568Z",
     "iopub.status.idle": "2024-04-03T19:00:51.463101Z",
     "shell.execute_reply": "2024-04-03T19:00:51.462179Z",
     "shell.execute_reply.started": "2024-04-03T19:00:51.448215Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_backup = all_pdf_formatted_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fce5eea-49da-43b8-a1c4-eb045d3cca5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:52.358950Z",
     "iopub.status.busy": "2024-04-03T19:00:52.358361Z",
     "iopub.status.idle": "2024-04-03T19:00:52.382666Z",
     "shell.execute_reply": "2024-04-03T19:00:52.381798Z",
     "shell.execute_reply.started": "2024-04-03T19:00:52.358921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_pdf_formatted_backup).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f723275-1048-4dfe-917b-848f14e07f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:53.206413Z",
     "iopub.status.busy": "2024-04-03T19:00:53.205606Z",
     "iopub.status.idle": "2024-04-03T19:00:53.523121Z",
     "shell.execute_reply": "2024-04-03T19:00:53.522085Z",
     "shell.execute_reply.started": "2024-04-03T19:00:53.206378Z"
    }
   },
   "outputs": [],
   "source": [
    "#Running rectified\n",
    "\n",
    "all_pdf_formatted_df = check_and_rectify_token_length(all_pdf_formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21288ebb-439e-4fe0-96e6-8b7a6d9038c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:53.996388Z",
     "iopub.status.busy": "2024-04-03T19:00:53.996044Z",
     "iopub.status.idle": "2024-04-03T19:00:54.015405Z",
     "shell.execute_reply": "2024-04-03T19:00:54.014479Z",
     "shell.execute_reply.started": "2024-04-03T19:00:53.996363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "      <td>3583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>355.840078</td>\n",
       "      <td>503.923807</td>\n",
       "      <td>125.980952</td>\n",
       "      <td>70.375384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.237183</td>\n",
       "      <td>431.908522</td>\n",
       "      <td>107.977130</td>\n",
       "      <td>64.635809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>456.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>552.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>212.500000</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>1534.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3583.000000      3583.000000       3583.000000      3583.000000\n",
       "mean    355.840078       503.923807        125.980952        70.375384\n",
       "std     217.237183       431.908522        107.977130        64.635809\n",
       "min       1.000000         0.000000          0.000000         1.000000\n",
       "25%     136.000000       117.000000         29.250000        13.000000\n",
       "50%     456.000000       355.000000         88.750000        46.000000\n",
       "75%     552.000000       850.000000        212.500000       123.000000\n",
       "max     570.000000      1534.000000        383.500000       287.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the increase in chunk_num_tokens count \n",
    "# max_ is less than 384\n",
    "# min token 0\n",
    "# \n",
    "all_pdf_formatted_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "649284c6-537d-4dd9-a0d1-4b4b22edeac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:54.656197Z",
     "iopub.status.busy": "2024-04-03T19:00:54.655756Z",
     "iopub.status.idle": "2024-04-03T19:00:54.679612Z",
     "shell.execute_reply": "2024-04-03T19:00:54.678892Z",
     "shell.execute_reply.started": "2024-04-03T19:00:54.656160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_num</th>\n",
       "      <th>chunk_num_chars</th>\n",
       "      <th>chunk_num_tokens</th>\n",
       "      <th>chunk_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "      <td>3384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.370567</td>\n",
       "      <td>584.316785</td>\n",
       "      <td>146.079196</td>\n",
       "      <td>81.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.691400</td>\n",
       "      <td>567.975995</td>\n",
       "      <td>141.993999</td>\n",
       "      <td>79.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>553.000000</td>\n",
       "      <td>960.250000</td>\n",
       "      <td>240.062500</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>1869.750000</td>\n",
       "      <td>458.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pg_num  chunk_num_chars  chunk_num_tokens  chunk_num_words\n",
       "count  3384.000000      3384.000000       3384.000000      3384.000000\n",
       "mean    362.370567       584.316785        146.079196        81.090130\n",
       "std     217.691400       567.975995        141.993999        79.566382\n",
       "min       1.000000        40.000000         10.000000         2.000000\n",
       "25%     140.000000       120.000000         30.000000        13.000000\n",
       "50%     482.000000       378.000000         94.500000        48.500000\n",
       "75%     553.000000       960.250000        240.062500       139.000000\n",
       "max     570.000000      7479.000000       1869.750000       458.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_pdf_formatted_backup).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f509e93b-3a25-407c-a4aa-b07dbe3b3886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:55.495182Z",
     "iopub.status.busy": "2024-04-03T19:00:55.494356Z",
     "iopub.status.idle": "2024-04-03T19:00:55.509845Z",
     "shell.execute_reply": "2024-04-03T19:00:55.508744Z",
     "shell.execute_reply.started": "2024-04-03T19:00:55.495148Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pdf_formatted_dict = all_pdf_formatted_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1be24a2d-85a0-4caf-aa90-397e6fe19d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:00:56.738053Z",
     "iopub.status.busy": "2024-04-03T19:00:56.737215Z",
     "iopub.status.idle": "2024-04-03T19:00:56.744338Z",
     "shell.execute_reply": "2024-04-03T19:00:56.743362Z",
     "shell.execute_reply.started": "2024-04-03T19:00:56.738009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pg_num': 209,\n",
       "  'sentence_chunk': '',\n",
       "  'chunk_num_chars': 0,\n",
       "  'chunk_num_tokens': 0.0,\n",
       "  'chunk_num_words': 1,\n",
       "  'doc_name': 'Standford NLP'},\n",
       " {'pg_num': 414,\n",
       "  'sentence_chunk': 'Thus a maximum spanning tree of G emanating from theROOT is the optimal dependency parse for the sentence. A directed graph for the example Book that ﬂight is shown in Fig18.11, with themaximum spanning tree corresponding to the desired parse shown in blueFor easeof exposition, we’ll describe here the algorithm for unlabeled dependency parsing.rootBookthatﬂight1244568757Figure 18.11Initial rooted, directed graph for Book that ﬂight. Before describing the algorithm it’s useful to consider two intuitions about di-rected graphs and their spanning treesThe ﬁrst intuition begins with the fact thatevery vertex in a spanning tree has exactly one incoming edgeIt follows from thisthat every connected component of a spanning tree (i.e., every set of vertices thatare linked to each other by paths over edges) will also have one incoming edge. The second intuition is that the absolute values of the edge scores are not criticalto determining its maximum spanning tree',\n",
       "  'chunk_num_chars': 967,\n",
       "  'chunk_num_tokens': 241.75,\n",
       "  'chunk_num_words': 146,\n",
       "  'doc_name': 'Standford NLP'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_pdf_formatted_dict,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea76dc7-f4b1-4dac-a5fb-b75b7b11a974",
   "metadata": {},
   "source": [
    "## Embedding and the retriever\n",
    "- Generate the embeddings for query and generate embeddings for the documents\n",
    "- Store the document embeddings in the vector store : Use FAISS\n",
    "- Serialize the vector store for later use\n",
    "- Test it later using load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57be59c9-3de0-428b-af6c-f9a77338f2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:01:08.685978Z",
     "iopub.status.busy": "2024-04-03T19:01:08.684926Z",
     "iopub.status.idle": "2024-04-03T19:01:18.126120Z",
     "shell.execute_reply": "2024-04-03T19:01:18.125025Z",
     "shell.execute_reply.started": "2024-04-03T19:01:08.685947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the embeddings for query and generate embeddings for the documents\n",
    "# Store the document embeddings in the vector store : Use FAISS\n",
    "# Serialize the vector store for later use\n",
    "# Test it later using load\n",
    "# Create the Retriever function to return the scores and indices. Create the print function to print relevant score, docs\n",
    "# Import the llm for generation. Use bitsandBytes config. Create prompt template\n",
    "# Add the context to prompt along with query format.\n",
    "# apply the chat template \n",
    "# Generate the answer using LLM\n",
    "\n",
    "# Sample testing\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "query_sample = \"What does Darryl's friends do?\"\n",
    "answer_samples = [\"Darryl pursued his Masters in Computer Science\", \"Darryl's friends study Information systems\",\"Studying Generative AI is a boost to the mind\"]\n",
    "\n",
    "answer_embeddings = embed_model.encode(answer_samples)\n",
    "query_embedding = embed_model.encode(query_sample)\n",
    "\n",
    "scores = util.cos_sim(query_embedding, answer_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e50a8ab-4945-4ef9-990b-535bb4db0c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:01:30.262064Z",
     "iopub.status.busy": "2024-04-03T19:01:30.261531Z",
     "iopub.status.idle": "2024-04-03T19:01:30.267537Z",
     "shell.execute_reply": "2024-04-03T19:01:30.266612Z",
     "shell.execute_reply.started": "2024-04-03T19:01:30.262033Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_similarity(scores, query_embedding, answer_embeddings, query, answers):\n",
    "    print(answer_embeddings.shape)\n",
    "    score = util.cos_sim(query_embedding, answer_embeddings)\n",
    "    score,idx = score, score.argmax(-1)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"ANSWER: {answers[idx]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1d82036-9f62-493d-9b6c-4adcdc947d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:01:31.754988Z",
     "iopub.status.busy": "2024-04-03T19:01:31.753921Z",
     "iopub.status.idle": "2024-04-03T19:01:31.760308Z",
     "shell.execute_reply": "2024-04-03T19:01:31.759512Z",
     "shell.execute_reply.started": "2024-04-03T19:01:31.754953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 768)\n",
      "QUERY: What does Darryl's friends do?\n",
      "ANSWER: Darryl's friends study Information systems\n"
     ]
    }
   ],
   "source": [
    "sentence_similarity(scores, query_embedding, answer_embeddings, query_sample, answer_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef52138a-a230-46bd-89b8-3f765dd77fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:01:37.075505Z",
     "iopub.status.busy": "2024-04-03T19:01:37.074403Z",
     "iopub.status.idle": "2024-04-03T19:02:53.349707Z",
     "shell.execute_reply": "2024-04-03T19:02:53.348719Z",
     "shell.execute_reply.started": "2024-04-03T19:01:37.075459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82cba26fc3a42ec9a00b11406c027fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 2.07 s, total: 4min 12s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Encoding and Retriever\n",
    "\n",
    "# Change embed_model to 'cuda'\n",
    "embed_model.to('cuda')\n",
    "\n",
    "# Returns\n",
    "# By default, a 2d numpy array with shape [num_inputs, output_dimension] is returned.\n",
    "# If only one string input is provided, then the output is a 1d array with shape [output_dimension]. \n",
    "# If convert_to_tensor, a torch Tensor is returned instead.\n",
    "\n",
    "#Utility for encoding chunks of documents\n",
    "def encode_sentences(documents):\n",
    "    for doc in tqdm(documents):\n",
    "        doc[\"embeddings\"] = embed_model.encode(doc[\"sentence_chunk\"], convert_to_tensor=True)\n",
    "        \n",
    "encode_sentences(all_pdf_formatted_dict)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8964748e-df4e-40c2-a29d-643cdee76e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:17.111344Z",
     "iopub.status.busy": "2024-04-03T19:03:17.110964Z",
     "iopub.status.idle": "2024-04-03T19:03:17.115299Z",
     "shell.execute_reply": "2024-04-03T19:03:17.114502Z",
     "shell.execute_reply.started": "2024-04-03T19:03:17.111315Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74822bb4-fe86-4049-a8d1-1626465fc042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:19.130076Z",
     "iopub.status.busy": "2024-04-03T19:03:19.129280Z",
     "iopub.status.idle": "2024-04-03T19:03:46.928180Z",
     "shell.execute_reply": "2024-04-03T19:03:46.927279Z",
     "shell.execute_reply.started": "2024-04-03T19:03:19.130045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "3583\n",
      "CPU times: user 36.3 s, sys: 8.24 s, total: 44.6 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using batched mode\n",
    "# sentence_chunks = [doc['sentence_chunk'] for doc in all_pdf_formatted_dict]\n",
    "# print(len(sentence_chunks))\n",
    "# print(len(all_pdf_formatted_dict))\n",
    "# print(sentence_chunks[3341])\n",
    "embed_model.to('cuda')\n",
    "\n",
    "\n",
    "def encode_sentences_batched(documents):\n",
    "    sentence_chunks = [doc['sentence_chunk'] for doc in documents]\n",
    "    print(len(sentence_chunks))\n",
    "    print(len(all_pdf_formatted_dict))\n",
    "    batched_sentence_embeddings = embed_model.encode(sentence_chunks, batch_size=15, convert_to_tensor=True)\n",
    "    return batched_sentence_embeddings\n",
    "\n",
    "batched_sentence_embeddings = encode_sentences_batched(all_pdf_formatted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fca0d177-bd63-4dc0-a1c9-0f4a1c90c991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:46.930995Z",
     "iopub.status.busy": "2024-04-03T19:03:46.930331Z",
     "iopub.status.idle": "2024-04-03T19:03:46.935038Z",
     "shell.execute_reply": "2024-04-03T19:03:46.934215Z",
     "shell.execute_reply.started": "2024-04-03T19:03:46.930966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings using batch_size=15: torch.Size([3583, 768])\n",
      "Embeddings without batched  3583 torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings using batch_size=15:\",batched_sentence_embeddings.shape)\n",
    "print(\"Embeddings without batched \",len(all_pdf_formatted_dict) , all_pdf_formatted_dict[0]['embeddings'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a3bae95-0566-4fc8-bc2c-0040021bc72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:46.936156Z",
     "iopub.status.busy": "2024-04-03T19:03:46.935925Z",
     "iopub.status.idle": "2024-04-03T19:03:46.942588Z",
     "shell.execute_reply": "2024-04-03T19:03:46.941776Z",
     "shell.execute_reply.started": "2024-04-03T19:03:46.936135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(batched_sentence_embeddings[0].type())\n",
    "print(batched_sentence_embeddings[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c9f8038-527e-4e54-bf7f-bda00470acd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:46.944574Z",
     "iopub.status.busy": "2024-04-03T19:03:46.944322Z",
     "iopub.status.idle": "2024-04-03T19:03:46.950530Z",
     "shell.execute_reply": "2024-04-03T19:03:46.949608Z",
     "shell.execute_reply.started": "2024-04-03T19:03:46.944553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_pdf_formatted_dict[0]['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e328a347-9e49-4d5b-b767-a5632a2a3e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:53.943869Z",
     "iopub.status.busy": "2024-04-03T19:03:53.943514Z",
     "iopub.status.idle": "2024-04-03T19:03:57.742591Z",
     "shell.execute_reply": "2024-04-03T19:03:57.741365Z",
     "shell.execute_reply.started": "2024-04-03T19:03:53.943842Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu==1.8.0 in /usr/local/lib/python3.9/dist-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Storing embeddings in vectorStore\n",
    "# Experimental: Can use Pinecone, Milvus, AstraDB, MongoDB etc\n",
    "# Using FAISS as the vector store\n",
    "%pip install  faiss-cpu==1.8.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdb97bcc-38ed-4276-8f05-eb641508332b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:03:57.744778Z",
     "iopub.status.busy": "2024-04-03T19:03:57.744520Z",
     "iopub.status.idle": "2024-04-03T19:03:57.815765Z",
     "shell.execute_reply": "2024-04-03T19:03:57.814990Z",
     "shell.execute_reply.started": "2024-04-03T19:03:57.744752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed_model SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "Dimension : 768\n",
      "Embeddings shape : (3583, 768) and type <class 'numpy.ndarray'>\n",
      "Adding FAISS index\n",
      "Added total indexes: 3583\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dimension = embed_model[1].word_embedding_dimension\n",
    "print(f\"Embed_model\",embed_model)\n",
    "print(f\"Dimension : {dimension}\")\n",
    "\n",
    "# def get_dimension(embedding_model):\n",
    "    \n",
    "index = faiss.IndexFlatL2(dimension)   \n",
    "\n",
    "# build the index, d=size of vectors \n",
    "# assume xb contains a n-by-d numpy matrix of type float32\n",
    "# index.add(xb)                          \n",
    "# add vectors to the index\n",
    "\n",
    "# TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "\n",
    "# Sol: https://stackoverflow.com/questions/53467215/convert-pytorch-cuda-tensor-to-numpy-array\n",
    "\n",
    "\n",
    "def convert_to_np(embeddings):\n",
    "    batched_embeddings_np = embeddings.detach().cpu().numpy()\n",
    "    return batched_embeddings_np\n",
    "\n",
    "# type(batched_embeddings_np)\n",
    "\n",
    "batched_sentence_embeddings_np = convert_to_np(batched_sentence_embeddings)\n",
    "print(f\"Embeddings shape : {batched_sentence_embeddings_np.shape} and type {type(batched_sentence_embeddings_np)}\")\n",
    "print(\"Adding FAISS index\")\n",
    "index.add(batched_sentence_embeddings_np)\n",
    "print(f\"Added total indexes: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b74339c1-f60f-486f-bafc-b57706dbac94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:04:01.383903Z",
     "iopub.status.busy": "2024-04-03T19:04:01.382848Z",
     "iopub.status.idle": "2024-04-03T19:04:01.411810Z",
     "shell.execute_reply": "2024-04-03T19:04:01.410824Z",
     "shell.execute_reply.started": "2024-04-03T19:04:01.383868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Serialize the index\n",
    "faiss.write_index(index, \"index_embeddings.bin\")\n",
    "index2 = faiss.read_index(\"index_embeddings.bin\")  # index2 is identical to index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1426e34-97f8-4358-b804-ecf64e121511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:04:05.303215Z",
     "iopub.status.busy": "2024-04-03T19:04:05.302164Z",
     "iopub.status.idle": "2024-04-03T19:04:53.345098Z",
     "shell.execute_reply": "2024-04-03T19:04:53.344170Z",
     "shell.execute_reply.started": "2024-04-03T19:04:05.303177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Database mapping of sentence-chunks and embeddings\n",
    "# For now use a csv to store the embeddings and text chunk mapping\n",
    "# For scaling: Database required : use mongodb or sql \n",
    "data_csv = pd.DataFrame(all_pdf_formatted_dict).to_csv(\"data_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d475b6f8-71a0-47bb-8899-a02e5d3e536a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:04:58.418998Z",
     "iopub.status.busy": "2024-04-03T19:04:58.418646Z",
     "iopub.status.idle": "2024-04-03T19:04:58.456956Z",
     "shell.execute_reply": "2024-04-03T19:04:58.456038Z",
     "shell.execute_reply.started": "2024-04-03T19:04:58.418972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) <class 'numpy.ndarray'>\n",
      "QUERY:How was Gemini invented? \n",
      "\n",
      ": ANS:{'pg_num': 57, 'sentence_chunk': 'Gemini: A Family of Highly Capable Multimodal Models9.4.1Reasoning and code generationPromptCreate a web app called \"Opossum Search\":1Every time you make a search query, it should redirect you to a google search with the samequery, but the word opossum before it.2It should be visually similar to Google search,3Instead of the google logo, it should have a picture of an opossum from the internet.4', 'chunk_num_chars': 398, 'chunk_num_tokens': 99.5, 'chunk_num_words': 62, 'doc_name': 'Gemini_paper', 'embeddings': tensor([ 5.7879e-02,  7.4607e-02, -3.0555e-02, -3.1337e-02, -1.6591e-02,\n",
      "        -2.1249e-02,  2.0056e-02,  1.6419e-02, -4.9016e-02, -4.0856e-02,\n",
      "        -2.3328e-03, -6.0466e-03, -4.7642e-02,  1.1492e-01, -5.0542e-03,\n",
      "        -1.0370e-01,  3.7736e-02, -4.6329e-03, -5.8520e-02, -2.2963e-02,\n",
      "        -3.4077e-02, -1.3310e-02, -5.1538e-03,  1.1935e-02,  6.6984e-03,\n",
      "        -5.1249e-02, -5.7770e-02,  2.8465e-02, -1.6979e-02, -6.2326e-02,\n",
      "        -2.7486e-02,  1.4423e-02, -6.4039e-03,  8.0667e-02,  2.4149e-06,\n",
      "        -4.0273e-02, -2.6936e-02,  8.3505e-03, -1.6559e-02, -1.0013e-02,\n",
      "         1.4826e-01,  3.8348e-02,  2.2073e-02,  1.0254e-02, -3.5411e-02,\n",
      "         6.9449e-03,  4.3633e-02, -9.7888e-03,  6.2992e-03,  5.7367e-02,\n",
      "         1.2876e-02,  3.3614e-02, -4.0589e-03, -4.2266e-03,  3.2912e-02,\n",
      "         3.9884e-02, -1.4570e-02, -1.7669e-02,  4.9093e-02,  8.0338e-02,\n",
      "         1.5139e-02,  2.5078e-02,  3.8542e-03,  3.9392e-03, -1.2802e-02,\n",
      "         1.6084e-02, -4.8851e-02, -7.2896e-02, -3.0366e-02, -2.7939e-02,\n",
      "         1.6939e-02,  6.3287e-04,  1.1736e-04,  9.5776e-02, -1.7846e-02,\n",
      "        -1.0823e-02, -1.6921e-02,  4.1661e-02,  2.9159e-02, -3.8153e-02,\n",
      "        -2.6747e-02,  1.4201e-02,  2.0430e-03, -7.1593e-03, -4.3956e-02,\n",
      "         5.6663e-02,  4.8020e-02,  1.3223e-02, -1.9456e-02, -4.4568e-02,\n",
      "        -2.6988e-02, -1.6907e-02,  8.5663e-03,  2.8711e-02, -3.5708e-02,\n",
      "        -2.1853e-02, -6.2002e-02,  1.6671e-02,  3.2494e-02, -3.4364e-02,\n",
      "         2.0129e-02,  2.6303e-02, -3.0503e-02,  2.1592e-02,  1.4061e-02,\n",
      "        -1.9161e-02, -3.7898e-02, -1.0835e-02, -1.3768e-02,  1.0588e-02,\n",
      "        -2.2562e-02,  6.5108e-03, -5.8796e-04,  1.8297e-02, -2.1286e-02,\n",
      "        -6.0064e-02, -1.1277e-02,  4.2738e-02,  2.7211e-02, -4.8846e-03,\n",
      "        -1.8147e-02,  3.3245e-02,  2.5449e-02,  8.2869e-03, -2.1629e-02,\n",
      "        -1.5143e-02,  2.0149e-02, -2.1453e-02,  3.4844e-02, -8.6405e-02,\n",
      "         2.1250e-02,  1.4669e-02, -2.7725e-02, -9.9053e-03, -4.2114e-03,\n",
      "         1.1004e-01,  1.3521e-02, -6.7876e-02, -2.2630e-03, -1.6326e-02,\n",
      "         3.1717e-02,  9.0162e-03, -3.1699e-02, -1.0847e-02, -4.6885e-02,\n",
      "         3.8791e-03,  8.5432e-03,  3.4320e-02,  1.9357e-02,  6.4005e-03,\n",
      "         1.9299e-02,  5.0219e-02, -7.6548e-02,  1.3288e-02, -2.4175e-03,\n",
      "         2.1916e-02,  3.4811e-02,  1.0951e-02, -1.5430e-02,  4.8874e-02,\n",
      "         3.5812e-02, -1.0800e-02, -3.3599e-02,  2.0400e-02, -7.2748e-02,\n",
      "        -6.5841e-03,  4.5588e-02, -5.6296e-03,  1.8112e-02,  1.8059e-02,\n",
      "        -3.4782e-02,  1.8665e-02, -5.4594e-06,  4.4784e-03,  5.2569e-02,\n",
      "        -3.3296e-02, -9.2599e-03,  5.2738e-02,  7.7308e-03, -4.6146e-02,\n",
      "        -6.1701e-02, -6.0966e-02, -3.0782e-02,  6.7743e-02, -4.2992e-02,\n",
      "         1.4094e-03, -5.5932e-02,  6.2492e-02, -1.2861e-02, -1.4437e-04,\n",
      "        -1.1794e-02, -9.2849e-03, -7.0974e-02,  8.1408e-03,  3.5328e-02,\n",
      "        -3.0749e-02, -6.0215e-03, -1.3834e-02,  2.3845e-02, -3.0092e-02,\n",
      "        -2.3482e-02, -4.2849e-02, -7.8706e-03,  5.2011e-02,  4.2945e-02,\n",
      "        -1.5644e-02, -1.1550e-02, -3.8039e-03, -1.9669e-02,  7.8719e-02,\n",
      "         1.1201e-01,  1.2755e-02, -3.2313e-02, -7.3753e-03, -1.1752e-02,\n",
      "        -3.8253e-03,  3.3245e-02,  4.2772e-02, -5.4255e-02,  4.7203e-02,\n",
      "         9.3998e-03,  6.7093e-02,  2.2844e-02,  8.7563e-03,  2.5428e-03,\n",
      "        -6.8890e-03, -3.1230e-02,  1.3230e-02, -5.9839e-03, -1.9833e-02,\n",
      "         1.0258e-02,  2.7627e-02,  2.8979e-02,  1.0023e-02,  1.9800e-02,\n",
      "         1.6723e-02,  5.4037e-02,  7.5039e-02,  4.3057e-02, -1.1445e-01,\n",
      "         3.9259e-02,  7.4645e-02,  1.8381e-02, -2.8921e-02,  6.4052e-02,\n",
      "        -5.0139e-02,  7.6114e-02, -1.7853e-02,  4.9688e-02, -2.7882e-03,\n",
      "         4.8269e-04,  2.9412e-02,  5.7888e-03, -7.1352e-03,  4.0198e-02,\n",
      "         1.2531e-02, -3.9707e-03,  6.5467e-03, -5.3448e-02, -4.8516e-02,\n",
      "        -1.9622e-02, -2.5210e-02,  1.7452e-02, -1.9213e-02,  1.2712e-02,\n",
      "         2.2685e-02, -2.2369e-02, -1.0316e-01, -6.7769e-03,  1.1906e-02,\n",
      "         1.7405e-04,  5.0811e-02,  3.2881e-02,  6.7049e-03, -2.4261e-02,\n",
      "         4.1706e-02,  2.3489e-03, -1.2490e-02, -2.9624e-02,  1.3649e-02,\n",
      "        -2.7433e-02, -1.0355e-01, -4.6670e-02, -4.1413e-02, -4.2910e-03,\n",
      "         1.8434e-02,  4.2455e-02,  1.7143e-02, -1.6984e-02, -1.5131e-02,\n",
      "        -4.0973e-02,  2.3570e-02,  1.2162e-02, -3.5059e-03,  3.4402e-02,\n",
      "        -3.3396e-02, -2.5306e-02,  6.0489e-02,  3.4271e-02,  3.5096e-02,\n",
      "         3.4704e-02, -2.7886e-02,  3.4758e-04, -1.9936e-02, -3.2859e-02,\n",
      "        -3.8418e-02,  2.1990e-02, -8.1151e-02,  1.9291e-02,  5.5134e-02,\n",
      "        -5.3710e-02, -1.3501e-02,  3.2778e-02,  1.2448e-02, -1.0618e-02,\n",
      "        -2.5940e-02, -6.7858e-03,  4.5768e-02, -3.3599e-02,  2.1601e-02,\n",
      "         2.9880e-03, -3.9555e-02,  8.2263e-03, -2.0916e-02,  1.8462e-02,\n",
      "         4.6675e-02, -7.9533e-03,  3.9459e-03,  1.2857e-02, -2.9740e-02,\n",
      "         3.0483e-02,  6.0116e-02, -4.1721e-03,  8.3267e-03,  4.7152e-02,\n",
      "         4.0168e-02, -3.4048e-02, -2.4456e-02, -7.2521e-03, -4.2209e-02,\n",
      "         3.1238e-03, -3.9607e-02, -3.5658e-02, -2.1292e-02, -2.7531e-02,\n",
      "         3.8389e-02,  5.6767e-02, -3.2279e-02, -1.5036e-01,  5.7643e-03,\n",
      "        -2.6544e-02, -5.2647e-03, -1.2412e-02,  7.7975e-03, -9.6166e-03,\n",
      "        -5.4897e-02,  8.2704e-03,  3.7873e-02,  1.3223e-02,  1.8357e-02,\n",
      "        -1.9036e-02, -7.3737e-03, -4.1753e-03, -2.1696e-02, -5.5463e-02,\n",
      "         3.9329e-02,  4.5523e-02,  3.2230e-03, -6.6518e-02, -1.1812e-02,\n",
      "        -4.8118e-02,  1.7833e-02,  7.5254e-03,  3.6056e-02,  2.3930e-02,\n",
      "         1.8974e-02, -2.5191e-03, -5.1772e-02, -2.1260e-02,  4.9999e-02,\n",
      "        -6.3759e-03, -2.5175e-02, -1.4829e-03, -1.7279e-02, -1.2485e-02,\n",
      "        -1.0860e-03,  1.3068e-02,  1.2459e-02,  2.4814e-02, -2.0815e-02,\n",
      "        -6.1585e-03, -1.1006e-02,  5.7226e-02, -3.3145e-02, -1.1426e-02,\n",
      "        -3.2099e-02, -6.9487e-02,  4.5407e-02, -4.6491e-02,  1.1748e-02,\n",
      "         1.5746e-02,  9.1807e-02,  4.2637e-02,  1.0088e-02, -2.6689e-02,\n",
      "        -3.8975e-02,  6.9839e-02,  2.4223e-02, -1.9442e-02, -9.6658e-02,\n",
      "        -5.4039e-02,  7.2404e-03,  4.4058e-02,  1.8852e-02,  1.6626e-02,\n",
      "        -3.0348e-02, -2.3017e-03, -3.9122e-02, -4.6399e-03, -3.6175e-02,\n",
      "         3.5773e-02, -1.9919e-02, -2.2155e-02, -2.3941e-02,  3.1901e-02,\n",
      "        -5.0716e-02, -1.1437e-02, -2.3804e-02,  2.7567e-02, -2.4902e-02,\n",
      "         1.6476e-02, -6.0066e-02, -4.3340e-03,  5.3340e-02, -2.4311e-02,\n",
      "        -1.1807e-02,  2.4385e-02,  2.3526e-02, -2.2669e-02, -3.9924e-02,\n",
      "         1.9537e-02, -1.5130e-02,  4.3630e-02,  3.9361e-02, -7.5836e-02,\n",
      "        -2.5126e-02,  1.9880e-02, -3.1899e-02,  1.2979e-03,  3.0446e-02,\n",
      "         1.4965e-03, -6.0998e-02,  3.0795e-02, -1.2672e-02,  6.7545e-04,\n",
      "        -9.7564e-03,  7.4802e-02, -3.3844e-02, -6.2339e-04,  3.2623e-02,\n",
      "         5.3756e-02,  5.1184e-02, -1.0330e-01,  1.2554e-02, -6.8593e-03,\n",
      "        -4.2730e-02,  1.8363e-02,  5.3521e-02,  6.6087e-03, -1.3345e-02,\n",
      "        -3.2879e-02,  9.7797e-03, -3.0812e-02,  3.6465e-03,  4.6105e-03,\n",
      "        -5.7796e-03, -1.8928e-02, -2.0202e-02,  9.5476e-03,  2.8841e-02,\n",
      "         1.8990e-02,  5.5025e-02, -7.3409e-02, -1.4344e-02,  1.9589e-02,\n",
      "         1.1048e-02, -1.7538e-02,  2.1262e-03, -4.7578e-03,  1.6972e-02,\n",
      "         3.2983e-03,  2.7780e-02,  4.8679e-02,  7.8915e-02,  7.9445e-03,\n",
      "        -2.0370e-02, -3.1969e-03, -8.1371e-04,  2.8566e-02, -3.5006e-02,\n",
      "         3.8114e-04,  9.3437e-03, -1.6445e-02,  3.3380e-02, -3.8262e-02,\n",
      "         1.9445e-02, -1.5465e-02,  1.3842e-02, -2.4331e-03, -2.2266e-02,\n",
      "        -7.0741e-03,  2.5741e-02, -3.7221e-02, -2.5458e-02,  7.3021e-03,\n",
      "         8.1078e-02,  8.3304e-02,  1.9387e-02, -1.4905e-02, -3.8083e-02,\n",
      "        -5.8873e-04, -1.1541e-02, -1.0802e-02,  1.6138e-04, -4.1251e-02,\n",
      "        -1.9068e-02,  1.4547e-02, -3.7383e-03, -5.7595e-02,  5.0040e-02,\n",
      "        -3.8574e-02,  3.5811e-03,  1.9551e-03,  1.0796e-02, -2.7181e-02,\n",
      "         4.7609e-02,  4.4126e-02,  4.0480e-02, -1.9921e-03, -4.8034e-02,\n",
      "        -3.6186e-02, -3.3927e-02,  1.4736e-02,  3.8873e-02,  3.2251e-02,\n",
      "        -4.5125e-03,  3.9269e-02,  1.1171e-02, -5.4273e-04, -9.8819e-02,\n",
      "         1.7522e-02, -6.6797e-03, -5.8345e-02,  2.7659e-02, -1.0571e-02,\n",
      "        -7.1097e-33, -4.0412e-02,  9.4384e-03, -3.0011e-02, -2.5912e-02,\n",
      "        -3.5681e-02, -1.8184e-02,  2.8450e-03,  3.4262e-02, -2.7387e-02,\n",
      "        -4.7345e-02,  1.0427e-02, -2.0742e-02,  5.5684e-03, -5.5033e-03,\n",
      "         1.6942e-02,  9.0162e-02,  3.3841e-02,  9.5499e-04, -2.9513e-02,\n",
      "        -6.9649e-02,  7.0603e-02,  3.1183e-02, -1.8830e-02,  4.8603e-02,\n",
      "         5.7490e-04, -5.6603e-02, -5.0779e-02,  1.4966e-02, -2.6351e-02,\n",
      "         3.5862e-02, -3.0993e-02, -2.5968e-02, -2.7877e-02,  4.8705e-02,\n",
      "         1.7295e-02,  7.0698e-03,  1.5782e-03, -2.7558e-02,  2.4235e-02,\n",
      "        -1.0672e-02,  5.4041e-03, -1.4637e-03, -9.7860e-03, -3.4961e-02,\n",
      "        -1.5814e-02,  1.2061e-03,  2.3360e-02, -4.1146e-02, -3.7543e-02,\n",
      "         6.6050e-02, -3.4550e-02,  2.1049e-02,  1.4305e-02, -1.7967e-02,\n",
      "         3.6886e-02,  2.4276e-02,  1.8782e-03, -5.0724e-02,  4.8311e-02,\n",
      "         5.2242e-02, -6.4403e-03,  2.2967e-02,  4.1214e-02,  7.7280e-02,\n",
      "         3.6564e-02,  6.6034e-02, -5.7465e-03, -1.4890e-02,  1.0578e-02,\n",
      "         1.6633e-02,  2.1572e-02,  1.1412e-01,  5.1495e-02, -1.1835e-02,\n",
      "        -2.5847e-02, -3.9744e-02,  2.0098e-02,  1.7121e-02,  2.8813e-03,\n",
      "        -2.7229e-02,  1.8697e-03, -1.3621e-03, -3.2976e-02,  4.3729e-02,\n",
      "         5.0267e-02, -7.0380e-02, -3.9196e-02, -6.0830e-02,  1.7681e-02,\n",
      "         1.6978e-02,  4.7186e-04,  5.6092e-02, -1.9929e-02, -2.9892e-02,\n",
      "        -1.3716e-02, -7.3572e-02,  1.7742e-02,  2.1667e-02, -2.8204e-02,\n",
      "        -2.3194e-02,  6.9739e-02, -1.6651e-02,  1.4001e-02,  3.8357e-03,\n",
      "         7.7740e-03,  2.2020e-02, -1.1035e-02,  9.0918e-04, -5.9910e-02,\n",
      "        -3.8630e-04,  7.4494e-03, -2.4721e-02,  6.6580e-03, -8.1635e-02,\n",
      "         4.9512e-02, -3.3784e-02, -4.7994e-04, -4.2828e-03,  2.7077e-02,\n",
      "         4.0942e-02, -4.9534e-02, -2.1416e-02, -2.6076e-02,  4.6750e-02,\n",
      "        -1.1308e-02, -2.0551e-03, -7.1420e-02, -2.8313e-02, -2.4557e-02,\n",
      "        -6.3250e-02, -3.1751e-02,  1.9439e-02,  3.0631e-07,  1.4010e-02,\n",
      "         3.4514e-02,  3.0709e-03,  5.4976e-02, -5.9406e-03,  1.5678e-02,\n",
      "        -2.2767e-02,  2.4141e-02, -3.6457e-03, -3.5346e-02, -3.1284e-03,\n",
      "        -3.9174e-02,  1.4585e-02, -8.0561e-04, -7.9634e-03,  1.5543e-02,\n",
      "        -4.8075e-03, -8.0621e-02, -3.6271e-02, -1.2782e-03,  7.7938e-02,\n",
      "         3.4433e-02,  4.6614e-02,  2.3044e-03, -1.3435e-02, -6.8992e-02,\n",
      "         7.5128e-03, -2.4723e-02,  4.1598e-04,  1.1853e-03, -4.9568e-02,\n",
      "         4.4205e-03, -3.7591e-02, -6.7851e-03, -2.1279e-02, -4.7738e-02,\n",
      "         3.3146e-02,  3.9005e-02, -7.9151e-03,  4.4954e-02,  2.9992e-02,\n",
      "        -8.2830e-04, -3.8259e-03, -4.7292e-02,  2.5864e-02,  4.7947e-02,\n",
      "        -3.9466e-03, -4.8547e-03, -3.1814e-02, -5.5494e-03,  5.0746e-03,\n",
      "        -4.0210e-02, -4.9681e-03,  1.7492e-02,  1.6164e-03,  1.1294e-02,\n",
      "         1.5114e-02, -1.0438e-02,  3.8530e-02,  3.1459e-02, -5.8181e-02,\n",
      "        -5.6628e-02, -3.0879e-02,  1.5284e-03,  8.7645e-02,  1.0695e-02,\n",
      "        -4.6125e-02,  2.7202e-34,  2.0352e-02,  2.2040e-02, -9.7096e-03,\n",
      "         1.2044e-02, -2.9727e-03,  8.7777e-03,  8.5258e-02, -2.3191e-02,\n",
      "         2.2574e-02, -3.7408e-02, -4.2357e-02], device='cuda:0')} , DISTANCE: 1.1432483196258545\n"
     ]
    }
   ],
   "source": [
    "#Testing search\n",
    "query = \"How was Gemini invented?\"\n",
    "embed_model.to('cuda')\n",
    "\n",
    "query_test = embed_model.encode(query)\n",
    "print(query_test.shape, type(query_test))\n",
    "distance, ids = index2.search(np.expand_dims(query_test, axis=0), 5)\n",
    "\n",
    "# second argument specifies the number of closest documents you want to retrieve\n",
    "#Matrix distance is the matrix of squared distances. It has the same shape as I and indicates for each result vector at the query’s squared Euclidean distance.\n",
    "\n",
    "first_doc_id = ids[0][0]\n",
    "original_doc = all_pdf_formatted_dict[first_doc_id]\n",
    "\n",
    "print(f\"QUERY:{query} \\n\\n: ANS:{original_doc} , DISTANCE: {distance[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72f44896-bbe5-4a10-b387-c8f4eec60c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:05:02.538131Z",
     "iopub.status.busy": "2024-04-03T19:05:02.537774Z",
     "iopub.status.idle": "2024-04-03T19:05:02.543058Z",
     "shell.execute_reply": "2024-04-03T19:05:02.542154Z",
     "shell.execute_reply.started": "2024-04-03T19:05:02.538102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making the output pretty\n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text , wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c2501dd8-5fca-4822-a7d6-4fe809803bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T21:04:24.461645Z",
     "iopub.status.busy": "2024-04-03T21:04:24.461193Z",
     "iopub.status.idle": "2024-04-03T21:04:24.470218Z",
     "shell.execute_reply": "2024-04-03T21:04:24.469269Z",
     "shell.execute_reply.started": "2024-04-03T21:04:24.461609Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import perf_counter as timer\n",
    "# Function for retriver\n",
    "def retrieve_docs(query, doc_embeddings, all_docs_array, model, faiss_index,n_return_docs=5, print_time=True, print_docs=True):\n",
    "    \"\"\" Embed the query , and return the top docs distance, indices\"\"\"\n",
    "    model = model.to('cuda')\n",
    "    # Query embedding\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    # Reshaping since faiss expects nxd ndarry format\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "    \n",
    "    # start time\n",
    "    time_strt = timer()\n",
    "    distances, retrieved_ids = faiss_index.search(query_embedding, n_return_docs)\n",
    "    time_end = timer()\n",
    "    \n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get search on {len(doc_embeddings)} embeddings: {time_end-time_strt:.5f} seconds\")\n",
    "    \n",
    "    if print_docs:\n",
    "        print(f\"QUERY: {query} \\n\")\n",
    "        print(\"Retrieved Docs: \\n\")\n",
    "        for doc_num,doc_id in enumerate(retrieved_ids[0]):\n",
    "            print(f\"DOC {doc_num}\")\n",
    "            print(f\"\\n {all_pdf_formatted_dict[doc_id]['sentence_chunk']}\")\n",
    "            print(\"\\n\")\n",
    "    return retrieved_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c26805f2-4dba-43c9-a85d-7625320d520f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T21:04:33.436521Z",
     "iopub.status.busy": "2024-04-03T21:04:33.435681Z",
     "iopub.status.idle": "2024-04-03T21:04:33.476674Z",
     "shell.execute_reply": "2024-04-03T21:04:33.475958Z",
     "shell.execute_reply.started": "2024-04-03T21:04:33.436489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get search on 3583 embeddings: 0.00163 seconds\n",
      "QUERY: Explain recurrent nueral networks \n",
      "\n",
      "Retrieved Docs: \n",
      "\n",
      "DOC 0\n",
      "\n",
      " 188CHAPTER 9•RNNS AND LSTMSworksThese networks are useful in their own right and serve as the basis for morecomplex approaches like the Long Short-Term Memory (LSTM) networks discussedlater in this chapterIn this chapter when we use the term RNN we’ll be referring tothese simpler more constrained networks (although you will often see the term RNNto mean any net with recurrent properties including LSTMs).xthtytFigure 9.1Simple recurrent neural network after Elman (1990)The hidden layer includesa recurrent connection as part of its inputThat is, the activation value of the hidden layerdepends on the current input as well as the activation value of the hidden layer from theprevious time step. Fig\n",
      "\n",
      "\n",
      "DOC 1\n",
      "\n",
      " 202CHAPTER 9•RNNS AND LSTMS+xtht-1cthtcthtct-1ht-1xttanh+σtanhσσ+++igfo⦿⦿⦿LSTMct-1Figure 9.13A single LSTM unit displayed as a computation graphThe inputs to each unit consists of thecurrent input, x, the previous hidden state, ht−1, and the previous context, ct−1The outputs are a new hiddenstate, ht and an updated context, ct.hxxtxtht-1hthtct-1ctht-1(b)(a)(c)⌃gza⌃gzLSTMUnitaFigure 9.14Basic neural units used in feedforward, simple recurrent networks (SRN), andlong short-term memory (LSTM). At the far left, (a) is the basic feedforward unit where a single set of weights anda single activation function determine its output, and when arranged in a layer thereare no connections among the units in the layerNext, (b) represents the unit in asimple recurrent networkNow there are two inputs and an additional set of weightsto go with it\n",
      "\n",
      "\n",
      "DOC 2\n",
      "\n",
      " Kuhn, and RJ. Williams1994Dynamic recurrentneural networks: Theory and appli-cationsIEEE Trans\n",
      "\n",
      "\n",
      "DOC 3\n",
      "\n",
      " The recurrent network offers a new way to representthe prior context, in its recurrent connections, allowing the model’s decision todepend on information from hundreds of words in the pastWe’ll see how to applythe model to the task of language modeling, to sequence modeling tasks like part-of-speech tagging, and to text classiﬁcation tasks like sentiment analysis.9.1Recurrent Neural NetworksA recurrent neural network (RNN) is any network that contains a cycle within itsnetwork connections, meaning that the value of some unit is directly, or indirectly,dependent on its own earlier outputs as an inputWhile powerful, such networksare difﬁcult to reason about and to trainHowever, within the general class of recur-rent networks there are constrained architectures that have proven to be extremelyeffective when applied to languageIn this section, we consider a class of recurrentnetworks referred to as Elman Networks (Elman, 1990) or simple recurrent net-ElmanNetworks\n",
      "\n",
      "\n",
      "DOC 4\n",
      "\n",
      " In a departure from our earlier window-based approach, se-quences are processed by presenting one item at a time to the networkWe’ll usesubscripts to represent time, thus xt will mean the input vector x at time tThe keydifference from a feedforward network lies in the recurrent link shown in the ﬁgurewith the dashed lineThis link augments the input to the computation at the hiddenlayer with the value of the hidden layer from the preceding point in time. The hidden layer from the previous time step provides a form of memory, orcontext, that encodes earlier processing and informs the decisions to be made atlater points in timeCritically, this approach does not impose a ﬁxed-length limiton this prior context; the context embodied in the previous hidden layer can includeinformation extending back to the beginning of the sequence. Adding this temporal dimension makes RNNs appear to be more complex thannon-recurrent architectures\n",
      "\n",
      "\n",
      "DOC 5\n",
      "\n",
      " The sequential nature of simplerecurrent networks can also be seen by unrolling the network in time as is shown inFig9.4In this ﬁgure, the various layers of units are copied for each time step toillustrate that they will have differing values over timeHowever, the various weightmatrices are shared across time.function FORWARDRNN(x,network) returns output sequence yh0 ←0for i←1 to LENGTH(x) dohi ←g(Uhi−1 + Wxi)yi ← f(Vhi)return yFigure 9.3Forward inference in a simple recurrent networkThe matrices U, V and W areshared across time, while new values for h and y are calculated with each time step.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 572,  601, 1824,  571,  574,  578])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_docs(\"Explain recurrent nueral networks\", batched_sentence_embeddings_np,all_pdf_formatted_dict, embed_model, \\\n",
    "              index2, n_return_docs=6, print_time=True, print_docs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbdb34-42ad-4121-b160-a5bd252421d4",
   "metadata": {},
   "source": [
    "# Generator \n",
    "1. Figure out the compute requirements. Quantize model according to your GPU RAM. \n",
    "2. Calculate parameters of your llm and see if there is enough RAM to load the model.\n",
    "3. Instruction tuned version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03ea0717-e3f1-4736-91ba-29057b7a787a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:05:14.415227Z",
     "iopub.status.busy": "2024-04-03T19:05:14.414360Z",
     "iopub.status.idle": "2024-04-03T19:05:14.420465Z",
     "shell.execute_reply": "2024-04-03T19:05:14.419547Z",
     "shell.execute_reply.started": "2024-04-03T19:05:14.415222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6097c664-e5de-4b23-8d16-cd6b3d4833ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:05:20.328263Z",
     "iopub.status.busy": "2024-04-03T19:05:20.327463Z",
     "iopub.status.idle": "2024-04-03T19:05:20.334172Z",
     "shell.execute_reply": "2024-04-03T19:05:20.333032Z",
     "shell.execute_reply.started": "2024-04-03T19:05:20.328231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 8 | Recommended model: Mistral 7B in 4-bit precision.\n",
      "use_quantization_config set to: True\n",
      "model_id set to: google/gemma-2b-it\n"
     ]
    }
   ],
   "source": [
    "# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Mistral AI LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Mistral 7B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Mistral 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Mistral 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a146e676-e304-44e8-8fb0-b94d9b6f1f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:05:32.621789Z",
     "iopub.status.busy": "2024-04-03T19:05:32.620998Z",
     "iopub.status.idle": "2024-04-03T19:05:32.625327Z",
     "shell.execute_reply": "2024-04-03T19:05:32.624480Z",
     "shell.execute_reply.started": "2024-04-03T19:05:32.621758Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install torch==2.1.1\n",
    "# %pip install --upgrade torchvision\n",
    "# %pip install --upgrade torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "807e7d86-66d5-4d00-ba8f-3032ed5bbff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:05:34.505951Z",
     "iopub.status.busy": "2024-04-03T19:05:34.505606Z",
     "iopub.status.idle": "2024-04-03T19:05:34.517136Z",
     "shell.execute_reply": "2024-04-03T19:05:34.516007Z",
     "shell.execute_reply.started": "2024-04-03T19:05:34.505923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "# Using mistral-ai\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if PyTorch is installed\n",
    "try:\n",
    "    torch_version = torch.__version__\n",
    "    print(f\"PyTorch version: {torch_version}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83e78dd9-6daa-486c-8349-40ee477a6a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:31:12.736557Z",
     "iopub.status.busy": "2024-04-03T19:31:12.736200Z",
     "iopub.status.idle": "2024-04-03T19:31:34.259271Z",
     "shell.execute_reply": "2024-04-03T19:31:34.258041Z",
     "shell.execute_reply.started": "2024-04-03T19:31:12.736529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c290850f154a8cadfb1a39121128e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0015bcb4de24497ba3e52b23eb50a8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f565f3c880c484ab797f06922603e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38731cdf66924e2f9fb918a785e5ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71734d503ff04dbaaa45bcf7488544bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Model tokenizer\u001b[39;00m\n\u001b[1;32m     21\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mllm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/big_modeling.py:454\u001b[0m, in \u001b[0;36mdispatch_model.<locals>.add_warning.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt move a model that has some modules offloaded to cpu or disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py:2534\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule\u001b[38;5;241m.\u001b[39mto)\n\u001b[1;32m   2531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2532\u001b[0m     \u001b[38;5;66;03m# Checks if the model has been loaded in 8-bit\u001b[39;00m\n\u001b[1;32m   2533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES:\n\u001b[0;32m-> 2534\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2535\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2536\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2537\u001b[0m         )\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mGPTQ:\n\u001b[1;32m   2539\u001b[0m         \u001b[38;5;66;03m# For GPTQ models, we prevent users from casting the model to another dytpe to restrict unwanted behaviours.\u001b[39;00m\n\u001b[1;32m   2540\u001b[0m         \u001b[38;5;66;03m# the correct API should be to load the model with the desired dtype directly through `from_pretrained`.\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m         dtype_present_in_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: `.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`."
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/v4.39.3/src/transformers/utils/quantization_config.py#L182\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16, bnb_4bit_quant_type=\"nf4\")\n",
    "\n",
    "# Check  scaled dot product attn + flash_attn\n",
    "\n",
    "\n",
    "# Model instantiated with quantization config\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", \\\n",
    "                                                   quantization_config=quant_config,\n",
    "                                                 low_cpu_mem_usage=True)\n",
    "\n",
    "# Model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", load_in_4bit=True, )\n",
    "\n",
    "\n",
    "# llm_model.to('cuda') -> Not available for quantized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d351057-6e72-400a-be11-ccaeaa8615ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:32:27.615629Z",
     "iopub.status.busy": "2024-04-03T19:32:27.615289Z",
     "iopub.status.idle": "2024-04-03T19:32:27.623532Z",
     "shell.execute_reply": "2024-04-03T19:32:27.622697Z",
     "shell.execute_reply.started": "2024-04-03T19:32:27.615603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "# ]\n",
    "\n",
    "# encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "# model_inputs = encodeds.to(device)\n",
    "# model.to(device)\n",
    "\n",
    "# generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "# decoded = tokenizer.batch_decode(generated_ids)\n",
    "# print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de00d64c-afd5-4c8a-8e27-f456e6800400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:32:44.691236Z",
     "iopub.status.busy": "2024-04-03T19:32:44.690502Z",
     "iopub.status.idle": "2024-04-03T19:32:46.036374Z",
     "shell.execute_reply": "2024-04-03T19:32:46.035291Z",
     "shell.execute_reply.started": "2024-04-03T19:32:44.691198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  3 19:32:45 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 4000     Off  | 00000000:00:05.0 Off |                  N/A |\n",
      "| 30%   32C    P8     5W / 125W |   6361MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1ccefab-299b-4bb2-9a22-c68ffa435f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:36:04.096244Z",
     "iopub.status.busy": "2024-04-03T19:36:04.095359Z",
     "iopub.status.idle": "2024-04-03T19:36:04.104716Z",
     "shell.execute_reply": "2024-04-03T19:36:04.103734Z",
     "shell.execute_reply.started": "2024-04-03T19:36:04.096210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3752071168"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_params(model):\n",
    "    return sum([torch.numel(param) for param in model.parameters()])\n",
    "\n",
    "get_model_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab2b6ed9-aac2-4058-b8f7-05cbed350cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:40:30.892443Z",
     "iopub.status.busy": "2024-04-03T19:40:30.891768Z",
     "iopub.status.idle": "2024-04-03T19:40:30.907209Z",
     "shell.execute_reply": "2024-04-03T19:40:30.906522Z",
     "shell.execute_reply.started": "2024-04-03T19:40:30.892370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 4551360512, 'model_mem_mb': 4340.52, 'model_mem_gb': 4.24}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model memory size on our machine\n",
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)\n",
    "# Minimum required is 4GB, but due to gradients etc, would require about 7 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5a6a0f0-470d-4b44-a549-459c2eb0e31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:48:48.557937Z",
     "iopub.status.busy": "2024-04-03T19:48:48.557475Z",
     "iopub.status.idle": "2024-04-03T19:48:48.564954Z",
     "shell.execute_reply": "2024-04-03T19:48:48.563752Z",
     "shell.execute_reply.started": "2024-04-03T19:48:48.557897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5745254400\n",
      "_CudaDeviceProperties(name='Quadro RTX 4000', major=7, minor=5, total_memory=7974MB, multi_processor_count=36)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.memory_allocated(device=0))\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59e1bffd-b9ba-49be-a7f3-a8c9315df5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:45:45.742039Z",
     "iopub.status.busy": "2024-04-03T19:45:45.741582Z",
     "iopub.status.idle": "2024-04-03T19:45:45.749004Z",
     "shell.execute_reply": "2024-04-03T19:45:45.747928Z",
     "shell.execute_reply.started": "2024-04-03T19:45:45.742000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "768cfd9f-419c-4e03-8774-babf845f35ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T19:45:51.789188Z",
     "iopub.status.busy": "2024-04-03T19:45:51.788434Z",
     "iopub.status.idle": "2024-04-03T19:45:51.794792Z",
     "shell.execute_reply": "2024-04-03T19:45:51.793904Z",
     "shell.execute_reply.started": "2024-04-03T19:45:51.789151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89a5d3bd-3053-470d-87bc-05ea9a69f20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T20:13:16.630273Z",
     "iopub.status.busy": "2024-04-03T20:13:16.629239Z",
     "iopub.status.idle": "2024-04-03T20:13:16.636153Z",
     "shell.execute_reply": "2024-04-03T20:13:16.635376Z",
     "shell.execute_reply.started": "2024-04-03T20:13:16.630235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [QUERY] : What are the differences between BERT and BART models?\n",
      "Formatter Template : <s>[INST] What are the differences between BERT and BART models? [/INST]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What are the differences between BERT and BART models?\"\n",
    "\n",
    "print(f\" [QUERY] : {query}\")\n",
    "# Chat template\n",
    "chat_tempalte = [\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": query\n",
    "    }]\n",
    "\n",
    "# Instruction format\n",
    "# In order to leverage instruction fine-tuning, your prompt should be surrounded by [INST] and [/INST] tokens. The very first instruction should begin with a begin of sentence id. The next instructions should not. The assistant generation will be ended by the end-of-sentence token id.\n",
    "\n",
    "# E.g.\n",
    "\n",
    "# text = \"<s>[INST] What is your favourite condiment? [/INST]\"\n",
    "# \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> \"\n",
    "# \"[INST] Do you have mayonnaise recipes? [/INST]\"\n",
    "# \n",
    "\n",
    "# apply_chat_template(\n",
    "#         self,\n",
    "#         conversation: Union[List[Dict[str, str]], List[List[Dict[str, str]]], \"Conversation\"],\n",
    "#         chat_template: Optional[str] = None,\n",
    "#         add_generation_prompt: bool = False,\n",
    "#         tokenize: bool = True,\n",
    "#         padding: bool = False,\n",
    "#         truncation: bool = False,\n",
    "#         max_length: Optional[int] = None,\n",
    "#         return_tensors: Optional[Union[str, TensorType]] = None,\n",
    "#         return_dict: bool = False,\n",
    "#         tokenizer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "#         **kwargs,\n",
    "#     ) -> Union[str, List[int], List[str], List[List[int]], BatchEncoding]:\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(conversation=chat_tempalte, tokenize=False, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "\n",
    "print(f\"Formatter Template : {prompt}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33e30a1a-9029-415c-9e92-d60d42fcdc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T20:13:20.013722Z",
     "iopub.status.busy": "2024-04-03T20:13:20.012851Z",
     "iopub.status.idle": "2024-04-03T20:13:20.018732Z",
     "shell.execute_reply": "2024-04-03T20:13:20.017986Z",
     "shell.execute_reply.started": "2024-04-03T20:13:20.013689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.2', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f8bb96e7-86fb-4b17-b51e-e43f0dfb9f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T20:13:23.037991Z",
     "iopub.status.busy": "2024-04-03T20:13:23.037129Z",
     "iopub.status.idle": "2024-04-03T20:13:36.199026Z",
     "shell.execute_reply": "2024-04-03T20:13:36.198161Z",
     "shell.execute_reply.started": "2024-04-03T20:13:23.037948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "input_ids\n",
    "\n",
    "# Generate output from llm\n",
    "output_tokens = llm_model.generate(**input_ids, max_new_tokens=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8bea344d-ed3a-4a50-b578-4e3f1e7dd5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T20:14:56.666964Z",
     "iopub.status.busy": "2024-04-03T20:14:56.666621Z",
     "iopub.status.idle": "2024-04-03T20:14:56.693282Z",
     "shell.execute_reply": "2024-04-03T20:14:56.692619Z",
     "shell.execute_reply.started": "2024-04-03T20:14:56.666938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output [tokens]: tensor([    1,     1,   733, 16289, 28793,  1824,   460,   272, 11090,  1444,\n",
      "          365,  4538,   304,   365,  4520,  4994, 28804,   733, 28748, 16289,\n",
      "        28793,   365,  4538,   325, 28760,   313,  7819,   282, 17611,  5722,\n",
      "        17891,   697,   477,  4335,   674,   404, 28731,   304,   365,  4520,\n",
      "          325, 19064,  3521, 16107, 28742, 28713,  4745, 28709,  2979, 12191,\n",
      "        20787,   354,  7379, 28733,   532, 28733,  1874,  8871,   288, 28731,\n",
      "          460,  1560,  1665, 28733,  1009, 28733,  1237, 28733,   444,  4994,\n",
      "          297,   272,  1834,   302, 16725, 15589, 10705,   288,   325, 28759,\n",
      "        11661,   557,   562,   590,  7031,  1581, 10700,   304,   506,  9494,\n",
      "         7821,  1890, 11090, 28723,    13,    13, 28760,  4538,   349,   264,\n",
      "          710, 28733, 28247,  5516,   263,  2229,   369,   541,   347,  4433,\n",
      "        28733, 28707,   370,   286,   354,  4118,   418, 11661,  9796,  1259,\n",
      "          390, 16776, 28725,  5160,  9040, 13828, 28725,  2996, 24402, 28725,\n",
      "          304,  2245,  8342, 28725,  3352,  2663, 28723,   661,   349,   264,\n",
      "        16129,  7819,   282,  2229, 28725,  5746,   378, 28325,   272,  2758,\n",
      "          477,  1560,  1749,   304,  1103,  2758, 28713,   739,  2492, 20596,\n",
      "        28723,   365,  4538,  6098,   264,  5934,   286,  3842, 27472, 13640,\n",
      "         1938,   710, 28733, 25714, 28725,   970,   378,  6782, 28713,  6925,\n",
      "         3085,   297,   264, 12271,  2818,   356,   272,  2758,   302,   272,\n",
      "        12028,  3085, 28723,    13,    13, 28760,  4520, 28725,   356,   272,\n",
      "          799,  1021, 28725,   349,   264,  1457, 28709,  2979,  4027, 20787,\n",
      "          369,   541,   347,  4433, 28733, 28707,   370,   286,   354,  2245,\n",
      "         8342,  9796, 28723,   661,   349,   396,  1206,   431,  2736,   495,\n",
      "         2229, 28725,  5746,   378, 26396,  2245,   624,  6029,   438,   264,\n",
      "          727,  2818,   356,   272,  8361,  7138, 16246, 28723,   365,  4520,\n",
      "         6098,   264,  1457, 28709,  2979, 13640,  1938,   710, 28733, 25714,\n",
      "        28725,   970,   378,  2822, 28713,   298,  9443,   272,  3493,  2245,\n",
      "          477,   264,  1275, 17488,  2751, 28723,   851], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<s><s> [INST] What are the differences between BERT and BART models? [/INST] BERT (Bidirectional Encoder Representations from Transformers) and BART (Facebook AI's Denoising Autoencoder for Text-to-Text Modeling) are both state-of-the-art models in the field of Natural Language Processing (NLP), but they serve different purposes and have distinct architectural differences.\\n\\nBERT is a pre-trained transformer model that can be fine-tuned for various NLP tasks such as classification, named entity recognition, question answering, and text generation, among others. It is a bidirectional model, meaning it considers the context from both left and right contexts when making predictions. BERT uses a masked language modeling objective during pre-training, where it predicts missing words in a sentence based on the context of the surrounding words.\\n\\nBART, on the other hand, is a denoising autoencoder that can be fine-tuned for text generation tasks. It is an autoregressive model, meaning it generates text one token at a time based on the previously generated tokens. BART uses a denoising objective during pre-training, where it learns to recover the original text from a corrupted version. This\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding output tokens\n",
    "print(f\"Output [tokens]: {output_tokens[0]}\\n\")\n",
    "\n",
    "tokenizer.decode(output_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fa38c02a-8d92-4d64-8285-02a91ce90842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T22:12:18.473455Z",
     "iopub.status.busy": "2024-04-03T22:12:18.472052Z",
     "iopub.status.idle": "2024-04-03T22:12:18.517094Z",
     "shell.execute_reply": "2024-04-03T22:12:18.515925Z",
     "shell.execute_reply.started": "2024-04-03T22:12:18.473415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What is the significance of attention mechanisms in neural networks, as discussed in the Attention paper?\n",
      "[INFO] Time taken to get search on 3583 embeddings: 0.00190 seconds\n",
      "QUERY: What is the significance of attention mechanisms in neural networks, as discussed in the Attention paper? \n",
      "\n",
      "Retrieved Docs: \n",
      "\n",
      "DOC 0\n",
      "\n",
      " The attention mechanism is a solution to the bottleneck problem, a way ofattentionmechanismallowing the decoder to get information from all the hidden states of the encoder,not just the last hidden state. In the attention mechanism, as in the vanilla encoder-decoder model, the contextvector c is a single vector that is a function of the hidden states of the encoder, thatis, c = f(he1 ...hen)Because the number of hidden states varies with the size ofthe input, we can’t use the entire set of encoder hidden state vectors directly as thecontext for the decoder. The idea of attention is instead to create the single ﬁxed-length vector c by takinga weighted sum of all the encoder hidden statesThe weights focus on (‘attendto’) a particular part of the source text that is relevant for the token the decoder iscurrently producing\n",
      "\n",
      "\n",
      "DOC 1\n",
      "\n",
      " 10.1•THE TRANSFORMER: A SELF-ATTENTION NETWORK217Self-AttentionLayerx1a1x2a2a3a4a5x3x4x5Figure 10.2Information ﬂow in a causal (or masked) self-attention modelIn processingeach element of the sequence, the model attends to all the inputs up to, and including, thecurrent oneUnlike RNNs, the computations at each time step are independent of all theother steps and therefore can be performed in parallel.10.1.3Self-attention more formallyWe’ve given the intuition of self-attention (as a way to compute representations of aword at a given layer by integrating information from words at the previous layer)and we’ve deﬁned context as all the prior words in the inputLet’s now introducethe self-attention computation itself. The core intuition of attention is the idea of comparing an item of interest to acollection of other items in a way that reveals their relevance in the current context. In the case of self-attention for language, the set of comparisons are to other words(or tokens) within a given sequenceThe result of these comparisons is then used tocompute an output sequence for the current input sequence\n",
      "\n",
      "\n",
      "DOC 2\n",
      "\n",
      " 10.4 and Eq10.9 with Eq10.12. Here’s a ﬁnal set of equations for computing self-attention for a single self-attentionoutput vector ai from a single input vector xi, illustrated in Fig10.3 for the case ofcalculating the value of the third output a3 in a sequence.qi = xiWQ;ki = xiWK;vi = xiWV(10.11)Final verson:score(xi,xj) = qi ·k j√dk(10.12)αij = softmax(score(xi,xj)) ∀j ≤ i(10.13)ai =Xj≤iαijvj(10.14)10.1.4Parallelizing self-attention using a single matrix XThis description of the self-attention process has been from the perspective of com-puting a single output at a single time step iHowever, since each output, yi, iscomputed independently, this entire process can be parallelized, taking advantage of\n",
      "\n",
      "\n",
      "DOC 3\n",
      "\n",
      " This makesit more difficult to learn dependencies between distant positions [12]In the Transformer this isreduced to a constant number of operations, albeit at the cost of reduced effective resolution dueto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention asdescribed in section 3.2. Self-attention, sometimes called intra-attention is an attention mechanism relating different positionsof a single sequence in order to compute a representation of the sequenceSelf-attention has beenused successfully in a variety of tasks including reading comprehension, abstractive summarization,textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      "\n",
      "\n",
      "DOC 4\n",
      "\n",
      " 10.1•THE TRANSFORMER: A SELF-ATTENTION NETWORK215transformers are a neural architecture that can handle distant informationBut unlikeLSTMs, transformers are not based on recurrent connections (which can be hard toparallelize), which means that transformers can be more efﬁcient to implement atscale. Transformers are made up of stacks of transformer blocks, each of which is amultilayer network that maps sequences of input vectors (x1,...,xn) to sequences ofoutput vectors (z1,...,zn) of the same lengthThese blocks are made by combin-ing simple linear layers, feedforward networks, and self-attention layers, the keyself-attentioninnovation of transformersSelf-attention allows a network to directly extract anduse information from arbitrarily large contextsWe’ll start by describing how self-attention works and then return to how it ﬁts into larger transformer blocks\n",
      "\n",
      "\n",
      "DOC 5\n",
      "\n",
      " arXiv preprint arXiv:1610.10099v2,2017.[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander MRushStructured attention networks. In International Conference on Learning Representations, 2017.[20] Diederik Kingma and Jimmy BaAdam: A method for stochastic optimizationIn ICLR, 2015.[21] Oleksii Kuchaiev and Boris Ginsburg\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3296,  628,  636, 3511,  621, 2891])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_questions=['What is Faiss? Summarize the working of Faiss.',\n",
    "'What are the different types of quantizers used in Faiss?',\n",
    "'What are Additive quantizers?',\n",
    "'What are Multi-codebook quantizers?',\n",
    "'Can you describe the pretraining process of BART and its architecture?',\n",
    "'Could you provide examples of where BART has been particularly effective?',\n",
    "'Are there any known challenges or limitations when using BART for certain tasks?',\n",
    "'What are the main principles behind the GEMINI framework?',\n",
    "'How does GEMINI address the challenges of interpretability in machine learning models?',\n",
    "'Can you explain the process of model extraction and perturbation used in GEMINI?',\n",
    "'What are some potential applications of GEMINI in real-world scenarios?',\n",
    "'What is the model architecture of Gemini?',\n",
    "'What is the significance of attention mechanisms in neural networks, as discussed in the Attention paper?',\n",
    "'How does the Attention paper propose to improve attention mechanisms in deep learning models?',\n",
    "'How do the proposed improvements of multi-head attention compare with existing single head attention mechanisms?',\n",
    "'What are recurrent nueral networks ? Are they time based deep learning models ?',\n",
    "'When do you see butterflies in the sky?',\n",
    "'Is there food in the kitchen?']\n",
    "\n",
    "\n",
    "import random\n",
    "query = random.sample(sample_questions,k=1)\n",
    "print(f\"Query:  {query[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "retrieve_docs(query[0], batched_sentence_embeddings_np,all_pdf_formatted_dict, embed_model, index2, n_return_docs=6, print_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d04c7d74-8864-45c2-86f7-6a6822ddcb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T23:36:34.004211Z",
     "iopub.status.busy": "2024-04-03T23:36:34.003855Z",
     "iopub.status.idle": "2024-04-03T23:36:34.050990Z",
     "shell.execute_reply": "2024-04-03T23:36:34.050324Z",
     "shell.execute_reply.started": "2024-04-03T23:36:34.004185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you explain the process of model extraction and perturbation used in GEMINI?\n",
      "<s>[INST] <s>[INST] Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What are the fat-soluble vitamins?\n",
      "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
      "\n",
      "Example 2:\n",
      "Query: What are the causes of type 2 diabetes?\n",
      "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the importance of hydration for physical performance?\n",
      "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "\n",
      " - It is trained by distilling from larger Gemini modelsItis 4-bit quantized for deployment and provides best-in-class performance. Table 1 | An overview of the Gemini 1.0 model family. Gemini models are trained to accommodate textual input interleaved with a wide variety of audioand visual inputs, such as natural images, charts, screenshots, PDFs, and videos, and they can producetext and image outputs (see Figure 2)The visual encoding of Gemini models is inspired by our ownfoundational work on Flamingo (Alayrac et al., 2022), CoCa (Yu et al., 2022a), and PaLI (Chen et al.,2022), with the important distinction that the models are multimodal from the beginning and cannatively output images using discrete image tokens (Ramesh et al., 2021; Yu et al., 2022b). Video understanding is accomplished by encoding the video as a sequence of frames in the largecontext windowVideo frames or images can be interleaved naturally with text or audio as part of themodel inputThe models can handle variable input resolution in order to spend more compute on2We plan to update this report with more details ahead of the general availability of the Gemini Ultra model.3\n",
      " - Gemini: A Family of Highly Capable Multimodal ModelsPaul Barham, Aakanksha Chowdhery, Jeff Dean, Sanjay Ghemawat, Steven Hand, Dan Hurt, MichaelIsard, Hyeontaek Lim, Ruoming Pang, Sudip Roy, Brennan Saeta, Parker Schuh, Ryan Sepassi,Laurent El Shafey, Chandramohan AThekkath, and Yonghui Wu. Pathways: Asynchronousdistributed dataflow for MLProceedings of Machine Learning and Systems, 4:430–449, 2022. James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin,George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao ZhangJAX:composable transformations of Python+NumPy programs, 2018URL http://github.com/google/jax. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, JeffreyWu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, BenjaminChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and DarioAmodei\n",
      " - Gemini: A Family of Highly Capable Multimodal ModelsFigure 5 | Gemini’s multimodal reasoning capabilities to generate matplotlib code for rearrangingthe subplotsThe multimodal prompt is shown at the top-left in grayGemini Ultra’s response,including its generated code, is shown in the right column in blueThe bottom left figure showsrendered version of the generated codeSuccessfully solving this task shows the model’s capabilityto combine several capabilities: (1) recognition of the functions depicted in the plots; (2) inversegraphics to infer the code that would have generated the subplots; (3) instruction-following to putsubplots in their desired positions; and (4) abstract reasoning to infer that the exponential plot muststay in its original place, because the sine plot must move out of the way for the 3-dimensional plot. Qualitative evaluation in Figure 5 illustrates an example of Gemini Ultra’s multimodal reasoningcapabilities\n",
      " - Attribution: If instructed to generate a response that should be fully attributed to a givencontext in the prompt, Gemini should produce a response with the highest degree of faithfulnessto the context (Rashkin et al., 2023)This includes the summarization of a user-providedsource, generating fine-grained citations given a question and provided snippets akin to Menicket al(2022); Peng et al(2023), answering questions from a long-form source such as abook (Mihaylov et al., 2018), and transforming a given source to a desired output (e.gan emailfrom a portion of a meeting transcript).2\n",
      " - Thethresholds are optimized for each model based on their validation split performanceThe proposedapproach is referred to as uncertainty-routed chain-of-thoughtThe intuition behind this approachis that chain-of-thought samples might degrade performance compared to the maximum-likelihooddecision when the model is demonstrably inconsistentWe compare the gains from the proposedapproach on both Gemini Ultra and GPT-4 in Figure 7We find that Gemini Ultra benefits more fromthis approach compared to using only chain-of-thought samples\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: Can you explain the process of model extraction and perturbation used in GEMINI?\n",
      "Answer:\n",
      "[/INST] [/INST]\n"
     ]
    }
   ],
   "source": [
    "# Augmentation of query + retrieved_docs\n",
    "# Pass to llm\n",
    "\n",
    "\n",
    "# Using Zero shot learning\n",
    "def data_augmenter(query, documents):\n",
    "    context = \"\\n - \" + \"\\n - \".join([doc[\"sentence_chunk\"] for doc in documents])\n",
    "    # base_prompt = \"\"\"Based on the following context documents, please answer the query.\n",
    "    # Think about the question and use the context to answer the query.\n",
    "    # Do not return the thinking, only return the answer.\n",
    "    # Make sure to provide detailed explainations.If you think there is not enough information in the context documents, say that you do not have enough information.\n",
    "    # Here are a few examples for your referance. Use it as a reference for the answer.\n",
    "    # \\nExample 1:\n",
    "    # Query: What is the best resource to learn generative AI ?\n",
    "    # Answer: Generative AI is a new and emerging field. The best way to learn is by practically implementing projects using HuggingFace transformers, LangChain and other available tools.\n",
    "    # \\nExample 2:\n",
    "    # Query: What is asdsdfvxcvsd ?\n",
    "    # Answer: I am sorry but I do not understand the question. Kindly re-correct the question or rephrase it to a meaningful ask.\n",
    "    # \\nNow use the following context below to answer the user query: \n",
    "    # {context}\n",
    "    # \\nRelevant passages: <extract relevant passages from the context here>\n",
    "    # User Query: {query}\n",
    "    # Answer:\"\"\"\n",
    "    base_prompt = \"\"\"<s>[INST] Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\n",
    "[/INST]\"\"\"\n",
    "\n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "    # Chat Template\n",
    "    chat_template = [\n",
    "                    {\"role\": \"user\", \n",
    "                     \"content\": base_prompt\n",
    "                    }\n",
    "                  ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(conversation=chat_template, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Choose a random query\n",
    "query = random.sample(sample_questions,k=1)\n",
    "print(f\"Query: {query[0]}\")\n",
    "# Get relevant context\n",
    "doc_ids = retrieve_docs(*query, batched_sentence_embeddings_np,all_pdf_formatted_dict, embed_model,\\\n",
    "                        index2, n_return_docs=5, print_time=False, print_docs=False)\n",
    "\n",
    "# Context documents\n",
    "context_docs = [all_pdf_formatted_dict[i] for i in doc_ids]\n",
    "# Format prompt\n",
    "prompt = data_augmenter(*query, documents=context_docs)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b0dc5065-2a84-49e5-ae13-35e349e612a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T23:37:34.488100Z",
     "iopub.status.busy": "2024-04-03T23:37:34.487210Z",
     "iopub.status.idle": "2024-04-03T23:37:48.213323Z",
     "shell.execute_reply": "2024-04-03T23:37:48.212739Z",
     "shell.execute_reply.started": "2024-04-03T23:37:34.488064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you explain the process of model extraction and perturbation used in GEMINI?\n",
      "Answer:<s><s> [INST] <s> [INST] Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What are the fat-soluble vitamins?\n",
      "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
      "\n",
      "Example 2:\n",
      "Query: What are the causes of type 2 diabetes?\n",
      "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the importance of hydration for physical performance?\n",
      "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "\n",
      " - It is trained by distilling from larger Gemini modelsItis 4-bit quantized for deployment and provides best-in-class performance. Table 1 | An overview of the Gemini 1.0 model family. Gemini models are trained to accommodate textual input interleaved with a wide variety of audioand visual inputs, such as natural images, charts, screenshots, PDFs, and videos, and they can producetext and image outputs (see Figure 2)The visual encoding of Gemini models is inspired by our ownfoundational work on Flamingo (Alayrac et al., 2022), CoCa (Yu et al., 2022a), and PaLI (Chen et al.,2022), with the important distinction that the models are multimodal from the beginning and cannatively output images using discrete image tokens (Ramesh et al., 2021; Yu et al., 2022b). Video understanding is accomplished by encoding the video as a sequence of frames in the largecontext windowVideo frames or images can be interleaved naturally with text or audio as part of themodel inputThe models can handle variable input resolution in order to spend more compute on2We plan to update this report with more details ahead of the general availability of the Gemini Ultra model.3\n",
      " - Gemini: A Family of Highly Capable Multimodal ModelsPaul Barham, Aakanksha Chowdhery, Jeff Dean, Sanjay Ghemawat, Steven Hand, Dan Hurt, MichaelIsard, Hyeontaek Lim, Ruoming Pang, Sudip Roy, Brennan Saeta, Parker Schuh, Ryan Sepassi,Laurent El Shafey, Chandramohan AThekkath, and Yonghui Wu. Pathways: Asynchronousdistributed dataflow for MLProceedings of Machine Learning and Systems, 4:430–449, 2022. James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin,George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao ZhangJAX:composable transformations of Python+NumPy programs, 2018URL http://github.com/google/jax. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, JeffreyWu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, BenjaminChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and DarioAmodei\n",
      " - Gemini: A Family of Highly Capable Multimodal ModelsFigure 5 | Gemini’s multimodal reasoning capabilities to generate matplotlib code for rearrangingthe subplotsThe multimodal prompt is shown at the top-left in grayGemini Ultra’s response,including its generated code, is shown in the right column in blueThe bottom left figure showsrendered version of the generated codeSuccessfully solving this task shows the model’s capabilityto combine several capabilities: (1) recognition of the functions depicted in the plots; (2) inversegraphics to infer the code that would have generated the subplots; (3) instruction-following to putsubplots in their desired positions; and (4) abstract reasoning to infer that the exponential plot muststay in its original place, because the sine plot must move out of the way for the 3-dimensional plot. Qualitative evaluation in Figure 5 illustrates an example of Gemini Ultra’s multimodal reasoningcapabilities\n",
      " - Attribution: If instructed to generate a response that should be fully attributed to a givencontext in the prompt, Gemini should produce a response with the highest degree of faithfulnessto the context (Rashkin et al., 2023)This includes the summarization of a user-providedsource, generating fine-grained citations given a question and provided snippets akin to Menicket al(2022); Peng et al(2023), answering questions from a long-form source such as abook (Mihaylov et al., 2018), and transforming a given source to a desired output (e.gan emailfrom a portion of a meeting transcript).2\n",
      " - Thethresholds are optimized for each model based on their validation split performanceThe proposedapproach is referred to as uncertainty-routed chain-of-thoughtThe intuition behind this approachis that chain-of-thought samples might degrade performance compared to the maximum-likelihooddecision when the model is demonstrably inconsistentWe compare the gains from the proposedapproach on both Gemini Ultra and GPT-4 in Figure 7We find that Gemini Ultra benefits more fromthis approach compared to using only chain-of-thought samples\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: Can you explain the process of model extraction and perturbation used in GEMINI?\n",
      "Answer:\n",
      "[/INST] [/INST] The Gemini models are multimodal machine learning models that can process text, audio, and visual inputs. They are trained by distilling from larger Gemini models and are 4-bit quantized for deployment (Barham et al., 2022). The visual encoding of Gemini models is inspired by previous research on Flamingo, CoCa, and PaLI, with the important distinction that these models are multimodal from the beginning and can produce images using discrete image tokens (Ramesh et al., 2021; Yu et al., 2022b).\n",
      "\n",
      "Gemini models can handle variable input resolution and accommodate textual input interleaved with a wide variety of audio and visual inputs, such as natural images, charts, screenshots, PDFs, and videos (Barham et al., 2022). Video understanding is accomplished by encoding the video as a sequence of frames in the large context window, and video frames or images can be interleaved naturally with text or audio as part of the model input.\n",
      "\n",
      "The models can generate outputs in the form of text and images. For example, they can generate matplotlib code for rearranging sub\n"
     ]
    }
   ],
   "source": [
    "#tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generating outputs using llm mistral-instruct now\n",
    "outputs = llm_model.generate(**input_ids, temperature=0.7,do_sample=True, max_new_tokens=256)\n",
    "\n",
    "generated_output = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query[0]}\")\n",
    "print(f\"Answer:{generated_output.replace(prompt, '')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9a9aa-8677-4c99-aa67-94652d9e9bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16092706-a342-477a-8f8b-9d92f30c99cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012bc61-832f-474d-b926-9103b961909e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
