{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324812b5-edfc-4501-9ded-ecd559725cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:16:47.544570Z",
     "iopub.status.busy": "2024-04-02T19:16:47.543710Z",
     "iopub.status.idle": "2024-04-02T19:16:52.166125Z",
     "shell.execute_reply": "2024-04-02T19:16:52.164682Z",
     "shell.execute_reply.started": "2024-04-02T19:16:47.544517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF==1.23.26 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.23.26)\n",
      "Requirement already satisfied: matplotlib==3.8.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (3.8.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pandas==2.2.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: Requests==2.31.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: sentence_transformers==2.5.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.66.2)\n",
      "Requirement already satisfied: transformers==4.38.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (4.38.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (0.28.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (0.43.0)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (0.35.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.9/dist-packages (from PyMuPDF==1.23.26->-r requirements.txt (line 1)) (1.23.22)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (5.10.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/dist-packages (from pandas==2.2.1->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==2.2.1->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from Requests==2.31.0->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (0.22.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.12.1+cu116)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (3.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (0.15.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.38.2->-r requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.4.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (66.1.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.8)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 10)) (5.9.4)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.16.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (8.0.2)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (5.5.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.5.2)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter->-r requirements.txt (line 12)) (7.2.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (2024.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.8.3->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 7)) (6.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 7)) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (8.5.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.6.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (25.0.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (7.3.4)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (0.1.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (6.1)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (5.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.5.6)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (3.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (3.0.36)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (5.1.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (2.14.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (5.7.3)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.2)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.4.8)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 12)) (2.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers==2.5.1->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.18.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.6.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter->-r requirements.txt (line 12)) (2.6.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.23.5)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 12)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (18.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (0.57.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ca8e7f-485d-43bc-bb8a-b5332868591b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T17:56:27.581570Z",
     "iopub.status.busy": "2024-04-02T17:56:27.581221Z",
     "iopub.status.idle": "2024-04-02T17:56:27.706893Z",
     "shell.execute_reply": "2024-04-02T17:56:27.706143Z",
     "shell.execute_reply.started": "2024-04-02T17:56:27.581542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import fitz\n",
    "import os\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f05e79-77f3-4fde-b9bf-f6bda82205d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T17:56:27.954538Z",
     "iopub.status.busy": "2024-04-02T17:56:27.954060Z",
     "iopub.status.idle": "2024-04-02T17:56:27.959617Z",
     "shell.execute_reply": "2024-04-02T17:56:27.958831Z",
     "shell.execute_reply.started": "2024-04-02T17:56:27.954511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Standford NLP.pdf', 'Attn_paper.pdf', 'Faiss.pdf', 'Gemini_paper.pdf', 'BART.pdf']\n"
     ]
    }
   ],
   "source": [
    "pdf_path = './'\n",
    "pdf_files = [f for f in os.listdir(pdf_path) if f.endswith(\".pdf\")]\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55f57935-34e4-40ae-bad8-5d1928230c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T18:04:42.521295Z",
     "iopub.status.busy": "2024-04-02T18:04:42.520283Z",
     "iopub.status.idle": "2024-04-02T18:04:42.526929Z",
     "shell.execute_reply": "2024-04-02T18:04:42.526134Z",
     "shell.execute_reply.started": "2024-04-02T18:04:42.521254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Text content of the pdf\n",
    "# For each pdf , get the pdf file contents \n",
    "# Store meta-data information about each pdf.\n",
    "\n",
    "def format_text(text):\n",
    "    text = text.strip(\"\\n\\n\")\n",
    "    text=text.replace(\"\\n\",'')\n",
    "    return text\n",
    "\n",
    "# # https://community.adobe.com/t5/acrobat-discussions/page-number-in-print-does-not-display-in-adobe-s-page-number-box/td-p/13781534\n",
    "# Doesn't use Logical Page numbers. Use the normal Page numbers\n",
    "# Logical causes issues during the rendering as you can't generalize to multiple pdfs\n",
    "\n",
    "def get_text_content(pdf_text_, pdf_):\n",
    "    doc = fitz.open(pdf_)\n",
    "    print(len(doc))\n",
    "    for page_num, page in enumerate(doc):\n",
    "        # Extract the text content of the page\n",
    "        text = page.get_text()\n",
    "        text = format_text(text)\n",
    "        name = pdf_.strip('.pdf')\n",
    "        pdf_text_.append((text, page_num+1, name))\n",
    "    return pdf_text_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "108b226d-3735-48c2-b4fe-ac6f882b03bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T18:04:43.294606Z",
     "iopub.status.busy": "2024-04-02T18:04:43.294253Z",
     "iopub.status.idle": "2024-04-02T18:04:46.071793Z",
     "shell.execute_reply": "2024-04-02T18:04:46.071064Z",
     "shell.execute_reply.started": "2024-04-02T18:04:43.294578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "15\n",
      "21\n",
      "62\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "books_ = []\n",
    "books_ = [get_text_content([], pdf_) for pdf_ in pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16e7ba8b-f5f9-4a52-9168-67d7bf68b45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T18:05:10.689319Z",
     "iopub.status.busy": "2024-04-02T18:05:10.688168Z",
     "iopub.status.idle": "2024-04-02T18:05:10.695799Z",
     "shell.execute_reply": "2024-04-02T18:05:10.694846Z",
     "shell.execute_reply.started": "2024-04-02T18:05:10.689261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107,\n",
       " ('Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on theEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.ModelBLEUTraining Cost (FLOPs)EN-DEEN-FREN-DEEN-FRByteNet [18]23.75Deep-Att + PosUnk [39]39.21.0 · 1020GNMT + RL [38]24.639.922.3 · 10191.4 · 1020ConvS2S [9]25.1640.469.6 · 10181.5 · 1020MoE [32]26.0340.562.0 · 10191.2 · 1020Deep-Att + PosUnk Ensemble [39]40.48.0 · 1020GNMT + RL Ensemble [38]26.3041.161.8 · 10201.1 · 1021ConvS2S Ensemble [9]26.3641.297.7 · 10191.2 · 1021Transformer (base model)27.338.13.3 · 1018Transformer (big)28.441.82.3 · 1019Residual DropoutWe apply dropout [33] to the output of each sub-layer, before it is added to thesub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and thepositional encodings in both the encoder and decoder stacks. For the base model, we use a rate ofPdrop = 0.1.Label SmoothingDuring training, we employed label smoothing of value ϵls = 0.1 [36]. Thishurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.6Results6.1Machine TranslationOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model islisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base modelsurpasses all previously published models and ensembles, at a fraction of the training cost of any ofthe competitive models.On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,outperforming all of the previously published single models, at less than 1/4 the training cost of theprevious state-of-the-art model. The Transformer (big) model trained for English-to-French useddropout rate Pdrop = 0.1, instead of 0.3.For the base models, we used a single model obtained by averaging the last 5 checkpoints, whichwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. Weused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameterswere chosen after experimentation on the development set. We set the maximum output length duringinference to input length + 50, but terminate early when possible [38].Table 2 summarizes our results and compares our translation quality and training costs to other modelarchitectures from the literature. We estimate the number of floating point operations used to train amodel by multiplying the training time, the number of GPUs used, and an estimate of the sustainedsingle-precision floating-point capacity of each GPU 5.6.2Model VariationsTo evaluate the importance of different components of the Transformer, we varied our base modelin different ways, measuring the change in performance on English-to-German translation on the5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.8',\n",
       "  8,\n",
       "  'Attn_paper'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_[1][7][0]) , books_[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "372100f9-c04e-4888-9d57-0e28f2d2a578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T18:05:41.219913Z",
     "iopub.status.busy": "2024-04-02T18:05:41.218964Z",
     "iopub.status.idle": "2024-04-02T18:05:41.291382Z",
     "shell.execute_reply": "2024-04-02T18:05:41.290698Z",
     "shell.execute_reply.started": "2024-04-02T18:05:41.219874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Books_  -> [List[List[(text_content, page_num)]]\n",
    "\n",
    "# Create a dictionary to store each pages documents into sentences\n",
    "\n",
    "# Estimating that each token is 4 characters\n",
    "# Page Info\n",
    "def page_formatter(page):\n",
    "    page_ = {}\n",
    "    for pg in page:\n",
    "        page_['doc_name'] = page[2]\n",
    "        page_['text'] = page[0]\n",
    "        page_['pg_num'] = page[1]\n",
    "        page_['pg_num_chars'] = len(page[0])\n",
    "        page_['pg_num_words'] = len(page[0].split(' '))\n",
    "        page_['pg_num_sentences'] = len(page[0].split('. ')) # Since sentences usually begin with '. '\n",
    "        page_['pg_num_tokens'] = page_['pg_num_chars'] / 4\n",
    "    return page_\n",
    "                                        \n",
    "# Testing with a single page\n",
    "# page_formatter(books_[1][6])\n",
    "\n",
    "all_content_ = [[page_formatter(page) for page in books] for books in books_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d8f3a9c-4daf-448c-bde8-00c044a642e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:11:59.666458Z",
     "iopub.status.busy": "2024-04-02T19:11:59.666113Z",
     "iopub.status.idle": "2024-04-02T19:11:59.672817Z",
     "shell.execute_reply": "2024-04-02T19:11:59.671988Z",
     "shell.execute_reply.started": "2024-04-02T19:11:59.666426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_name': 'Gemini_paper',\n",
       " 'text': 'Gemini: A Family of Highly Capable Multimodal ModelsFigure 2 | Gemini supports interleaved sequences of text, image, audio, and video as inputs (illustratedby tokens of different colors in the input sequence). It can output responses with interleaved imageand text.tasks that require fine-grained understanding. In addition, Gemini can directly ingest audio signals at16kHz from Universal Speech Model (USM) (Zhang et al., 2023) features. This enables the model tocapture nuances that are typically lost when the audio is naively mapped to a text input (for example,see audio understanding demo on the website).Training the Gemini family of models required innovations in training algorithms, dataset, andinfrastructure. For the Pro model, the inherent scalability of our infrastructure and learning algorithmsenable us to complete pretraining in a matter of weeks, leveraging a fraction of the Ultra’s resources.The Nano series of models leverage additional advancements in distillation and training algorithmsto produce the best-in-class small language models for a wide variety of tasks, such as summarizationand reading comprehension, which power our next generation on-device experiences.3. Training InfrastructureWe trained Gemini models using TPUv5e and TPUv4 (Jouppi et al., 2023), depending on their sizesand configuration. Training Gemini Ultra used a large fleet of TPUv4 accelerators across multipledatacenters. This represents a significant increase in scale over our prior flagship model PaLM-2which presented new infrastructure challenges. Scaling up the number of accelerators results in aproportionate decrease in the mean time between failure of hardware in the overall system. Weminimized the rate of planned reschedules and preemptions, but genuine machine failures arecommonplace across all hardware accelerators at such large scales.TPUv4 accelerators are deployed in “SuperPods” of 4096 chips, each connected to a dedicatedoptical switch, which can dynamically reconfigure 4x4x4 chip cubes into arbitrary 3D torus topologiesin around 10 seconds (Jouppi et al., 2023). For Gemini Ultra, we decided to retain a small number ofcubes per superpod to allow for hot standbys and rolling maintenance.TPU accelerators primarily communicate over the high speed inter-chip-interconnect, but atGemini Ultra scale, we combine SuperPods in multiple datacenters using Google’s intra-cluster andinter-cluster network (Poutievski et al., 2022; Wetherall et al., 2023; yao Hong et al., 2018). Google’snetwork latencies and bandwidths are sufficient to support the commonly used synchronous training4',\n",
       " 'pg_num': 4,\n",
       " 'pg_num_chars': 2605,\n",
       " 'pg_num_words': 360,\n",
       " 'pg_num_sentences': 12,\n",
       " 'pg_num_tokens': 651.25}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content_[3][3] # List[List[dictionaries]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11cd74a8-2aa4-45cd-951e-c0849a2015a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T18:57:09.240924Z",
     "iopub.status.busy": "2024-04-02T18:57:09.240100Z",
     "iopub.status.idle": "2024-04-02T18:57:09.251611Z",
     "shell.execute_reply": "2024-04-02T18:57:09.250901Z",
     "shell.execute_reply.started": "2024-04-02T18:57:09.240882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token_mean , Sentences_mean (725.0064991334489, 32.85441941074524)\n",
      "Token_mean , Sentences_mean (642.45, 17.0)\n",
      "Token_mean , Sentences_mean (1178.2619047619048, 26.857142857142858)\n",
      "Token_mean , Sentences_mean (581.2137096774194, 11.983870967741936)\n",
      "Token_mean , Sentences_mean (1003.2, 18.7)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# df_p1_mean = pd.DataFrame(all_content_[0])['pg_num_tokens'].mean()\n",
    "# # df_p2 = pd.DataFrame(all_content_[1])\n",
    "# # df_p3 = pd.DataFrame(all_content_[2])\n",
    "# # df_p4 = pd.DataFrame(all_content_[3])\n",
    "# print(df_p1_mean)\n",
    "\n",
    "# Calculate the mean number of sentences in each document.Then use sentence_splitter \n",
    "# to split the long sentences\n",
    "def calc_mean(doc):\n",
    "    doc_df = pd.DataFrame(doc)\n",
    "    doc_mean = doc_df['pg_num_tokens'].mean()\n",
    "    doc_sentences_mean = doc_df['pg_num_sentences'].mean()\n",
    "    return doc_mean, doc_sentences_mean\n",
    "\n",
    "for doc in all_content_:\n",
    "    print(\"Token_mean , Sentences_mean\",calc_mean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "490938ae-971f-4fc3-83d1-7a8a6271b570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:12:12.550253Z",
     "iopub.status.busy": "2024-04-02T19:12:12.549607Z",
     "iopub.status.idle": "2024-04-02T19:12:12.554363Z",
     "shell.execute_reply": "2024-04-02T19:12:12.553653Z",
     "shell.execute_reply.started": "2024-04-02T19:12:12.550225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each sentence is long , the mean token size are above and won't fit the embedding model for tokenization\n",
    "# Split sentences into smaller chunks\n",
    "\n",
    "# Method to put all sentences in an array called sentences for making the splitting easier\n",
    "def sentence_formatter_per_page(doc):\n",
    "    for page in doc:\n",
    "        page['sentences'] = [sentence for sentence in page['text'].split('. ')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c910ef41-1429-4e27-96c4-8e92fa6976fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:12:13.442397Z",
     "iopub.status.busy": "2024-04-02T19:12:13.441318Z",
     "iopub.status.idle": "2024-04-02T19:12:13.455708Z",
     "shell.execute_reply": "2024-04-02T19:12:13.454688Z",
     "shell.execute_reply.started": "2024-04-02T19:12:13.442366Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_formatter_all_books(books):\n",
    "    for item in books:\n",
    "        sentence_formatter_per_page(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53290f2f-9396-45b9-9a45-2f4302595bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:12:48.851106Z",
     "iopub.status.busy": "2024-04-02T19:12:48.850205Z",
     "iopub.status.idle": "2024-04-02T19:12:48.855884Z",
     "shell.execute_reply": "2024-04-02T19:12:48.855363Z",
     "shell.execute_reply.started": "2024-04-02T19:12:48.851074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_name': 'Standford NLP',\n",
       " 'text': '2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence. With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions. The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe. Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way. Consider the expression /[a-z]*/when matching against the text once upon a time. Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once. In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer. The operator *? is a Kleene star that matches as little text as*?possible. The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the. A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The). This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology). So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/. We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25). We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line. This is because the regular expression [ˆa-zA-Z], which',\n",
       " 'pg_num': 17,\n",
       " 'pg_num_chars': 2646,\n",
       " 'pg_num_words': 398,\n",
       " 'pg_num_sentences': 15,\n",
       " 'pg_num_tokens': 661.5,\n",
       " 'sentences': ['2.1•REGULAR EXPRESSIONS9any number of spaces! The star here applies only to the space ␣ that precedes it,not to the whole sequence',\n",
       "  'With the parentheses, we could write the expression/(Column␣[0-9]+␣*)*/ to match the word Column, followed by a number andoptional spaces, the whole pattern repeated zero or more times.This idea that one operator may take precedence over another, requiring us tosometimes use parentheses to specify what we mean, is formalized by the operatorprecedence hierarchy for regular expressions',\n",
       "  'The following table gives the orderoperatorprecedenceof RE operator precedence, from highest precedence to lowest precedence.Parenthesis()Counters* + ? {}Sequences and anchorsthe ˆmy end$Disjunction|Thus,becausecountershaveahigherprecedencethansequences,/the*/ matches theeeee but not thethe',\n",
       "  'Because sequences have a higher prece-dence than disjunction, /the|any/ matches the or any but not thany or theny.Patterns can be ambiguous in another way',\n",
       "  'Consider the expression /[a-z]*/when matching against the text once upon a time',\n",
       "  'Since /[a-z]*/ matches zero ormore letters, this expression could match nothing, or just the ﬁrst letter o, on, onc,or once',\n",
       "  'In these cases regular expressions always match the largest string they can;we say that patterns are greedy, expanding to cover as much of a string as they can.greedyThere are, however, ways to enforce non-greedy matching, using another mean-non-greedying of the ? qualiﬁer',\n",
       "  'The operator *? is a Kleene star that matches as little text as*?possible',\n",
       "  'The operator +? is a Kleene plus that matches as little text as possible.+?2.1.3A Simple ExampleSuppose we wanted to write a RE to ﬁnd cases of the English article the',\n",
       "  'A simple(but incorrect) pattern might be:/the/One problem is that this pattern will miss the word when it begins a sentence andhence is capitalized (i.e., The)',\n",
       "  'This might lead us to the following pattern:/[tT]he/But we will still incorrectly return texts with the embedded in other words (e.g.,other or theology)',\n",
       "  'So we need to specify that we want instances with a word bound-ary on both sides:/\\\\b[tT]he\\\\b/Suppose we wanted to do this without the use of /\\\\b/',\n",
       "  'We might want this since/\\\\b/ won’t treat underscores and numbers as word boundaries; but we might wantto ﬁnd the in some context where it might also have underlines or numbers nearby(the or the25)',\n",
       "  'We need to specify that we want instances in which there are noalphabetic letters on either side of the the:/[ˆa-zA-Z][tT]he[ˆa-zA-Z]/But there is still one more problem with this pattern: it won’t ﬁnd the word thewhen it begins a line',\n",
       "  'This is because the regular expression [ˆa-zA-Z], which']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_formatter_all_booksall_content_[0][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805733a-2cea-4579-be77-b8dcb40e1ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98814d44-297b-4e64-8629-b1428e7e4d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78c1e6-fac7-4c67-8be1-4a3380158b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc056e-e4b2-41d5-bf11-3800a69177e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94c8fe-f37b-4b9b-9459-9f78b3b21c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
